import{_ as r,c as e,o as t,a4 as o}from"./chunks/framework.DBIahkuf.js";const n="/AINotes/assets/fc8d04f1805d42f48a612157d413d20btplv-k3u1fbpfcp-zoom-in-crop-mark1512000.D9__m8pU.webp",d=JSON.parse('{"title":"开源LLM微调训练指南","description":"","frontmatter":{},"headers":[],"relativePath":"Document/开源模型训练/开源LLM微调训练指南.md","filePath":"Document/开源模型训练/开源LLM微调训练指南.md","lastUpdated":1708941732000}'),a={name:"Document/开源模型训练/开源LLM微调训练指南.md"},l=o('<h1 id="开源llm微调训练指南" tabindex="-1">开源LLM微调训练指南 <a class="header-anchor" href="#开源llm微调训练指南" aria-label="Permalink to &quot;开源LLM微调训练指南&quot;">​</a></h1><h2 id="flowise-轻松构建-llm-应用程序" tabindex="-1">Flowise - 轻松构建 LLM 应用程序 <a class="header-anchor" href="#flowise-轻松构建-llm-应用程序" aria-label="Permalink to &quot;Flowise - 轻松构建 LLM 应用程序&quot;">​</a></h2><p><a href="https://github.com/FlowiseAI/Flowise" target="_blank" rel="noreferrer">FlowiseAI/Flowise：拖放UI来构建您的自定义LLM流程 (github.com)</a></p><h2 id="the-document-is-all-you-need-一站式-llm-底层技术原理入门指南" tabindex="-1">The Document is All You Need！一站式 LLM 底层技术原理入门指南 <a class="header-anchor" href="#the-document-is-all-you-need-一站式-llm-底层技术原理入门指南" aria-label="Permalink to &quot;The Document is All You Need！一站式 LLM 底层技术原理入门指南&quot;">​</a></h2><p><strong>飞书文档</strong>：<a href="https://s3tlxskbq3.feishu.cn/docx/NyPqdCKraoXz9gxNVCfcIFdnnAc" target="_blank" rel="noreferrer">⁡The Document is All You Need！一站式 LLM底层技术原理入门指南 - 飞书云文档 (feishu.cn)</a></p><p>这是一篇非常「硬核」的飞书文档，面向非科班出身但想要了解AI技术原理的受众，帮助实现<strong>零基础入门大语言模型 (Large Language Mode, LLM) 底层技术原理</strong>。</p><p>文档从浅到深，覆盖了非常多内容细节，并在持续更新 LLM 最新技术进展及相关原理！<strong>如果你对ChatGPT等大语言模型感兴趣、希望入门了解大语言模型这件事、想知道这个世界上正在发生什么</strong>，那这篇文档值得放入你的收藏夹~</p><blockquote><ol><li>Introduction：人工智能概述</li><li>入门 | 多层感知器 Multiple-Layer Perceiver， MLP</li><li>入门 | 卷积神经网络 Convolutional Neural Network， CNN</li><li>入门 | 循环神经网络 Recurrent Neural Networks， RINNS</li><li>入门 | 强化学习 Reinforcement Learning， RL</li><li>入门 | 自然语言处理与语言模型 NLP &amp; LanguageModeI， LM</li><li>开始进入正题！seq2seq模型与注意力机制 Attention！ (2014)</li><li>RNN 时代的 BERT 和 GPT！Semi-Supervised Sequence Learning：怎么用大量无标注样本去做自监督学习？ (2015)</li><li>欢迎来到芝麻街家族！图解ELMo：Embedding的新纪元 (2018.2)</li><li>Attention is All You Need！大语言模型的基石 Transfoormer (2017)</li><li>ULM-FiT 与多任务学习 Multitask Learning：NLP的 ImageNet 时刻 (2018.5)</li><li>它来了它来了，终于等到你！大篇幅详解 GPT，GPT-2 与 GPT3</li><li>预训练语言模型的新范式：Prompting！</li><li>为什么它诞生之初远比 GPT 出风头？图解芝麻街家族新员BIERT！(2018.10)</li><li>回看波澜壮阔的语言模型乃至 NLP 的发展史！</li></ol></blockquote><h2 id="llama-2微调的极速指南-制作对话摘要生成器" tabindex="-1">Llama 2微调的极速指南，制作对话摘要生成器 <a class="header-anchor" href="#llama-2微调的极速指南-制作对话摘要生成器" aria-label="Permalink to &quot;Llama 2微调的极速指南，制作对话摘要生成器&quot;">​</a></h2><p><a href="https://brev.dev/blog/fine-tuning-llama-2" target="_blank" rel="noreferrer">A simple guide to fine-tuning Llama 2 (brev.dev)</a></p><p>这是一篇极速操作指南，结合<strong>代码案例</strong>演示了如何使用 Hugging Face 库对 Llama 2 模型进行微调 (fine-tuning)，使其成为一个对话摘要生成器，对于 Llama 模型的实际使用具有很好的参考价值。</p><blockquote><ol><li><strong>Download the model</strong>：通过 clone Llama 的 inference repo 来下载 Llama 2 的7B模型，并组织好目录结构，准备接下来的转换和训练；<strong>这一步获取了基础的Llama 2模型</strong></li><li><strong>Convert model to Hugging Face format</strong>：使用提供的转换脚本，将原始的 Llama 2 模型转换为 Hugging Face 的格式，方便后续通过 Hugging Face 的 API 进行微调；<strong>这一步实现了模型格式的转换，为 fine-tuning 做好了准备</strong></li><li><strong>Run the fine-tuning notebook</strong>：基于 Hugging Face 的 transformers 库，作者编写了一个 nNotebook，内含了数据集准备、模型加载、设置训练参数等代码，可以直接运行进行对话摘要任务的微调；<strong>这一步完成了对话摘要模型的训练</strong></li><li><strong>Run inference on your fine-tuned model</strong>：由于 Hugging Face 仅保存 adapter 权重，所以需要将经过微调的权重加载到完整 Llama 2 模型中，然后就可以进行推理和生成对话摘要了；<strong>这一步实现了利用微调过的模型进行下游任务</strong></li></ol></blockquote><h2 id="llm-超全综述博客-并在hn引发热烈讨论" tabindex="-1">LLM 超全综述博客，并在HN引发热烈讨论 <a class="header-anchor" href="#llm-超全综述博客-并在hn引发热烈讨论" aria-label="Permalink to &quot;LLM 超全综述博客，并在HN引发热烈讨论&quot;">​</a></h2><p><a href="https://willthompson.name/what-we-know-about-llms-primer" target="_blank" rel="noreferrer"><strong>⋙ Blog</strong></a> | <a href="https://news.ycombinator.com/item?id=36860992" target="_blank" rel="noreferrer"><strong>Hacker News</strong></a></p><p>这是一篇由 Will Thompson 撰写的大语言模型 (LLM) 综述性文章，并被分享到了 Hacker News (HN) 引发了热烈的讨论。文章包含以下主要内容：</p><blockquote><ol><li><strong>介绍</strong>：概述了当前社会各界对 LLM 的广泛关注和讨论，以及文章作者出于理性分析的立场进行撰写的目的</li><li><strong>我们对 LLM 的理解</strong></li></ol><ul><li><strong>LLM 的技术内涵</strong>：详细介绍了 LLM 的技术原理 (包括 Transformer、Attention 机制、并行处理等)，分析了 LLM 相较 RNN 的优势，以及模型规模不断增长的趋势</li><li><strong>LLM 的分类</strong>：根据语言处理过程的不同，可分为 Encoder、Decoder 和 Encoder-Decoder 三类 LLM 模型，各有优势</li></ul><ol><li><strong>我们过去对 LLM 的认知</strong></li></ol><ul><li><strong>泛化能力</strong>： LLM 可快速泛化应用到新的任务，无需全新训练，体现出强大的迁移学习能力</li><li><strong>性能可预测</strong>：模型规模越大，数据量越多， LLM 性能 predictable，呈现可量化的规模法则</li><li><strong>研究热点</strong>：介绍了 LLM 研究的主要方向，包括模型缩放、效率提升、多模态等</li></ul><ol><li><strong>InstructGPT 的贡献</strong>：InstructGPT 通过引入 SFT 和 RLHF 提升了 LLM 的可控性和 alignment，为后续模型奠定基础</li><li><strong>Instruction Fine-tuning 和 RLHF</strong>：详细解释了InstructGPT的两大技术要点，包括实现方式、意义等</li><li><strong>LLM 作为推理代理</strong>：基于 Prompt Engineering等技术，LLM 可作为推理代理完成复杂任务，发挥强大的问题解决能力</li></ol></blockquote><p>Hacker News 页面收获了近200条留言，评论者积极讨论了 LLM 的现状和发展前景等话题：</p><blockquote><ol><li><strong>LLM 技术目前还处在哪个阶段</strong>：有人认为仍在高峰期，也有观点是已经进入「幻灭期」</li><li><strong>关于杀手级应用的意见不一</strong>：有人认为 Copilot 等就是杀手级应用，也有评论认为目前还没有出现真正的杀手级应用</li><li><strong>关于商业应用</strong>：讨论了 LLM 在知识管理、产品教学等方面的应用潜力。但也有观点认为空洞的营销应用居多</li><li><strong>关于社会影响</strong>：担心就业损失的声音比较多。也有观点认为真正受影响的可能只是一小部分人</li><li><strong>技术讨论方面</strong>：有评论分析了不同 Transformer 架构的区别，以及在不同任务上的适用性</li><li><strong>关于研究方向</strong>：提到了 Interpretability 等让 LLM 决策更可解释的研究趋势</li><li>还讨论了 customizable 芯片、降低训练成本等硬件方向，以及提升安全性、避免偏见等方面的研究价值</li></ol></blockquote><h2 id="开源llm微调训练指南-如何打造属于自己的llm模型" tabindex="-1">开源LLM微调训练指南：如何打造属于自己的LLM模型 <a class="header-anchor" href="#开源llm微调训练指南-如何打造属于自己的llm模型" aria-label="Permalink to &quot;开源LLM微调训练指南：如何打造属于自己的LLM模型&quot;">​</a></h2><p>原文：<a href="https://mp.weixin.qq.com/s/R-6ds1bFmOqPANIgVCs2Gg" target="_blank" rel="noreferrer">开源LLM微调训练指南：如何打造属于自己的LLM模型 (qq.com)</a></p><p>LLM应该算是目前当之无愧的最有影响力的AI技术。而很多人在领略了 GPT 等大语言模型的魅力后，迫不及待地考虑能将模型能力集成到自己的产品中去。</p><p>这篇文章就聊到了这个话题——大语言模型 (LLM) 微调训练。这是一篇系统的 LLM 微调指南，对初学者掌握 LLM 微调技术非常有价值：</p><blockquote><ol><li><strong>介绍</strong>：介绍了商用LLM模型存在的问题，包括使用成本高昂和数据隐私风险，因此建议微调开源LLM模型来实现自己的目标</li><li><strong>什么是迁移学习</strong>：解释了什么是迁移学习,以及如何通过微调预训练语言模型来适应新的任务</li><li><strong>选择合适的基础模型</strong>：提出了选择基础 LLM 模型的方法，包括参考模型排行榜、检查许可证、注意模型大小等，推荐使用 Hugging Face 的 falcon 系列</li><li><strong>如何准备模型训练数据</strong>：详细解释了如何准备高质量的 LLM 训练数据集，包含数量、自动生成、遵循的格式等方面</li><li><strong>如何选择模型训练环境</strong>：推荐了模型训练环境的选择，推荐了各种获取 GPU 资源的方式，建议初学者使用 Google Colab</li><li><strong>开始训练你的 LLM 模型</strong>：指导了如何用 Hugging Face 的 Transformer 库加载模型，并使用 QLoRA 技术进行微调</li><li><strong>模型推理</strong>：给出了模型推理的代码示例，展示了如何使用微调后的模型生成回复</li><li><strong>总结</strong>：总结要点，微调开源LLM模型可以获得比较好的结果，适合各种实际应用场景</li></ol></blockquote><h2 id="llm-开发必修课-6周教你用热门框架开发商业级-llm-产品" tabindex="-1">LLM 开发必修课，6周教你用热门框架开发商业级 LLM 产品 <a class="header-anchor" href="#llm-开发必修课-6周教你用热门框架开发商业级-llm-产品" aria-label="Permalink to &quot;LLM 开发必修课，6周教你用热门框架开发商业级 LLM 产品&quot;">​</a></h2><p><a href="https://www.edx.org/course/large-language-models-application-through-production/" target="_blank" rel="noreferrer">Databricks: Large Language Models: Application through Production | edX</a></p><p>这是 Databricks 出品的「<strong>Large Language Models: Application through Production (大语言模型：产品中的应用)</strong>」在线课程，国内小伙伴们可以在 edX 网站免费观看。</p><p>这门课程面向开发人员、数据科学家和工程师，帮助使用最流行的框架 (如Hugging Face、LangChain) 来构建面向大语言模型的应用程序。通过这门课程的学习,你能够构建一个端到端的LLM工作流程，使其准备上线生产。</p><h3 id="🔔-课程章节" tabindex="-1">🔔 <strong>课程章节</strong> <a class="header-anchor" href="#🔔-课程章节" aria-label="Permalink to &quot;🔔 **课程章节**&quot;">​</a></h3><blockquote><p><em>▢</em> 模块1：用LLM应用</p><p><em>▢</em> 模块2：嵌入、向量数据库和搜索</p><p><em>▢</em> 模块3：多阶段推理</p><p><em>▢</em> 模块4：LLM的微调和评估</p><p><em>▢</em> 模块5：社会与LLM-偏见和安全</p><p><em>▢</em> 模块6：LLMOps</p></blockquote><h3 id="🔔-学习收获" tabindex="-1">🔔 <strong>学习收获</strong> <a class="header-anchor" href="#🔔-学习收获" aria-label="Permalink to &quot;🔔 **学习收获**&quot;">​</a></h3><blockquote><p><em>▢</em> 如何使用流行的库 (如Hugging Face、LangChain) 将 LLM 应用到自然语言处理 (NLP) 的实际问题中</p><p><em>▢</em> <strong>如何使用嵌入和向量数据库将域知识和记忆添加到 LLM 流程中</strong></p><p><em>▢</em> <strong>理解预训练、微调和提示工程的细微差别,并将这些知识应用到自定义聊天模型的微调中</strong></p><p><em>▢</em> 如何使用不同的方法来评估 LLM 的效果和偏见</p><p><em>▢</em> 如何实现 LLMOps 和多阶段推理最佳实践的 LLM 工作流程</p><p><em>▢</em> <strong>如何利用 LLMOps 最佳实践在规模上部署模型</strong></p></blockquote><h2 id="llm-进化树升级版-清晰展示-15821-个大语言模型的关系" tabindex="-1">LLM 进化树升级版！清晰展示 15821 个大语言模型的关系 <a class="header-anchor" href="#llm-进化树升级版-清晰展示-15821-个大语言模型的关系" aria-label="Permalink to &quot;LLM 进化树升级版！清晰展示 15821 个大语言模型的关系&quot;">​</a></h2><p><a href="https://arxiv.org/ftp/arxiv/papers/2307/2307.09793.pdf" target="_blank" rel="noreferrer"><strong>⋙ 论文</strong></a></p><p><img src="'+n+'" alt="img"></p><p>这张进化图来自于论文 「<em><strong>On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models</strong></em>」，构建了一个包含15821个大型语言模型的进化树和关系图，以便探索不同的大模型之间的关系</p><h2 id="大模型微调-finetune-方法总结-带你解锁5种技术" tabindex="-1">大模型微调 (finetune) 方法总结，带你解锁5种技术 <a class="header-anchor" href="#大模型微调-finetune-方法总结-带你解锁5种技术" aria-label="Permalink to &quot;大模型微调 (finetune) 方法总结，带你解锁5种技术&quot;">​</a></h2><p>这篇文章详细介绍了 LoRA、Adapter、Prefix-tuning、P-tuning 和 Prompt-tuning 这5种微调技术的方法论、实现原理和优缺点，并对每种方法都进行了翔实的技术解读&amp;效果展示，让读者快速理解每种微调技术的精髓所在。</p><p>在实践中合理地选择和应用这些大模型微调技术,可以有效提升下游任务的效果，取得与全模型微调接近的表现，而又大幅降低了算力和存储成本。这对于中小企业能否取得大模型带来的效果提升,具有重大意义。</p><blockquote><p><em>1</em>. <strong>LoRA</strong></p><p><em>▢</em> <strong>论文</strong>：LoRA: Low-Rank Adaptation of Large Language Models - <a href="https://arxiv.org/pdf/2106.09685.pdf" target="_blank" rel="noreferrer">arxiv.org/pdf/2106.09…</a></p><p><em>▢</em> <strong>代码</strong>：<a href="https://github.com/microsoft/LoRA" target="_blank" rel="noreferrer">github.com/microsoft/L…</a></p><p><em>▢</em> <strong>简介</strong>：通过增加旁路低秩矩阵来模拟全模型微调，只训练降维矩阵A和升维矩阵B，固定原模型参数，实现轻量级微调</p><p><em>2</em>. <strong>Adapter</strong></p><p><em>▢</em> <strong>论文</strong>：Parameter-Efficient Transfer Learning for NLP - <a href="https://arxiv.org/pdf/1902.00751.pdf" target="_blank" rel="noreferrer">arxiv.org/pdf/1902.00…</a></p><p><em>▢</em> <strong>论文</strong>：MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer - <a href="https://arxiv.org/pdf/2005.00052.pdf" target="_blank" rel="noreferrer">arxiv.org/pdf/2005.00…</a></p><p><em>▢</em> <strong>简介</strong>：在模型层中添加 Adapter 模块，只训练 Adapter 的参数，固定原模型，避免灾难性遗忘；Adapter Fusion 通过两阶段训练提升性能</p><p><em>3</em>. <strong>Prefix-tuning</strong></p><p><em>▢</em> <strong>论文</strong>：Prefix-Tuning: Optimizing Continuous Prompts for Generation - <a href="https://arxiv.org/pdf/2101.00190.pdf" target="_blank" rel="noreferrer">arxiv.org/pdf/2101.00…</a></p><p><em>▢</em> <strong>代码</strong>：<a href="https://github.com/XiangLi1999/PrefixTuning" target="_blank" rel="noreferrer">github.com/XiangLi1999…</a></p><p><em>▢</em> <strong>简介</strong>：为模型添加连续的任务特定向量作为前缀，只优化前缀参数，实现轻量级微调</p><p><em>4</em>. <strong>P-tuning</strong></p><p><em>▢</em> <strong>论文</strong>：GPT Understands, Too - <a href="https://arxiv.org/abs/2103.10385" target="_blank" rel="noreferrer">arxiv.org/abs/2103.10…</a></p><p><em>▢</em> <strong>代码</strong>：<a href="https://github.com/THUDM/P-tuning" target="_blank" rel="noreferrer">github.com/THUDM/P-tun…</a></p><p><em>▢</em> <strong>简介</strong>：使用模板和编码过的 prompt，在输入前后加入 anchor，同时只更新 prompt 的参数，适合 NLP 下游任务</p><p><em>5</em>. <strong>Prompt-tuning</strong></p><p><em>▢</em> <strong>简介</strong>：为每个任务自定义 prompt 拼接在输入上，固定原模型只训练 prompt，可以达到与全模型微调相近的效果 <a href="https://zhuanlan.zhihu.com/p/644122818" target="_blank" rel="noreferrer"><strong>⋙ 知乎 @腾讯技术工程</strong></a></p></blockquote><h2 id="如何评估一个大语言模型-看微软这篇-llm-能力评测综述" tabindex="-1">如何评估一个大语言模型？看微软这篇 LLM 能力评测综述 <a class="header-anchor" href="#如何评估一个大语言模型-看微软这篇-llm-能力评测综述" aria-label="Permalink to &quot;如何评估一个大语言模型？看微软这篇 LLM 能力评测综述&quot;">​</a></h2><p>大型语言模型（Large language models, LLMs）因其在学术界和工业界展现出前所未有的性能而备受青睐。随着 LLMs 在研究和实际应用中被广泛使用，对其进行有效评估变得愈发重要。</p><p>微软亚洲研究院的 <em><strong>A Survey on Evaluation of Large Language Models</strong></em> 是大模型评测领域的第一篇综述文章，一共调研了219篇文献，以<strong>评估对象 (what to evaluate)</strong> 、<strong>评估领域 (where to evaluate)</strong> 、<strong>评估方法 (How to evaluate)</strong> 和目前的评估挑战等几大方面，对大模型的评估进行了详细的梳理和总结。</p><blockquote><ol><li><strong>评测什么</strong>：自然语言处理、鲁棒性/伦理/偏见和真实性、医学应用、社会科学、自然科学与工程、代理应用、其他应用</li><li><strong>在哪评测</strong>：总结了19个流行的基准测试，每个基准关注不同的方面和评估标准，为各自的领域做出了贡献</li><li><strong>如何评测</strong>：介绍了自动评估和人工评估两种主要方法。这两种方法在评估语言模型和机器翻译等任务时起着重要的作用</li><li><strong>综述总结</strong>：总结大语言模型的成功案例和可能的失败情况</li></ol><p>1.<strong>重大挑战</strong>：提出了7项大语言模型评估面临的重大挑战</p><ul><li><strong>设计 AGI 基准测试</strong>：什么是可靠、可信任、可计算的能正确衡量 AGI 任务的评估指标？</li><li><strong>设计 AGI 基准完成行为评估</strong>：除去标准任务之外，如何衡量 AGI 在其他任务，如机器人交互中的表现？</li><li><strong>稳健性评估</strong>：目前的大模型对输入的 prompt 非常不鲁棒，如何构建更好的鲁棒性评估准则？</li><li><strong>动态演化评估</strong>：大模型的能力在不断进化、也存在记忆训练数据的问题。如何设计更动态更进化式的评估方法？</li><li><strong>可信赖的评估</strong>：如何保证所设计的评估准则是可信任的？</li><li><strong>支持所有大模型任务的统一评估</strong>：大模型的评估并不是终点、如何将评估方案与大模型有关的下游任务进行融合？</li><li><strong>超越单纯的评估</strong>：大模型的增强：评估出大模型的优缺点之后，如何开发新的算法来增强其在某方面的表现？ <a href="https://arxiv.org/abs/2307.03109" target="_blank" rel="noreferrer"><strong>⋙ 论文</strong></a> | <a href="https://github.com/MLGroupJLU/LLM-eval-survey" target="_blank" rel="noreferrer"><strong>GitHub</strong></a> | <a href="https://mp.weixin.qq.com/s/eFNx97ajxZnWZ-X-19KBNg" target="_blank" rel="noreferrer"><strong>中文解读 @微软亚洲研究院</strong></a></li></ul></blockquote><h2 id="拾象实践-为了理解-ai-native-我们做了几款ai应用" tabindex="-1">拾象实践：为了理解 AI-Native，我们做了几款AI应用 <a class="header-anchor" href="#拾象实践-为了理解-ai-native-我们做了几款ai应用" aria-label="Permalink to &quot;拾象实践：为了理解 AI-Native，我们做了几款AI应用&quot;">​</a></h2><p><a href="https://mp.weixin.qq.com/s/QCpGXsqYRzfHIPBiHAlsRw" target="_blank" rel="noreferrer"><strong>⋙ @海外独角兽</strong></a></p><p>拾象团队内部进行了一系列 LLM 应用开发的实践，既包括对话式内部知识库、音视频转录这类效率工具，也有复刻 GPT、LLM 输入法等偏实验性质尝试。这是技术负责人秦佳豪对 LLM 应用实践的阶段性总结回顾。</p><p>虽然大部分实践在这个时间点看起来已经「过时」甚至「徒劳」，但快速了解一个行业的最佳的方式就是参与其中，尤其是 LLM 这样的新浪潮。本篇 LLM 应用探索笔记则是一位一线开发者对 LLM 的思考。</p><h3 id="💡-llm-应用实践复盘" tabindex="-1">💡 <strong>LLM 应用实践复盘</strong> <a class="header-anchor" href="#💡-llm-应用实践复盘" aria-label="Permalink to &quot;💡 **LLM 应用实践复盘**&quot;">​</a></h3><blockquote><p><em>1</em>. <strong>实践1-对话式内部知识库</strong>：利用 GPT-3 接口实现对话式搜索，部署成飞书机器人使用；虽然效果不错，但 davinci-002 理解能力仍不足，需要连接真实数据才能提升准确性</p><p><em>2</em>. <strong>实践2-复刻instruct GPT</strong>：参考论文，使用 trlx 库对 GPT-2 中文进行 finetune，实现简易的instruct GPT；可以通过改变提示实现情感分析切换，但整体效果与ChatGPT相比仍有差距</p><p><em>3</em>. <strong>实践3-让ChatGPT上网</strong>：通过浏览器与网络接口，实现 ChatGPT 查询互联网信息的功能。不同任务使用不同的数据和 API，扩展了 ChatGPT 的能力边界</p><p><em>4</em>. <strong>实践4-端侧推理产品探索</strong>：尝试通过移动输入法、翻译耳机等端侧部署，实现本地推理；但受限于硬件和系统，效果一般</p></blockquote><h3 id="💡-llm应用一-pickpod" tabindex="-1">💡 <strong>LLM应用一：PickPod</strong> <a class="header-anchor" href="#💡-llm应用一-pickpod" aria-label="Permalink to &quot;💡 **LLM应用一：PickPod**&quot;">​</a></h3><blockquote><p><em>1</em>. 开发了音视频内容总结工具，支持准确转录及提取关键信息</p><p><em>2</em>. <strong>后期转为利用 LLM 提取「非共识」，实现个性化的播客发现和推荐，根据用户反馈不断改进</strong></p></blockquote><h3 id="💡-llm应用二-盗梦笔记" tabindex="-1">💡 <strong>LLM应用二：盗梦笔记</strong> <a class="header-anchor" href="#💡-llm应用二-盗梦笔记" aria-label="Permalink to &quot;💡 **LLM应用二：盗梦笔记**&quot;">​</a></h3><blockquote><p><em>1</em>. 实现基于网页的AI驱动跑团游戏，多个 AI agent 分工协作推进游戏</p><p><em>2</em>. 添加创作者模式，可以导入故事或通过提示自动生成游戏模块，还可以修改和优化</p><p><em>3</em>. <strong>不同AI模型可以实现不同的游戏风格，Claude 表现突出，同时可以通过游戏采集交互数据</strong></p></blockquote><h3 id="💡-总结" tabindex="-1">💡 <strong>总结</strong> <a class="header-anchor" href="#💡-总结" aria-label="Permalink to &quot;💡 **总结**&quot;">​</a></h3><blockquote><p><em>1</em>. <strong>工程实现被模型能力提升淹没，但可以快速感受 LLM 应用发展</strong></p><p><em>2</em>. <strong>控制成本和实现可持续业务模式是关键</strong>，游戏等娱乐形式有天然优势</p><p><em>3</em>. <strong>模型强弱取决于使用场景</strong>，端侧推理可提升安全性，基础服务可大幅提高应用效率</p><p><em>4</em>. <strong>影响下一代用户和硬件发展，才是 LLM 应用的关键所在</strong></p></blockquote>',55),i=[l];function s(g,p,L,m,u,h){return t(),e("div",null,i)}const f=r(a,[["render",s]]);export{d as __pageData,f as default};
