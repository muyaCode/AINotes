import{_ as a,c as e,o as n,a4 as s}from"./chunks/framework.DBIahkuf.js";const m=JSON.parse('{"title":"语言模型社区","description":"","frontmatter":{},"headers":[],"relativePath":"Document/语言模型社区/语言模型社区.md","filePath":"Document/语言模型社区/语言模型社区.md","lastUpdated":1708941732000}'),p={name:"Document/语言模型社区/语言模型社区.md"},r=s(`<h1 id="语言模型社区" tabindex="-1">语言模型社区 <a class="header-anchor" href="#语言模型社区" aria-label="Permalink to &quot;语言模型社区&quot;">​</a></h1><p>语言模型知识博客：<a href="https://wqw547243068.github.io/" target="_blank" rel="noreferrer">鹤啸九天 (wqw547243068.github.io)</a></p><p>Falcon 是由位于阿布扎比的 <a href="https://www.tii.ae/" target="_blank" rel="noreferrer">技术创新研究院 (Technology Innovation Institute，TII) </a> 创建的一系列的新语言模型，其基于 Apache 2.0 许可发布。 <strong>值得注意的是，<a href="https://huggingface.co/tiiuae/falcon-40b" target="_blank" rel="noreferrer">Falcon-40B</a> 是首个“真正开放”的模型，其能力可与当前许多闭源模型相媲美</strong>。这对从业者、爱好者和行业来说都是个好消息，因为“真开源”使大家可以毫无顾忌地基于它们探索百花齐放的应用。</p><p>本文，我们将深入探讨 Falcon 模型: 首先探讨它们的独特之处，然后 <strong>展示如何基于 Hugging Face 生态提供的工具轻松构建基于 Falcon 模型的多种应用 (如推理、量化、微调等)</strong> 。</p><h2 id="huggingchat" tabindex="-1">HuggingChat <a class="header-anchor" href="#huggingchat" aria-label="Permalink to &quot;HuggingChat&quot;">​</a></h2><p>『HuggingFace发布ChatGPT开源替代品HuggingChat』公开向OpenAI闭源生态发起挑战</p><p>4月25日，Huggingface宣布推出HuggingChat，这是一款ChatGPT的开源替代品，可以与用户进行问答互动，目前还不支持中文回答。</p><p>HuggingFace相当于人工智能领域届的GitHub，基本上开源AI模型的Demo都跑在上面，因此很多人都开源的HuggingChat寄予厚望。不过，经过 ShowMeAI 社区小伙伴们的测试，HuggingChat与ChatGPT还存在较大差距，逊色于GPT-3.5。期待开源后大量用户对数据进行微调能提升体验。</p><p><a href="https://huggingface.co/chat/" target="_blank" rel="noreferrer"><strong>在线体验</strong></a></p><p><a href="https://juejin.cn/post/7245205625851478053" target="_blank" rel="noreferrer">Falcon 登陆 Hugging Face 生态 - 掘金 (juejin.cn)</a></p><h3 id="huggingface-介绍" tabindex="-1">huggingface 介绍 <a class="header-anchor" href="#huggingface-介绍" aria-label="Permalink to &quot;huggingface 介绍&quot;">​</a></h3><p>Hugging Face 是一家在自然语言处理和人工智能领域著名的公司，以开发开源的软件库和工具为主要贡献，其中最受欢迎的是 Transformers 库，广泛应用于诸如语言翻译、情感分析和问答等多种自然语言处理任务。此外，Hugging Face 还开发了一些商业产品，例如 Hugging Face Spaces 和 Hugging Face Datasets，为构建和部署自然语言处理模型提供工具和基础设施。</p><p>Hugging Face Hub是一个社区，旨在为机器学习开发者提供各种功能。其中主要包括：</p><ul><li><p>模型仓库（Model Repository）：类似于Git仓库，允许用户管理代码版本和开源代码，模型仓库则让用户管理模型版本和开源模型等。使用方式与Github类似。</p></li><li><p>模型（Models）：Hugging Face为不同的机器学习任务提供了许多预训练好的机器学习模型，这些模型存储在模型仓库中。</p></li><li><p>数据集（Dataset）：Hugging Face上有许多公开数据集可供用户使用。</p></li></ul><p>在NLP领域，Hugging Face因其提供基于Transformer的模型而闻名。为了方便用户使用，Hugging Face还提供了以下几个项目：</p><ul><li><p>Transformers ：Transformers 库是Hugging Face的核心，我们学习Hugging Face其实就是学习怎么使用这个库。这个库提供了API和很多工具及方法，方便我们下载和训练最先进的预训练模型。这些模型支持不同模态下的常见任务，例如自然语言处理，计算机视觉，音频，多模态等。</p></li><li><p>Datasets ：使用该框架，只需要少量代码即可轻松下载和预处理常见公开数据集。同时还提供了强大的数据预处理方法，可帮助我们快速准备数据，以用于训练机器学习模型。</p></li><li><p>Space ：在这里我们可以在线体验很多有趣的应用，比如根据文字生成图片，根据我们的照片制作合成音视频等。</p></li></ul><p>那究竟如何使用 Transformers进行推理呢？首先我们先要安装Transformers：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span>pip install transformers</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>如果任务比较简单，Transformers的pipline()函数本身就提供了很丰富的功能，比如下面的代码，就多一个语句进行了一个简单的情感分析：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span>from transformers import pipeline</span></span>
<span class="line"><span>​</span></span>
<span class="line"><span>classifier = pipeline(&quot;text-classification&quot;)</span></span>
<span class="line"><span>classifier(&quot;This book is awesome.&quot;)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>运行上面的代码，会先下载默认的模型，在加载模型的时候，可能会因为缺少库而报错，我们只需要安装对应的库即可，模型下载好以后就会对我们输入的句子进行情感分析，结果如下：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span>[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998772144317627}]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>这个结果表明这是一个正向的句子，概率为0.999877。</p><p>如果我们希望执行的任务官方并没有对应的默认模型提供，我们可以去官网上按照下面的流程自己寻找合适的模型，然后在代码中明确使用某个模型即可。</p><p>首先我们打开 Hugging Face 官网，点击导航栏中的 Models 进入模型页面：</p><p>页面主要分为三个部分，左侧是过滤项列表，分不同的维度列出了许多过滤项，点击即可进行过滤；右侧顶部是搜索框，可以根据名字搜索模型；下方是模型列表，不带前缀的是官方模型，例如 gpt2，带前缀的是第三方提供的模型，例如 microsoft/layoutlmv3-base。</p><p>我们通过过滤或者搜索找到我们所需模型后，点击进入模型详情页面，如下图：</p><p>页面最上方是模型名字，往下一点便是模型的标签，主体部分，靠左的是模型的详细说明，右侧是一些关联信息，如果模型的API托管在 Hugging Face上，就会出现框柱的部分，我们可以在这里进行模型效果的体验。假设我们想试试 distilgpt2 模型生成文本的效果如何，我们可以使用如下代码：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span>from transformers import pipeline</span></span>
<span class="line"><span></span></span>
<span class="line"><span>generator = pipeline(&quot;text-generation&quot;, model=&quot;gpt2&quot;)</span></span>
<span class="line"><span>generator( &quot;The book is awsome and&quot;, max_length=30, num_return_sequences=2)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>稍等片刻即可获得运行结果，是两句根据我提供句子的开头自动生成的完整话语。</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span>[{&#39;generated_text&#39;: &#39;The book is awsome and beautiful, I love it. I love how this story follows everyone from the protagonist of this book with her family to his&#39;}, {&#39;generated_text&#39;: &quot;The book is awsome and fascinating. I&#39;m sure you&#39;re already familiar with the way things turn out after reading one of its pages of novels.&quot;}]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>这只是 Hugging Face 的简单用法，他还有很多很厉害的功能，我们可以通过网站的 Spaces 菜单进入 Space 页面进行体验，也可以按照官方文档进行更深入的研究。</p><p>除此之外，国内也开始建设类似的 MaaS 网站，比如：<a href="https://modelscope.cn/" target="_blank" rel="noreferrer">https://modelscope.cn/</a></p><h2 id="国内语言模型社区" tabindex="-1">国内语言模型社区 <a class="header-anchor" href="#国内语言模型社区" aria-label="Permalink to &quot;国内语言模型社区&quot;">​</a></h2><p>阿里魔塔社区：<a href="https://modelscope.cn/home" target="_blank" rel="noreferrer">首页 · 魔搭社区 (modelscope.cn)</a></p><p>华为盘古社区：<a href="https://www.huaweicloud.com/product/pangu.html?utm_source=baidu&amp;utm_medium=se-cpc-op&amp;utm_campaign=&amp;utm_content=&amp;utm_term=%E7%9B%98%E5%8F%A4%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_adplace=AdPlace082471" target="_blank" rel="noreferrer">盘古大模型_panguLM_大模型_华为云 (huaweicloud.com)</a></p><p>百度飞桨平台：<a href="https://aistudio.baidu.com/aistudio/modelsoverview?lang=zh_CN" target="_blank" rel="noreferrer">飞桨AI Studio - 人工智能学习与实训社区 (baidu.com)</a></p>`,37),t=[r];function i(o,l,c,g,u,d){return n(),e("div",null,t)}const b=a(p,[["render",i]]);export{m as __pageData,b as default};
