import{_ as a,c as e,o as p,a4 as s}from"./chunks/framework.DBIahkuf.js";const h=JSON.parse('{"title":"AI音频提取和识别","description":"","frontmatter":{},"headers":[],"relativePath":"Document/各行业AI工具集/AI音频相关/AI音频提取和识别.md","filePath":"Document/各行业AI工具集/AI音频相关/AI音频提取和识别.md","lastUpdated":1708941732000}'),r={name:"Document/各行业AI工具集/AI音频相关/AI音频提取和识别.md"},t=s(`<h1 id="ai音频提取和识别" tabindex="-1">AI音频提取和识别 <a class="header-anchor" href="#ai音频提取和识别" aria-label="Permalink to &quot;AI音频提取和识别&quot;">​</a></h1><h3 id="语音-视频合成" tabindex="-1">语音/视频合成 <a class="header-anchor" href="#语音-视频合成" aria-label="Permalink to &quot;语音/视频合成&quot;">​</a></h3><ul><li><a href="https://murf.ai/" target="_blank" rel="noreferrer">Murf AI</a></li><li><a href="https://www.resemble.ai/" target="_blank" rel="noreferrer">Resemble AI</a></li><li><a href="https://www.synthesia.io/" target="_blank" rel="noreferrer">Synthesia</a></li><li><a href="https://podcast.adobe.com/" target="_blank" rel="noreferrer">Adobe Podcast</a></li></ul><h2 id="🤖-meta推出开源模型「seamlessm4t」-能翻译和转录近百种语言" tabindex="-1">🤖 Meta推出开源模型「SeamlessM4T」，能翻译和转录近百种语言 <a class="header-anchor" href="#🤖-meta推出开源模型「seamlessm4t」-能翻译和转录近百种语言" aria-label="Permalink to &quot;🤖 Meta推出开源模型「SeamlessM4T」，能翻译和转录近百种语言&quot;">​</a></h2><p><a href="https://ai.meta.com/blog/seamless-m4t" target="_blank" rel="noreferrer"><strong>⋙ Meta Blog</strong></a> | <a href="https://github.com/facebookresearch/seamless_communication" target="_blank" rel="noreferrer"><strong>GitHub 模型代码下载</strong></a></p><p>2023年8月22日，Meta 宣布推出人工智能多模态模型「<strong>SeamlessM4T</strong>」，能够直接翻译35种语言的语音和100种语言的文本。SeamlessM4T 的翻译功能很强大，可以完成语音到文本、语音到语音、文本到语音、文本到文本的翻译，并能够自动识别语音，是 Meta 推出通用翻译器的重要一步。</p><p>SeamlessM4T 在翻译基准上的表现要优于 OpenAI 的 Whisper，虽然二者的翻译质量目前都逊色于人类，但差距正在随着模型的优化而不断缩小。</p><p>Demo：<a href="https://seamless.metademolab.com/demo" target="_blank" rel="noreferrer">Seamless Communication Translation Demo (metademolab.com)</a></p><p>秉持其一贯的开源策略，Meta 在开源协议CC BY-NC 4.0下公开发布了 SeamlessM4T，开发人员可以在这个模型的基础上进行开发。同时，Meta 还发布了 SeamlessAlign 的数据集，其博客提到这也是迄今为止最大的开放多模态翻译数据集，覆盖挖掘的语音和文本对齐总计达 270,000 小时 。</p><h2 id="『writeout-ai』使用-openai-的-whisper-api-转录和翻译音频文件" tabindex="-1">『writeout.ai』使用 OpenAI 的 Whisper API 转录和翻译音频文件 <a class="header-anchor" href="#『writeout-ai』使用-openai-的-whisper-api-转录和翻译音频文件" aria-label="Permalink to &quot;『writeout.ai』使用 OpenAI 的 Whisper API 转录和翻译音频文件&quot;">​</a></h2><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/351de51fe20449648a69182f759dd26e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>🌍<a href="https://writeout.ai/" target="_blank" rel="noreferrer"><strong>writeout.ai</strong></a> 是一个免费的转录和翻译网站，<strong>使用最近发布的 OpenAI Whisper API，可以在几秒钟内快速准确地翻译任何音频文件</strong>。</p><p>你只需要上传音频文件，应用程序将使用 Laravel 的队列作业通过 OpenAI Whisper API 进行发送，使用使用新的 OpenAI 聊天 API 进行翻译，并将生成的 VTT 文件分成更小的部分，以适应提示上下文地限制。</p><p>🌍<a href="https://github.com/beyondcode/writeout.ai" target="_blank" rel="noreferrer"><strong>GitHub 存储库</strong></a></p><h2 id="audiogpt" tabindex="-1">AudioGPT <a class="header-anchor" href="#audiogpt" aria-label="Permalink to &quot;AudioGPT&quot;">​</a></h2><p>AudioGPT是针对于语音领域的GPT</p><p>AudioGPT开源地址：<a href="https://github.com/AIGC-Audio/AudioGPT" target="_blank" rel="noreferrer">https://github.com/AIGC-Audio/AudioGPT</a></p><p>如何在自己的电脑上去运行AudioGPT的代码程序，以及如何学会正确运用AudioGPT实现对应的功能</p><p>AudioGPT的使用是需要基于ChatGPT基础的，为什么这么说呢？原因在于需要我们通过使用OpenAI的API key进访问权限的验证，如图为OpenAI key的获取示意图</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fb9c80968b704897baea18a67b5f2d67~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>所以大家如果还没有OpenAI的GPT账号的，自己去申请一下，然后将这个API Key放到这个AudioGPT的输入框中，即可进行运行程序。</p><h3 id="实现搭建模型运行环境" tabindex="-1">实现搭建模型运行环境 <a class="header-anchor" href="#实现搭建模型运行环境" aria-label="Permalink to &quot;实现搭建模型运行环境&quot;">​</a></h3><p>安装requirements文件列表里面的这依赖项，以及怎么实现在我们本地的客户端去运行AudioGPT的程序。</p><p>1.创建运行程序新的conda环境</p><div class="language-ini line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">ini</span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span style="color:#7F848E;font-style:italic;"># create a new environment</span></span>
<span class="line"><span style="color:#98C379;">conda create -n audiogpt </span><span style="color:#C678DD;">python</span><span style="color:#ABB2BF;">=</span><span style="color:#98C379;">3.8</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>2.安装环境运行所需依赖，以及下载模型文件</p><div class="language-bash line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span style="color:#7F848E;font-style:italic;">#  prepare the basic environments</span></span>
<span class="line"><span style="color:#61AFEF;">pip</span><span style="color:#98C379;"> install</span><span style="color:#D19A66;"> -r</span><span style="color:#98C379;"> requirements.txt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;"># download the foundation models you need</span></span>
<span class="line"><span style="color:#61AFEF;">bash</span><span style="color:#98C379;"> download.sh</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>3.导入你的OpenAI Key字符串进入代码文件</p><div class="language-ini line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">ini</span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span style="color:#7F848E;font-style:italic;"># prepare your private openAI private key</span></span>
<span class="line"><span style="color:#98C379;">export </span><span style="color:#C678DD;">OPENAI_API_KEY</span><span style="color:#ABB2BF;">=</span><span style="color:#98C379;">{Your_Private_Openai_Key}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>4.开始运行AudioGPT程序</p><div class="language-css line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">css</span><pre class="shiki one-dark-pro vp-code"><code><span class="line"><span style="color:#C678DD;">python </span><span style="color:#E06C75;">audio-chatgpt</span><span style="color:#D19A66;">.py</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>至此我们可以实际检验AudioGPT的实际功能。</p><p>以上的操作步骤还是似乎还是偏向于极客，可以直接使用Hugging Face社区，调用实际的API接口，使用更加方便。以下是Hugging Face社区的代码地址：<a href="https://huggingface.co/spaces/AIGC-Audio/AudioGPT" target="_blank" rel="noreferrer">https://huggingface.co/spaces/AIGC-Audio/AudioGPT</a></p><p>AudioGPT效果如下图所示：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a3f30da68d64e4a95b6c0df327344ef~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><h3 id="实践环节演示" tabindex="-1">实践环节演示 <a class="header-anchor" href="#实践环节演示" aria-label="Permalink to &quot;实践环节演示&quot;">​</a></h3><p>AudioGPT包括以下几种功能，由于AudioGPT的模型属于语音音频方向的大模型。其功能包括以下的内容分类。</p><p>第一、实现根据输入文本转换为语音文件的语音合成</p><p>例如：生成带有文本“here we go”的语音音频</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ec620b8733ea47989b812931239daa7a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>第二、实现将单通道语音转换为双通道语音</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4ae0cde387543e7b0b02c151a894322~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>第三、根据语言的文本描述生成对应语音</p><p>例如：生成狗叫声的音频：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d79aa8f092ca4bd292bb4e97abbaf2bc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>第四，根据音频输出指定文字的描述</p><p>例如：给我这个生成音频的描述</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ca4daef5a12642c89cc46145951d8c81~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>第五、根据输入语音信号转换输出其对应的频谱图</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/77be793ccc7a4d2a87b56dfbd56c749d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>第六、说明音频内部所包含的事件以及起止时间</p><p>例如：这段音频中的雷声是什么时候发生的？</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd77b0b21cd14a92ba866f2aea967e7d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>不仅如此，AudioGPT也集成了图像识别的功能，根据图片输入的上传图片生成对应的内容描述音频</p><p>例如：上传下图的江南水乡的图片</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c2d9afcd23f74766938ce011e4b104c5~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>然后通过江南水乡的图片，生成的雨水声音</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b8ccec5373ef4fa9b1966380cac6a6ee~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>怎么样感觉效果如何？不过其实告诉大家一个秘密，音频信号的处理，相对来说，比较占用内存，处理音频的时间较长，可以选择不同的加速硬件GPU，如下图所示</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d786f41a3092475c9235f0fb14286b8e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>原始使用的T4显卡是免费的，其实理论上计算性能也还不错，免费的，还要啥自行车!</p><p>不过如果有更多的需要，当然也可以按需购买。</p><h2 id="相关网站工具" tabindex="-1">相关网站工具 <a class="header-anchor" href="#相关网站工具" aria-label="Permalink to &quot;相关网站工具&quot;">​</a></h2><p>付费：</p><p>Lalal.ai：人声和伴奏分离</p><p><a href="https://www.lalal.ai/zh-hans/" target="_blank" rel="noreferrer">https://www.lalal.ai/zh-hans/</a></p><p>免费：</p><p>motionface：</p><h2 id="whisper语音识别和提取" tabindex="-1">whisper语音识别和提取 <a class="header-anchor" href="#whisper语音识别和提取" aria-label="Permalink to &quot;whisper语音识别和提取&quot;">​</a></h2><p>【whisper.cpp最详细安装教程 | 免费开源语音识别项目 | 可以做实时语音识别】<a href="https://www.bilibili.com/video/BV19L411v7cq?vd_source=36c9491a7fa2ab8a22ca060af01b7472" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV19L411v7cq?vd_source=36c9491a7fa2ab8a22ca060af01b7472</a></p><p>whisper.cpp最详细安装教程 | 免费开源语音识别项目 | 可以做实时语音识别</p><p>服务器：<a href="https://www.vultr.com/?ref=8685401" target="_blank" rel="noreferrer">https://www.vultr.com/?ref=8685401</a></p><p>博客：<a href="https://blog.lukeewin.top" target="_blank" rel="noreferrer">https://blog.lukeewin.top</a></p><p>开源地址：<a href="https://github.com/openai/whisper" target="_blank" rel="noreferrer">openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision (github.com)</a></p><p>模型训练：<a href="https://juejin.cn/post/7249286405024432185" target="_blank" rel="noreferrer">使用 Transformers 为多语种语音识别任务微调 Whisper 模型 - 掘金 (juejin.cn)</a></p><p>whisper是一种通用语音识别模型。它是在各种音频的大型数据集上进行训练的，也是一个多任务模型，可以执行多语言语音识别、语音翻译和语言识别。</p><h2 id="「通义听悟」开放公测-基于音视频内容的ai效率工具" tabindex="-1">「通义听悟」开放公测，基于音视频内容的AI效率工具 <a class="header-anchor" href="#「通义听悟」开放公测-基于音视频内容的ai效率工具" aria-label="Permalink to &quot;「通义听悟」开放公测，基于音视频内容的AI效率工具&quot;">​</a></h2><p>官网：<a href="https://tingwu.aliyun.com/" target="_blank" rel="noreferrer">通义听悟 - 你的工作学习AI助手 (aliyun.com)</a></p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c0d1b4c3899447c1ba4818f56ed9eb2c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p><strong>通义听悟</strong>是基于「通义千问」大模型的音视频内容效率工具，目前开启公测，注册可免费体验。</p><p><strong>通义听悟</strong>支持实时语音转文字、音视频文件转文字、智能总结、中英互译等功能，可以帮助你实现高效地记录、整理和共享。</p>`,81),n=[t];function o(i,l,c,b,m,u){return p(),e("div",null,n)}const f=a(r,[["render",o]]);export{h as __pageData,f as default};
