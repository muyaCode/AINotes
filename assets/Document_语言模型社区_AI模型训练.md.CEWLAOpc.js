import{_ as e,c as a,o,a4 as t}from"./chunks/framework.DBIahkuf.js";const c="/AINotes/assets/96c7f7e9881049d1b93ee19dbf34d4a0.z9erDUat.png",i="/AINotes/assets/1405f3e9fada4c0cbd545ba4b62f435c.BhikAH0F.png",n="/AINotes/assets/6ee08f5d97c44cfda48ac4f5c06dd126.CEqcfaF_.png",d="/AINotes/assets/97a26abacc0f4ac98bc88b30947f6c22.B__PkElf.png",p="/AINotes/assets/d694dc7225a14d2f95ccc2955b54822d.9b8cYBH_.png",s="/AINotes/assets/db2a87f3791b46c9b1fd28539509f4fb.HOoRuIFE.png",r="/AINotes/assets/e74d2c56fc6747bbb8863c77b1e394a1.Dfhk14cS.png",l="/AINotes/assets/6ff16d6db5c44ec2b610894b29441fca.BCi9YOJS.png",f="/AINotes/assets/0f6cb514b5014918bcff3d95264c2820.DytOK4V4.png",h="/AINotes/assets/e671ded0b3df4f1b9da439969ebc0428.ws9hqYhd.png",g="/AINotes/assets/30b46056942041f29b21196b62ccfa17.DG4k7KRn.png",u="/AINotes/assets/92eb28c434f2484b935985511476eff0.ro4SZNNZ.png",N=JSON.parse('{"title":"AI模型训练","description":"","frontmatter":{},"headers":[],"relativePath":"Document/语言模型社区/AI模型训练.md","filePath":"Document/语言模型社区/AI模型训练.md","lastUpdated":1708941732000}'),b={name:"Document/语言模型社区/AI模型训练.md"},_=t('<h1 id="ai模型训练" tabindex="-1">AI模型训练 <a class="header-anchor" href="#ai模型训练" aria-label="Permalink to &quot;AI模型训练&quot;">​</a></h1><p><a href="https://juejin.cn/post/7261628991055888442" target="_blank" rel="noreferrer">强推！大语言模型『百宝书』，一文缕清所有大模型！ - 掘金 (juejin.cn)</a></p><h2 id="轻松可视化-fine-tuning-训练你的模型" tabindex="-1">轻松可视化 Fine-tuning 训练你的模型 <a class="header-anchor" href="#轻松可视化-fine-tuning-训练你的模型" aria-label="Permalink to &quot;轻松可视化 Fine-tuning 训练你的模型&quot;">​</a></h2><h3 id="fine-tuning-介绍" tabindex="-1">Fine-tuning 介绍 <a class="header-anchor" href="#fine-tuning-介绍" aria-label="Permalink to &quot;Fine-tuning 介绍&quot;">​</a></h3><p>在介绍这个可视化模型训练平台之前，我需要给大家补充点儿 <code>Fine-tuning</code> 的基础知识。</p><p><code>Fine-tuning</code> 意思是 “微调”，即在预训练模型的基础上，进行进一步的微调，从而使得模型达到更好的效果，输出更理想的结果。在这个过程中，通常会使用更小的学习率，从而防止出现 <code>过拟合</code> 的情况。</p><p>我们今天要做的事情，其实就是在基于 <code>GPT-3.5</code> 或 <code>GPT-4</code> 这样强大的模型上，做 <code>Fine-tuning</code>，训练微调出我们想要的语言模型。</p><h3 id="dify-ai-介绍" tabindex="-1">Dify AI 介绍 <a class="header-anchor" href="#dify-ai-介绍" aria-label="Permalink to &quot;Dify AI 介绍&quot;">​</a></h3><p>一个开发者工具，帮你快速生成基于 AI 的应用：<a href="https://dify.ai/" target="_blank" rel="noreferrer">https://dify.ai/</a></p><p><a href="https://docs.dify.ai/v/zh-hans/getting-started/intro-to-dify" target="_blank" rel="noreferrer">Dify</a> 是今天文章的主角，我们正是依靠于该平台强大的能力，搭建出属于我们的语言模型！</p><p>Dify 是一个无代码的 LLM Ops 平台，也是一个可视化、可运营、可改进的 <code>LLM</code> 训练平台，它提供了强大的 <code>LLMOps</code> 能力。此外，它还提供了搭建 <code>Web App</code> 的能力。这些意味着你可以用它快速开发一个专属于你的 <code>ChatGPT</code> 应用，你可以基于此进行训练、微调，直到它变成你喜欢的模样！</p><p>让任何人都可以轻松创建和运营基于 GPT 等大型语言模型的AI应用。</p><blockquote><p>LLMOps（Large Language Model Operations）是一种基于机器学习模型的运维（Operations）实践，是一个涵盖了大型语言模型（如GPT系列）开发、部署、维护和优化 的一整套实践和流程。</p><p>LLMOps 的目标是确保高效、可扩展和安全地使用这些强大的 AI 模型来构建和运行实际应用程序。它涉及到模型训练、部署、监控、更新、安全性和合规性等方面。</p></blockquote><p>模型供应商上新增了一大批国内外知名的开源模型：</p><blockquote><ul><li>凡托管在 Hugging Face 及 Replicate 上的模型，在 Dify 上只需要输入 Hugging Face 、 Replicate 的 API token 和模型名称就可以轻松接入调用 (如Llama2、ChatGLM、百川Baichuan、通义千问-7B 等)</li><li>与国内数家模型厂商达成了友好的上下游合作，讯飞星火、MiniMax、文心一言、通义千问都已在本批次接入</li></ul></blockquote><p>Dify 为用户争取到了讯飞星火和 MiniMax 体验额度，可以通过设置 --&gt; 模型供应商 --&gt; 讯飞星火或 MiniMax 图标处点击【免费获取】：</p><blockquote><ul><li><strong>讯飞星火</strong>：免费领取 300 万 token，需要从 Dify 的入口进入，完成讯飞星火开放平台的注册，返回 Dify 静候 5 分钟即可在 Dify 页面体现可用额度（仅限未注册过讯飞星火的手机号）</li><li><strong>MiniMax</strong>：免费领取 100 万 token，只需点击【免费领取】即可到账额度，无需手动注册流程 <a href="https://mp.weixin.qq.com/s/uIdCnP1iVgnknjEUixKXdA" target="_blank" rel="noreferrer"><strong>⋙ 了解更多</strong></a></li></ul></blockquote><h3 id="dify-快速开始" tabindex="-1">Dify 快速开始 <a class="header-anchor" href="#dify-快速开始" aria-label="Permalink to &quot;Dify 快速开始&quot;">​</a></h3><p>今天，咱们就借助于 Dify 强大的能力，动手训练一个模型！</p><p>我们的目的就是想让训练出来的语言模型所输出的内容，均符合我们的预期，并且它不会胡编乱造，捏造事实。</p><h4 id="注册-dify-创建应用" tabindex="-1">注册 Dify &amp; 创建应用 <a class="header-anchor" href="#注册-dify-创建应用" aria-label="Permalink to &quot;注册 Dify &amp; 创建应用&quot;">​</a></h4><p>进入 <a href="https://dify.ai/" target="_blank" rel="noreferrer">Dify</a> 官方页面，注册并填写 API Key 后，点击创建应用。</p><p><img src="'+c+'" alt="image.png"></p><p>接着，我们为即将诞生的模型，起一个炫酷的名字 <code>真IKun</code>，给它设置一个贴切的头像，并选择应用类型为 <code>对话型应用</code>。</p><ul><li>之前我们做的 <code>IKun</code> 上下文信息太少，数据量不够，导致其只能回答有限的问题，远远达不到 <code>真</code> 的程度。</li></ul><p><img src="'+i+'" alt="image.png"></p><p>点击创建后，我们便可以得到如下界面：</p><p><img src="'+n+'" alt="image.png"></p><p>如果我们要求不高的话，其实现在就已经得到了一个普通的 <code>ChatGPT</code> 应用啦，我们可以与它进行基本的 <code>GPT</code> 对话。但我们又怎么满足于此呢？速速进入下一步 - <code>Fine-tuning</code>！</p><h4 id="提示词编排" tabindex="-1">提示词编排 <a class="header-anchor" href="#提示词编排" aria-label="Permalink to &quot;提示词编排&quot;">​</a></h4><p>大家进入界面后，可以看到左边侧边栏有 <code>提示词编排</code> 按钮，我们在这里可以输入对话前的提示词，从而一定程度上调整模型的输出内容。如下图所示：</p><p><img src="'+d+'" alt="image.png"></p><p>在这里，我将 <code>IKun</code> 的基本素养作为提示词传输给语言模型，并依次点击 <code>确认</code> 与 <code>发布</code> 按钮。接下来，让我们测试一下，它能否达到我们预期的效果！</p><p><img src="'+p+'" alt="image.png"></p><p>它确实理解了我们输入给它的上下文，并且能够根据问题，输出相对理想的内容。但如果 Dify 真的只是这样，那么它并没有多么强大，因为在 OpenAI 提供的接口中，我们通过设置上下文参数，也可以实现这样的效果（详情请参考 <a href="https://juejin.cn/column/7244174817679425591" target="_blank" rel="noreferrer">GPT Terminal 专栏</a>）。接下来，让我们看看 <code>Dify</code> 真正强大的地方。</p><h4 id="构建并填充数据集" tabindex="-1">构建并填充数据集 <a class="header-anchor" href="#构建并填充数据集" aria-label="Permalink to &quot;构建并填充数据集&quot;">​</a></h4><p>我们点击导航栏的 <code>数据集</code> 按钮，并点击 <code>创建数据集</code> 按钮，开始创建。</p><p><img src="'+s+'" alt="image.png"></p><p>我们可以看到，需要通过导入已有的文本内容，创建我们自己的数据集。</p><p><img src="'+r+'" alt="iShot2023-06-23 21.31.18.png"></p><p>这些数据其实还是比较容易获取啦，我们可以准备两个文件：关于🐔哥的个人资料（从 <code>某基百科</code> 或 <code>某度百科</code> 中获取）、🐔哥的梗（从 <code>某乎</code>、<code>某音</code> 中获取）</p><p><img src="'+l+'" alt="iShot2023-06-23 21.40.24.png"></p><p>接着，我们进入下一步 - <code>文本分段与清洗</code>。</p><p><img src="'+f+'" alt="image.png"></p><p>保留默认选项，直接点击 <code>保存并处理</code> 进入下一步即可。</p><p><img src="'+h+'" alt="iShot2023-06-23 21.43.54.png"></p><p>大功告成！接下来咱们去填充数据集！</p><p>返回到之前构建应用的界面，点击上下文的 <code>添加</code> 按钮，将我们的数据集导入，并点击 <code>发布</code> 按钮，生成新的模型。</p><p><img src="'+g+'" alt="iShot2023-06-23 21.46.51.png"></p><h4 id="效果展示" tabindex="-1">效果展示 <a class="header-anchor" href="#效果展示" aria-label="Permalink to &quot;效果展示&quot;">​</a></h4><p><img src="'+u+'" alt="iShot2023-06-23 22.08.48.png"></p><p>最后生成的 <code>IKun</code> 似乎能够回答一些问题，但是感觉没有那么活灵活现，没有达到资深 <code>小黑子</code> 的程度。可能是我们的数据集还是太少，也可能是咱们的 <code>梗文化</code> 太深奥啦，语言模型难以理解。不过当我们 Feed 的数据量越来越大、越来越精确时，相信它一定可以达到我们想要的效果！</p><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h3><p>今天通过借助于 <code>Dify</code> 平台，我们体验了一把自己训练模型是什么感觉！虽然它还没有达到真正能够理解语言文化的程度，但是随着 <code>LLM</code> 的发展，这一功能一定可以在不远的将来实现。</p>',54),m=[_];function I(A,k,y,q,D,P){return o(),a("div",null,m)}const L=e(b,[["render",I]]);export{N as __pageData,L as default};
