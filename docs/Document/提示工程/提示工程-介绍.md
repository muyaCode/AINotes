# 提示工程-介绍

## 教程

[如何成为提示工程的高手：2023年最全的在线指南 - 飞书云文档 (feishu.cn)](https://esouqpttmy.feishu.cn/docx/HFPPdJ8TborlQjxtkBFcXIVTnae)

[‌⁤‌‍‍⁡﻿⁤‬﻿‬⁢﻿﻿⁢‬‬⁣⁡﻿‬‍‬‌⁤⁡⁣‍⁤‍‍‬‬‌⁡⁢‍‌﻿‬‌你是一个导演，把chatgpt当成演员定角色 - 飞书云文档 (feishu.cn)](https://d16rg8unadx.feishu.cn/docx/GKEQdbUP4oG8szxzyoPc2jlmn8c)

吴恩达联合官方教程：[ChatGPT Prompt Engineering for Developers - DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)

## 前言

随着ChatGPT的大火，提示工程在大模型中的重要性不言而喻，本文参考国外[Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)完成国内中文版本的《提示工程指南》，希望能够和大家一起交流，分享及发现提示工程的美妙之处。文章所有内容可以在[ChatGPT_Prompt_Chinese](https://github.com/shawshany/ChatGPT_Project/tree/main/ChatGPT_Prompt_Chinese) 中找到。

---

## 一、引言

提示工程学是一门相对较新的学科，用于开发和优化提示，以便高效地利用语言模型（LM）来进行各种应用和研究主题。提示工程技能有助于更好地了解大型语言模型（LLM）的能力和限制。研究人员使用提示工程来改善LLM在各种常见和复杂任务上的能力，例如问答和算术推理。开发人员使用提示工程来设计与LLM和其他工具接口的强大和有效的提示技术。

本指南介绍标准提示的基础知识，以提供如何使用提示与指导大型语言模型（LLM）进行交互和指导的大致概念。

除非另有说明，否则所有示例均使用`chatgpt`进行测试，所以输出内容和国外版本的文档有些出入。[Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)的测试环境是`text-davinci-003`（使用OpenAI的playground进行测试）。它使用默认配置，例如`temperature=0.7`和`top-p=1`。

---

## 二、基本提示

您已经可以通过提示实现很多功能，但结果的质量取决于您提供的信息量。提示可以包含信息，例如您传递给模型的指令或问题，以及包括其他细节，例如输入或示例。

以下是一个简单提示的基本示例：

*Prompt*：
> `天空是`

*Output*：
> `天空是什么？`

正如您所看到的，语言模型根据 `“天空是”` 的上下文输出了一个问句。输出可能会出乎意料，或者远离我们想要实现的任务。

这个基本示例也突出了提供更多关于我们具体想要实现什么任务的上下文或说明的必要性。

让我们试着改进一下：

*Prompt*:

> 完成句子：
> `天空是`

*Output*:

> `天空是一种美丽的自然景观，展现着无限的宽广和深邃。`

这样是不是更好了？我们告诉模型完成句子，因此结果看起来好多了，它恰好遵循了我们告诉它要做的（“完成句子”）。这种设计最佳提示以指导模型执行任务的方法被称为**提示工程**。

以上示例是当前语言模型可能的基本示例。当前的语言模型能够执行各种高级任务，从文本摘要到数学推理再到代码生成等等。

---

## 三、LLM设置说明

`说明：这部分内容主要是针对davinci-003环境，本文演示的chatgpt已经是一个较成熟的产品了，因为不具备超参调节的功能`

在使用提示时，您将通过API或直接与LLM进行交互。您可以配置一些参数以获得不同的提示结果。

- **Temperature**- 简而言之，温度越低，结果越确定，即始终选择最可能的下一个标记。增加温度可能会导致更多的随机性，从而鼓励更多多样化或创造性的输出。我们基本上是增加了其他可能标记的权重。在应用方面，我们可能希望在基于事实的问答（QA）中使用较低的温度，以鼓励更多基于事实和简洁的回答。对于诗歌生成或其他创意任务，增加温度可能会有所好处。

- **Top_p** - 同样，通过top_p进行采样，使用称为核采样的温度采样技术，您可以控制模型在生成响应时的确定性。如果您正在寻找准确和真实的答案，请保持较低。如果您希望获得更多样化的响应，请增加到较高的值。

一般建议是只更改其中一个参数而不是两个都更改。

在开始一些基本示例之前，请记住，您的结果可能会因您使用的LLM版本而有所不同。

---

## 四、标准提示

我们尝试了一个非常简单的提示。标准提示的格式如下：

> \<Question>?

这可以转换成QA格式，这在许多QA数据集中是标准格式，如下所示：

> Q： \<Question>?
> A：

鉴于上述标准格式，一种流行且有效的提示技术被称为**Few-shot**提示，其中我们提供示例。**Few-shot**提示的格式如下：
> \<Question>?
> \<Answer>
> \
> \<Question>?
> \<Answer>
>
>\
> \<Question>?
> \<Answer>
> \
> \<Question>?

你已经猜到了，其QA格式的版本如下所示：

> Q: \<Question>?
> A: \<Answer>
>\
> Q: \<Question>?
> A: \<Answer>
>\
> Q: \<Question>?
> A: \<Answer>
>\
>Q: \<Question>?
> A:

请注意，我们在实际场景中并不一定需要使用QA格式。具体的格式取决于手头的任务。例如，您可以执行一个简单的分类任务，并给出演示该任务的实例，如下所示：

*Prompt*：

> 这很棒！// 积极
> 这很糟糕！// 消极
> 哇，那部电影太棒了！// 积极
> 多么可怕的节目啊！//

*Output*：
> 多么可怕的节目啊！// 消极

Few-shot提示使得在上下文学习中成为可能，即语言模型仅通过少量的示例就可以学习任务。我们将在即将发布的指南中看到更多这方面的内容。

---

## 五、提示的组成要素

随着我们越来越多地涉及提示工程的例子和应用，您会注意到组成提示的某些要素。

提示可以包含以下任何组成部分：

**指令** - 您想让模型执行的具体任务或指令

**上下文** - 可以涉及外部信息或附加上下文，可以引导模型做出更好的响应

**输入数据** - 是我们有兴趣找到响应的输入或问题

**输出指示** - 表示输出的类型或格式。

并非所有组成部分都是提示所必需的，格式取决于手头的任务。我们将在后面发布的指南中涉及更多具体的示例。

---

## 六、设计提示的通用技巧

以下是在设计提示时应牢记的一些技巧：

### 从简单开始

当您开始设计提示时，应牢记这是一个迭代的过程，需要大量的试验才能获得最佳结果。使用像OpenAI或Cohere这样的简单实验场所是一个很好的起点。

您可以从简单的提示开始，随着您的目标越来越明确，逐渐添加更多的元素和背景。在这个过程中进行版本控制非常重要。在我们阅读本指南时，您会看到许多例子表明，明确、简洁和精确通常会给您带来更好的结果。

当您有一个涉及许多不同子任务的大型任务时，可以尝试将任务分解为更简单的子任务，并随着您获得更好的结果而逐步构建。这避免了在提示设计过程中添加过多的复杂性。

### 指令

通过使用指令来指导模型进行各种简单任务的设计，例如“写入”、“分类”、“总结”、“翻译”、“排序”等。

请记住，您还需要进行大量的实验，以查看哪种方法最有效。尝试使用不同的指令、关键字、上下文和数据，看看什么对您的特定用例和任务最有效。通常，上下文对于您尝试执行的任务越具体和相关，效果越好。我们将在即将推出的指南中介绍采样和添加更多上下文的重要性。

其他人建议将指令放在提示的开头。建议使用一些清晰的分隔符，如“###”，来分隔指令和上下文。

例如：

*Prompt*:
> ###指令###
> 将下面的文本翻译成西班牙语：
> 文本：“嗨！”

*Output*：
> Texto: "¡Hola!"

### 具体性

在指示和任务上要非常具体。提示越详细，结果就越好。当您需要特定的输出或生成风格时，这一点尤其重要。并不存在能够导致更好结果的特定标记或关键字。拥有良好的格式和描述性的提示更加重要。实际上，在提示中提供示例非常有效，这样可以获得特定格式的所需输出。

设计提示时，您还应牢记提示的长度，因为长度存在一定的限制。需要考虑具体和详细的程度。并不是无用细节越多越好，而是应当与任务有关并有助于完成任务的相关细节越多越好。这是需要进行大量实验和迭代以优化应用程序的提示的一个方面。

例如，让我们尝试从一段文本中提取特定信息的简单提示。

*Prompt*：

> 提取以下文本中的地名。
> \
> 期望格式：
> \
> 地点: <comma_separated_list_of_company_names>
> \
> 输入：“尽管这些发展令研究人员感到鼓舞，但仍有很多谜团。“我们经常在大脑和我们在外围看到的效果之间有一个黑匣子，”里斯本尚帕利莫未知中心的神经免疫学家恩里克·维加-费尔南德斯说。“如果我们想在治疗环境中使用它，我们实际上需要了解其机制。”

*Output*:

> 地点: 里斯本尚帕利莫未知中心

输入文本取自[Nature文章](https://www.nature.com/articles/d41586-023-00509-z)。

### 避免不准确性

根据上述关于详细说明和改善格式的提示，很容易陷入想要变得过于聪明的陷阱，从而可能创建不精确的描述，因此直接和具体的描述往往更好。这里的类比与有效沟通非常相似--越直接，信息就越能有效传达。

例如，您可能有兴趣了解提示工程的概念。您可以尝试像这样的东西：

> 解释提示工程的概念。保持解释简短，只有几句话，不要过于描述。

从上面的提示中无法清楚地了解使用多少句话以及采用什么样的风格。您可能仍然可以获得良好的响应，但更好的提示是非常具体，简明扼要和直截了当的。例如：

> 用2-3个句子向高中生解释提示工程的概念。

### 做还是不做？

设计提示的另一个常见技巧是避免说明不要做什么，而是说明要做什么。这鼓励更具体化和更专注于细节，从而获得模型的良好响应。

以下是电影推荐聊天机器人的示例，因为我的指令的表述方式而未能成功做到我不想做的事情 - 焦点在于避免做什么。

*Prompt*：

> 以下是向客户推荐电影的代理。不要询问兴趣。不要询问个人信息。
> 客户：请根据我的兴趣推荐电影。
> 代理：

*Output*：

> 代理：
> 非常感谢您的请求。以下是我们为您推荐的一些电影：
>
> 1. 头号玩家 (Ready Player One)
> 2. 盗梦空间 (Inception)
> 3. 阿凡达 (Avatar)
> 4. 星际穿越 (Interstellar)
> 5. 风云雄霸天下 (The Godfather)
> 6. 我们希望您会喜欢其中的某一部电影。

可能ChatGPT相比于davinci-3做了些优化，使得回答更加准确了。。。。

这是一个更好的提示：

*Prompt*：

> 以下是向客户推荐电影的代理。代理负责从全球流行电影中推荐电影。
> 它应该避免询问用户的偏好并避免询问个人信息。如果代理没有电影推
> 荐，它应该回答“很抱歉，今天找不到电影推荐。”
> 客户：请根据我的兴趣推荐电影。
> 代理：

*Output*：

> 很抱歉，我没有关于您的兴趣的信息。然而，这是目前全球流行电影列表：[电影列表]。希望您能找到自己喜欢的电影！
>上面的一些示例摘自“使用OpenAI API进行提示工程的最佳实践”文章。

---

## 总结

本文主要介绍了提示工程的一些基本示例，下一章会介绍一些基本的提示。
