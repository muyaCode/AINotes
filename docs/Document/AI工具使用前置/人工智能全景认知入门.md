# 人工智能全景认知入门

## 背景

几个月前，chatGPT 刚出来的时候，就知道它会掀起一波热潮，但没想到会这么猛烈，席卷美国和中国互联网基本所有的公司。

有人可能会问，chatGPT 不就是一个聊天机器人吗？而且回答问题还不完美，有那么夸张吗？值得所有人这么重视吗？chatGPT 远不止一个聊天机器人，它使得人类离AGI（通用人工智能）迈进了一大步，很多领域和行业都会被彻底颠覆。目前国内各大厂都在争先恐后推出自己的“chatGPT”。

目前我每天基本慢慢脱离了 baidu 搜索、google 搜索 等等(减少了很大频率)，因为它们都不够精准，只能做一些模糊匹配，甚至还带一堆广告，让我在“茫茫人海寻找对的那个人”，属实有点难，现在有啥问题基本都是去找 chatGPT 了......

人工智能已经开始疯狂渗透我的生活了......那么我们对人工智能的全景认知：从入门开始......

## AIGC

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ebd33d84e2664c3bb31c4ce7fcc5dfb5~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

AIGC 即 AI Generated Content，是指利用人工智能技术来生成内容，AIGC 也被认为是继 [UGC](https://baike.baidu.com/item/UGC/66502%3FfromModule%3Dlemma_inlink)、[PGC](https://baike.baidu.com/item/PGC/16859378%3FfromModule%3Dlemma_inlink) 之后的新型内容生产方式，AI 绘画、AI 写作等都属于 AIGC 的分支。对 AIGC 来说，2022 年被认为是其发展速度惊人的一年。

大家近几个月也是接触了大量的 AIGC 相关的内容，但是很多人对其中的一些内容仍然缺乏了解，接下来我们就从入门开始......

## 🤖 『万字长文，大模型训练避坑指南』想训大模型？这里有一份避坑指南

作者 AI 领域投资人 @Kiwi 与3位AI工程师与PM一起，**分别就算力、算法、工程、数据和团队等方向，从实用角度讨论了训练一个千亿参数量级的大语言模型和ChatGPT需要些什么**，希望能够给正在尝试拥抱大模型的业务决策者和技术人员一些有价值的参考。

> **Part 1：当我们讨论大模型时其实是在讨论什么**
>
> **Part 2：大模型是如何炼成的？**
>
> - 2-1：想训大模型？这里有一张入场费账单
> - 2-2：如何训练大模型效率会更高？
> - 2-3：训练中文大语言模型，你的数据够用吗？
> - 2-4：训出大模型，人海战术可能并不好使
>
> **Part 3：One More Thing，嘉宾的互问互答**
>
> - Q：会出现训练 Transformer 的专用框架吗？
> - Q：从投资人视角看来，为什么每家都要训出ChatGPT，这合乎逻辑吗？
> - Q：ChatGPT 会一统天下吗？

**我们相信千亿参数的大语言模型并不是终点，而只是AI浪潮中的第一步，开放的分享和讨论才能加速整个生态的发展和落地。**

> 点击 🌍[**原文**](https://mp.weixin.qq.com/s/yX5B1ZzV7vewQs1-ezHIQg) 查看精彩问答，也可以收听播客。

## chatGPT 和 GPT3 有何区别?

我们可能有些许疑问，比如：GPT3 和 chatGPT 都是 OpenAl 开发的语言模型，那它们之间有什么区别呢?

### 什么是 chatGPT?

ChatGPT 是一种**更小、更专业的语言模型**，专为聊天应用程序设计。它基于相同的 GPT-3 技术构建，但已经过微调以处理会话语言的特定挑战，例如理解上下文、识别意图和提供适当的响应。与通用语言模型 GPT-3 不同，chatGPT 专注于**提供自然且引人入胜的对话体验**。

ChatGPT 具有几个关键特性和功能，使其成为 NLP 任务的强大语言模型。其中一些包括：

- **类人响应**：ChatGPT 经过训练可以生成类似于人类在特定情况下的响应方式的响应。这使它能够与用户进行自然的类似人类的对话。
- **上下文感知**：ChatGPT 能够维护上下文并跟踪对话的流程，即使在复杂或多轮对话中也能提供适当的响应。
- **大训练数据**：ChatGPT 在大量文本数据上进行训练，这使其能够学习广泛的语言模式和风格。这使得它能够产生多样化和细微的反应。

### 什么是 GPT-3?

GPT-3 是 OpenAl 的第三代 GPT 系列模型。它是有史以来**最大、最强大的语言模型之一**，拥有 1750 亿个参数，GPT-3 **旨在执行各种语言处理任务**，包括语言翻译摘要和文本生成。

GPT-3 具有几个关键特性和功能，包括可用于广泛的语言相关任务，包括翻译、摘要和文本生成，这使其成为可应用于各种应用的多功能模型。

### chatGPT 和 GPT-3 的区别是什么?

GPT-3 和 chatGPT 之间的主要区别在于它们的**范围和目的**。

- GPT-3 是一种大型通用语言模型，可以处理各种语言处理任务。
- 另一方面，ChatGPT 是一个较小的专用模型，专为聊天应用程序设计。虽然这两种模型都基于相同的底层技术，但 chatGPT 是根据会话语言处理的特定需求量身定制的。

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/df7cd7420bc84673bafad8fe5e73e280~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

## Stable Diffusion 和 Midjourney 的区别?

### 什么是 Stable Diffusion?

Stable Diffusion 是一个**文转图的模型**，其使用了 CLIP ViT-L/14 文本编码器，能够通过文本提示调整模型。它在运行时将成像过程分离成"扩散(diffusion)"的过程--从有噪声的情况开始，逐渐改善图像，直到完全没有噪声，逐步接近所提供的文本描述。

### 什么是 Midjourney?

Midjourney 也是一款由人工智能驱动的工具，其**能够根据用户的提示生成图像**，Midlourney 善于适应实际的艺术风格，创造出用户想要的任何效果组合的图像。它擅长环境效果，特别是幻想和科幻场景，看起来就像游戏的艺术效果。

### Stable Diffusion 和 Midjourney 之间的比较

Midjourney 是一个以其**艺术风格**闻名的工具。

Midjourney 使用其 Discord 机器人来发送以及接收对 AI 服务器的请求，几乎所有的事情都发生在 Discord 上。

由此产生的图像很少看起来像照片，似乎更像一幅画。

Stable Diffusion 是一个开源的模型，人人都可以使用。

它对当代艺术图像有比较好的理解，可以产生**充满细节的艺术作品**。

然而它需要对复杂的 prompt 进行解释。

Stable Diffusion 比较适合生成复杂的、有创意的插图。但在创作一般的图像时就显得存在些许不足。

下面的 prompt 有助于了解每种模型的相似性和差异。

A cartoon cat playing football (一只卡通猫咪踢足球)

> 这个是我作为一只“铲屎官”，看到自家猫咪喜欢玩球之类的，玩的挺好的，有种踢足球的感觉，所以希望有组织能做这么一个主题的动漫！

**Midjourney 效果**：

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0a2cb326c98443c39f98671339998fdd~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

**Stable Diffusion**：

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d6d8ef6b20e248e495dd4b4a8c6af93f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

我们可以看到针对同一句 prompt 生成的图像有较大的差异，Midjourney 的画面充满艺术性，像一幅完整的动漫画作，而 Stable Diffusion 生成的图像更像是一张逗我玩的涂鸦。

不同的 prompt 生成出的图像也有巨大的差别，希望大家，可以继续探索学习驯化模型，运用平台生成更精美的图像。

## 认识 Midjourney 的 Prompt

如何使用 Midjourney 做出更好效果的图片？

Prompt 是 Midjourney 中一个非常重要的概念，它类似于一句指令或灵感，用于指导 AI 生成特定主题或视觉风格的图片。

在 Midjourney 中，用户可以通过输入自定义的 Prompt，让 AI 生成不同的图像。Prompt 不仅仅是文本，还可以使用图片以及各种参数，Midiourney 会使用AI 算法分析并理解输入的信息，所以熟练运用 Prompt 非常重要。

### 简单 Prompt

一个简单的 Prompt 可以只有一串文本，甚至只有一个单词就可以，用来告诉 AI 你想画什么。

比如：漫画 一个电竞少女，带着粉色的耳机，坐在电脑桌前，一台电脑放在桌上，游戏画面，浅灰色的长发，蓬松的头发，可爱，淡淡的腮红，空旷的房间，床上有几盆花朵，丁达尔效应

然后 AI 生成了下面这种风格的的4张图片：

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/366e72b79aab4f8ea83d302eac77473b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

关于 Prompt 的几个 Tips：

1. **描述尽量具体**：如果你有确定的图片需求，描述词尽可能具体，以获得更符合预期的结果，否则出来的效果与你想的可能大相径庭，不过如果你只是想探索一番，可以不用那么具体以获得更丰富多样的图片，有时会出现一些意外和惊喜。
2. **只描述你想要的**：只描述你想要的内容，而不是说你不想要的。
3. **不断尝试和调整**：在使用 Midjourney 时，需要不断尝试不同的Prompt，并根据结果进行调整和优化。可以从颜色、构图、细节、参数等多方面入手，对 Prompt 进行微调，以获得更好的创作效果，几乎不可能一两次就能立即获得满意的图片。

打开 MidJourney 官网，目前已经开放公测，所有用户均可使用

官网：[www.midjourney.com/home](https://www.midjourney.com/home)

## chatGPT 的原理及作用?

大概了解了 chatGPT 的基本理念，它的全称是 Generative Pre-trained Transformer，**生成式预训练转换器**。

简单来说，它的**原理**是：

先给它提供一个**庞大的语料库**(通常是直接从互联网上抓来的)，让模型通过上千亿个参数对这些文本进行打散标记、学习，构建起一个**复杂的预测模型**。

然后再依据这个预测模型，判断一个单词在这个情境下应该接哪一个单词。就这样一个一个单词串起来，形成一段话，或者一篇文章。

这种预测的模式，其实跟我们大脑的学习和加工模式是非常相似的。

因此，这也是它能够更“像人”的一个重要原因。

### 三层模型理解

这个模型背后无需人工参与的“无监督”式预训练自学习原理，或者说让模型像大脑“自由生长"的过程，就是它的**动力层**。

借由这个原理所完成的 GPT-3.5，就是一个**结构层**，是 ChatGPT 起作用的主要基础。

而对这个 GPT-3.5 进行包装、优化所形成的 ChatGPT，就是一个**交互层**，它的本质就是加了一层更友好的用户界面和交互方式，让个人用户能够更容易地应用它。

了解完 ChatGPT 的原理，我们自然会关心一个问题：就目前而言，ChatGPT 究竟能做什么?

### chatGPT的作用

**1.回答问题**：

这可能是 ChatGPT 最简单的应用。你在聊天界面里向它提问，比如“波粒二象性是什么意思”，它就会用流畅的语言向你解释，把这个概念讲解得非常清楚。就我试用的体验而言，效果非常好，简洁晓畅，表达能力胜过许多人。

**2.撰写文章**：

你可以向它提要求，让它按照你的要求撰写一篇文章。例如:

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9283d0836eeb494d8da00cf941359c19~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

**3.撰写邮件**：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0125f22a7d0947ac8de54a24922d7962~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

**4.撰写策划方案**：

你可以给它一个主题，再给一些背景和指引，甚至让它帮你想创意、提供各种不同方向的点子和灵感。

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fb098b75660d40d6ae7ed0be27c3619d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

**5.撰写报告**：

你可以给它一些数据，让它根据这些材料撰写一份报告。等等。

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/882eb5ce7c804d94a94a58ca2cc2a609~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

总之，ChatGPT 具备极强的总结提炼信息的能力，但是 AI 只是帮我们拓展触及信息的能力，处理信息和做出决策的人依然是我们自己。而不是依赖于它给出的解释和答案，让它替代我们去决策和判断。一旦我们放弃了思考，我们作为人类的主体性其实也就不复存在。

## 拓展

除了现在最常见的：

- 内容生产 CoPilot（ChatGPT、Midjourney），

还有：

- 办公 CoPilot（微软 Office CoPilot）、
- 搜索 CoPilot（微软 New bing）、
- 编程 CoPilot（微软 GitHub CoPilot）、
- 教育 CoPilot（可汗学院、Speak、多邻国），
- 以及基于 ChatGPT Plugins 的接入了多个插件的生活服务 CoPilot。

其实还有更多，**万物都可以 +GPT，万物都可以 CoPilot**。

## 感受

人工智能带给我的感受：

一个人的认知，是需要不断的进化的，而进化主要靠和其他人的交流，获取到更多新的信息和他人的认知，然后认真学习吸收，从而迭代自己的认知。

一个人能力提升的速度，基本取决于他能链接到的信息的强度，和自己迭代的速度。

再说直白点，只要你能找到可以学习的牛人，你自己也愿意走出舒适区，愿意持续学习和思考，你就能进步，否则就是停滞不前，甚至被时代淘汰。

AI 进化的原理，其实和人脑是完全一样的，从机器学习，到深度学习，再到现在的pre-train 自监督大模型 + 生成式 AI，AI 越来越逼近人脑的机制。

AI 它也能帮助我们学习成长，帮助我们找学习资料，帮助我们解决疑难问题......就看怎么利用，会用不会用 AI，首先最重要的就是学会精准的表达，把你的需求精准的告诉 AI，它才能更好的帮助你。

## 🤖 构筑大语言模型应用：应用开发与架构设计

教程：[前言 - 构筑大语言模型应用：应用开发与架构设计 (phodal.com)](https://aigc.phodal.com/)

开源地址：[phodal/aigc: 《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍了大语言模型的基础知识和应用，以及如何构建自己的模型。其中包括Prompt的编写、开发和管理，探索最好的大语言模型能带来什么，以及LLM应用开发的模式和架构设计。 (github.com)](https://github.com/phodal/aigc)

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/afdf929da1574b7cb9eb0a50c1d3c0ff~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这是作者团队的优质内容合辑，将过往半年的思考和文章进行了梳理和重新编写，包含**LLM 能力的充分运用**、**LLM 软件开发工序及应用架构设计**、**面向特定场景的 LLM 应用**等主题。以下是内容大纲，感兴趣可以点击阅读原文：

> **🔔 介绍**
>
> *1*. 前言
>
> *2*. 程序员的 AI 2.0 新机遇
>
> **🔔 基础篇**
>
> *3*. 理解 Prompt
>
> *4*. Prompt 编写模式
>
> *5*. 模式：Prompt 即代码

> **🔔 进阶篇**
>
> *▢* **开发工序**
>
> *6*. LLM 应用开发之前
>
> *7*. 模式：精细化流程
>
> *8*. 模式：DSL 驱动开发
>
> *9*. LLM 应用集成模式
>
> *10*. LLM 应用示例：AI + DevOps
>
> *11*. LLM 应用示例：最佳实践示例
>
> *▢* **架构设计**
>
> *12*. LLM 应用架构设计原则
>
> *13*. LLM 应用架构设计：参考架构
>
> *14*. LLM 应用架构：ArchGuard Co-mate
>
> *15*. LLM 应用架构：GitHub Copilot 分析

> **🔔 应用篇**
>
> *▢* **微调 + LLMOps**
>
> *16*. 微调之前的准备
>
> *17*. 微调模式：三阶六步 + LLMOps
>
> *18*. 微调示例集：AI + DevOps
>
> *▢* **训练篇（TBD）**

> **🔔 如何自保**
>
> *19*. LLM 自保
>
> **🔔 名词解释**
>
> *20*. LLM 名词解释

## 大语言模型 (LLM) 学习路径和资料汇总 (工程向)

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ffb205bfb81459091e9b879a69cdf7a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这是 @ninehills 使用优质公开资料 (尽可能选择了中文) 构建的 LLM 学习路径，侧重工程方向，总共分为4个章节。读者可以根据自己需要选择对应的章节。

### 🔔 *1*. **入门篇**

> 了解 LLM 基础知识和常见术语，使用编程语言访问 OpenAI API 等常见大语言模型接口
>
> *▢* **大语言模型综述** ：[github.com/RUCAIBox/LL…](https://github.com/RUCAIBox/LLMSurvey)
>
> *▢* **ChatGPT Prompt Engineering for Developers** ：[learn.deeplearning.ai/chatgpt-pro…](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction)
>
> *▢* **OpenAI Quickstart** ：[platform.openai.com/docs/quicks…](https://platform.openai.com/docs/quickstart)
>
> *▢* **State of GPT**：[www.youtube.com/watch?v=bZQ…](https://www.youtube.com/watch%3Fv%3DbZQun8Y4L2A)

### 🔔 *2*. **提高篇**

> 了解机器学习、神经网络、NLP 的基础知识，了解 Transformer 以及典型 Decoder-only 语言模型的基础结构和简单原理，了解大语言模型发展历史，以及业界主流模型 (含开源模型) 进展
>
> *▢* **清华大模型公开课**：[www.bilibili.com/video/BV1UG…](https://www.bilibili.com/video/BV1UG411p7zv)
>
> *▢* **深度学习：台湾大学李宏毅**：[www.bilibili.com/video/BV1J9…](https://www.bilibili.com/video/BV1J94y1f7u5/)
>
> *▢* **Understanding large language models**：[www.wandb.courses/courses/tak…](https://www.wandb.courses/courses/take/building-llm-powered-apps/lessons/44341580-understanding-large-language-models)
>
> *▢* **The Illustrated GPT-2 (Visualizing Transformer Language Models)** ：[jalammar.github.io/illustrated…](https://jalammar.github.io/illustrated-gpt2/)
>
> *▢* **InstructGPT: Training language models to follow instructions with human feedback**：[cdn.openai.com/papers/Trai…](https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf)
>
> *▢* **Huggingface NLP Course**：[huggingface.co/learn/nlp-c…](https://huggingface.co/learn/nlp-course/chapter1/1)

### 🔔 *3*. **应用篇**

> 可以在本地环境搭建开源模型的推理环境，使用已有框架 (如Langchain) 或自行开发生产应用
>
> *▢* **Building Systems with the ChatGPT API**：[learn.deeplearning.ai/chatgpt-bui…](https://learn.deeplearning.ai/chatgpt-building-system/lesson/1/introduction)
>
> *▢* **Langchain**：[python.langchain.com/](https://python.langchain.com/)
>
> *▢* **GPT best practices**：[platform.openai.com/docs/guides…](https://platform.openai.com/docs/guides/gpt-best-practices/gpt-best-practices)
>
> *▢* **openai-cookbook**：[github.com/openai/open…](https://github.com/openai/openai-cookbook)
>
> *▢* **Brex’s Prompt Engineering Guide**：[github.com/brexhq/prom…](https://github.com/brexhq/prompt-engineering)

### 🔔 *4*. **深入篇**

> 掌握 Continue Pre-train、Fine-tuning 已有开源模型的能力，掌握 Lora、QLora 等低资源高效模型训练的能力，掌握大语言模型微调以及预训练数据准备的能力，深入了解大模型背后的技术原理，了解生产环境部署大模型的相关技术点
>
> *▢* **Huggingface Transformer 文档**：[huggingface.co/docs/transf…](https://huggingface.co/docs/transformers/index)
>
> *▢* **复杂推理：大语言模型的北极星能力**：[yaofu.notion.site/6dafe3f8d11…](https://yaofu.notion.site/6dafe3f8d11445ca9dcf8a2ca1c5b199)
>
> *▢* **GPT，GPT-2，GPT-3 论文精读**：[www.bilibili.com/video/BV1AF…](https://www.bilibili.com/video/BV1AF411b7xQ)
>
> *▢* **Building LLM applications for production**：[huyenchip.com/2023/04/11/…](https://huyenchip.com/2023/04/11/llm-engineering.html) [**⋙ @ninehills**](https://ninehills.tech/articles/97.html)
