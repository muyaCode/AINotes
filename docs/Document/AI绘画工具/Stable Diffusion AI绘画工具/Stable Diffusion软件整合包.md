# Stable Diffusion软件整合包

教程：[2023-03-20-2023最新AI绘画Stable Diffusion，原创不用愁日赚1000+【软件+教程】_免费高速下载|百度网盘-分享无限制 (baidu.com)](https://pan.baidu.com/s/1RmAKpCP0qbltlRfQJ-7AtA?pwd=xkwo#list/path=/)

## 『Stability AI 发布大语言模型StableLM』继SD之后又一大招，剑锋直指GPT-4

4月19日，Stability AI 又开源了大模型 StableLM，与 ChatGPT 类似，是一套文本生成AI模型，可以生成代码、笑话、歌词、故事等内容，旨在与OpenAI的GPT-4等系统竞争。StableLM 的 alpha 版本目前可以在GitHub和Hugging Spaces上获得。

Stability AI 是一家创业公司，之前开发的生成AI艺术工具 Stable Diffusion 刮起了艺术领域的腥风血雨。公司计划在未来几个月内发布更多的StableLM模型，提供更多的应用场景和示例，并与其他开发者和研究者以改进和扩展这些模型，探索它们的潜在用途。

> 注意！ StableLM基础模型可以商用，但必须遵守CC BY-SA-4.0许可证的条款；微调模型是不可以的。 [**官方博客**](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models) | [**GitHub**](https://github.com/stability-AI/stableLM/) | [**HuggingFace**](https://huggingface.co/spaces/stabilityai/stablelm-tuned-alpha-chat)

## Stable Diffusion 电脑配置推荐

[SD推荐电脑配置 (qq.com)](https://docs.qq.com/sheet/DRU9ydUR3TmNWeWdE?tab=BB08J2)

- *▢* 基础配置 / 5500元
- *▢* 进阶配置 / 9000元
- *▢* 性价比配置 / 10000元
- *▢* 高级配置 / 14000元

电脑配置需求

操作系统：windows10以后

CPU：不做强制性要求

内存：推荐8G以上

显卡：必须是Nvidia的独立显卡，显存最低4G，推荐20系以后

A卡核显只能用CPU跑整合包，推荐放在固态硬盘中，提升模型加载速度

**所需配置**：

推荐配置：拥有Nvidia独立显卡、RTX20系以后的显卡。仅生成图片推荐8G显存（4G是最低保障配置）训练推荐大于12G（越大越好）

内存推荐16G及以上。硬盘推荐使用固态硬盘，否则你开软件要等个5-10分钟。

CPU不做太多要求。

A卡能不能用？能，但是性能损耗很大。可以在Linux系统上获得最佳效果，但是由于我本人没有A卡，所以我也不会做相关的教程

## Stable Diffusion软件整合包合集

**开源项目Stable Diffusion WebUI**：

- **Stable Diffusion官方开源库地址**：[CompVis/stable-diffusion: A latent text-to-image diffusion model (github.com)](https://github.com/CompVis/stable-diffusion)
- **Stable Diffusion官方开源项目**：[CompVis - Computer Vision and Learning LMU Munich (github.com)](https://github.com/CompVis)
- **GitHub搜索Stable Diffusion相关**：[Repository search results · GitHub](https://github.com/search?q=Stable+Diffusion&type=repositories&s=stars&o=desc)
- 官方项目并不适合我们这些新手直接使用，好在有一些基于 `stable-diffusion` 封装的 `webui` 开源项目，可以通过界面交互的方式来使用 `stable-diffusion`，极大的降低了使用门槛，以下是几个比较火的 `webui` 项目：
- **Stable Diffusion web UI**：[AUTOMATIC1111/stable-diffusion-webui: Stable Diffusion web UI (github.com)](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- **stable diffusion webui colab**：[camenduru/stable-diffusion-webui-colab: stable diffusion webui colab (github.com)](https://github.com/camenduru/stable-diffusion-webui-colab)
- **基于Stable Diffusion模型的高分辨率图像合成**：[Stability-AI/stablediffusion: High-Resolution Image Synthesis with Latent Diffusion Models (github.com)](https://github.com/Stability-AI/stablediffusion)
- **M1/M2 Mac 上本地运行 Stable Diffusion 的最简单方法**：[divamgupta/diffusionbee-stable-diffusion-ui：Diffusion Bee是在M1 Mac上本地运行Stable Diffusion的最简单方法。无需依赖关系或技术知识。 (github.com)](https://github.com/divamgupta/diffusionbee-stable-diffusion-ui)

**Stable Diffusion WebUI 启动器+整合包  完美支持苹果MAC OS   已经下载webUI的可以一键导入直接使用**：[爱兔(AITools) Stable Diffusion WebUl启动器 (easyartx.com)](https://www.easyartx.com/landing)

**【秋葉aaaki】的Stable Diffusion整合包**：

- **整合包的安装和使用教程**：【【AI绘画】Stable Diffusion整合包v4.2发布！全新加速 解压即用 防爆显存 三分钟入门AI绘画 ☆可更新 ☆训练 ☆汉化】<https://www.bilibili.com/video/BV1iM4y1y7oA?vd_source=36c9491a7fa2ab8a22ca060af01b7472>
- 百度盘：<https://pan.baidu.com/s/1MnyQH_gWgVdxU1S_Hjc5JQ>   提取码 t724
- 夸克盘：<https://pan.quark.cn/s/3a32257a7323>   提取码：284q
- 使用教程和模型：
- 快速开始使用 → <https://www.bilibili.com/read/cv22661198>
- 新手最全教程 → <https://www.bilibili.com/read/cv22159609>
- 4月模型推荐 → <https://www.bilibili.com/video/BV1em4y1z7Dg>
- 5-6月模型推荐 → <https://www.bilibili.com/video/BV1iM4y1y7oA>
- 模型安装使用百科 → <https://www.bilibili.com/read/cv21362202>
- 安装遇到问题可以前往我的爱发电 → <https://afdian.net/a/akibanzu>
- 若启动器更新报毒，属正常现象。Windows Defender日常误报，推荐直接安装一个火绒让wd闭嘴。或者可以添加入信任区
- 【报错解决】
  - 1.遇到报错请前往启动器的 “疑难解答” 页面进行扫描，绝大部分问题都会有解决方法。
  - 2.打开网页报错 `Something went wrong Expecting value: line 1 column 1 (char 0)` 的，把你梯子关了

**剑心一键安装包**：

- 123云盘：<http://mtw.so/61hwF2>（请用pc端打开，下载软件不限速下载）
- 百度网盘：<http://mtw.so/6viaOM>  提取码：8m51
- qq频道：<https://pd.qq.com/s/dsjf0fhhe>

**未知整合包**：<https://pan.baidu.com/s/1RmAKpCP0qbltlRfQJ-7AtA?pwd=xkwo>

出处：[2023最新AI绘画Stable Diffusion，原创不用愁日赚1000+【软件+教程】-小K网 (xkwo.com)](https://www.xkwo.com/article-29679.html)

## 本地运行部署项目：以【秋葉aaaki】的整合包为例

教程：<https://www.bilibili.com/video/BV1fa4y1G71W/>

上面链接下载完后，共有三类文件：

- `sd-webui-aki-v4.2.rar` 压缩包：主程序启动包
- `可选controlnet1.1`文件夹：模型和预处理器
- `启动器运行依赖-dotnet-6.0.11.exe` ：需要先双击这个，安装整合包需要的依赖

1.把`sd-webui-aki-v4.2.rar`压缩包解压

2.然后把 `可选controlnet1.1` 文件夹的 `模型` 文件夹内的模型文件复制到 文件夹：`sd-webui-aki\sd-webui-aki-v4.2\models\ControlNet`

3.再把 `可选controlnet1.1` 文件夹的 `预处理器` 文件夹内的 `downloads` 文件夹复制到 文件夹：`sd-webui-aki\sd-webui-aki-v4.2\extensions\sd-webui-controlnet\annotator`内覆盖

4.启动：双击`sd-webui-aki\sd-webui-aki-v4.2` 内的 `A启动器.exe` 文件启动软件

5.一键启动：点击界面的【一键启动】，会启动一个浏览器实例，便可以开始绘图了

### 绘制第一张图

#### 1.提示词

正向提示词

```text
masterpiece,best quality,
```

反向提示词

```bash
lowres,bad anatomy,bad hands,text,error,missing fingers,extra digit,fewer digits,cropped,worst quality,low quality,normal quality,jpeg artifacts,signature,watermark,username,blurry
```

正向反向提示词，如果要加大提示词比重，(word:1.5) - 将权重提高 1.5 倍

#### 2.采样和迭代步数

![img](https://pic2.zhimg.com/80/v2-b157d72e97e6dfc08489a2f0c23979f1_720w.webp)

- **Sampler（采样器/采样方法）**

  - Euler a（Eular ancestral）可以以较少的步数产生很大的多样性，不同的步数可能有不同的结果。

  - DPM 相关的采样器通常具有不错的效果，但耗时也会相应增加。

  - Euler 是最简单、最快的

  - Euler a 更多样，不同步数可以生产出不同的图片。但是太高步数 (>30) 效果不会更好。

  - DDIM 收敛快，但效率相对较低，因为需要很多 step 才能获得好的结果，适合在重绘时候使用。

  - LMS 是 Euler 的衍生，它们使用一种相关但稍有不同的方法（平均过去的几个步骤以提高准确性）。大概 30 step 可以得到稳定结果

  - PLMS 是 Euler 的衍生，可以更好地处理神经网络结构中的奇异性。

  - DPM2 是一种神奇的方法，它旨在改进 DDIM，减少步骤以获得良好的结果。它需要每一步运行两次去噪，它的速度大约是 DDIM 的两倍，生图效果也非常好。但是如果你在进行调试提示词的实验，这个采样器可能会有点慢了。

  - UniPC 效果较好且速度非常快，对平面、卡通的表现较好，推荐使用。

  - 推荐 Euler a ，DPM2++2M Karras，DPM2++SDE Karras

- **迭代步数**
  - Stable Diffusion 的工作方式是从以随机高斯噪声起步，向符合提示的图像一步步降噪接近。随着步数增多，可以得到对目标更小、更精确的图像。但增加步数也会增加生成图像所需的时间。增加步数的边际收益递减，取决于采样器。一般开到 20~30。

#### 3.修复和图片相关设置

![img](https://pic4.zhimg.com/80/v2-695c8ca254fa6856c8e3d8a6a530d2db_720w.webp)

- **高清修复** 默认情况下，文生图在高分辨率下会生成非常混沌的图像。如果使用高清修复，会型首先按照指定的尺寸生成一张图片，然后通过放大算法将图片分辨率扩大，以实现高清大图效果。最终尺寸为（原分辨率*缩放系数 Upscale by)。
- **面部修复** 修复画面中人物的面部，但是非写实风格的人物开启面部修复可能导致面部崩坏。
- **放大算法中**，Latent 在许多情况下效果不错，但重绘幅度小于 0.5 后就不甚理想。ESRGAN_4x、SwinR 4x 对 0.5 以下的重绘幅度有较好支持。
- **Hires step** 表示在进行这一步时计算的步数。
- **Denoising strength** 字面翻译是降噪强度，表现为最后生成图片对原始输入图像内容的变化程度。该值越高，放大后图像就比放大前图像差别越大。低 denoising 意味着修正原图，高 denoising 就和原图就没有大的相关性了。一般来讲阈值是 0.7 左右，超过 0.7 和原图基本上无关，0.3 以下就是稍微改一些。实际执行中，具体的执行步骤为 Denoising strength * Sampling Steps。
- **CFG Scale（提示词相关性）** 图像与你的提示的匹配程度。增加这个值将导致图像更接近你的提示，但它也在一定程度上降低了图像质量。 可以用更多的采样步骤来抵消。过高的 CFG Scale 体现为粗犷的线条和过锐化的图像。一般开到 7~11。 CFG Scale 与采样器之间的关系：
- **生成批次** 每次生成图像的组数。一次运行生成图像的数量为“批次* 批次数量”。
- **每批数量** 同时生成多少个图像。增加这个值可以提高性能，但也需要更多的显存。大的 Batch Size 需要消耗巨量**显存**。若没有超过 12G 的显存，请保持为 1。
- **尺寸** 指定图像的长宽。出图尺寸太宽时，图中可能会出现多个主体。1024 之上的尺寸可能会出现不理想的结果，推荐使用小尺寸分辨率+高清修复（Hires fix)。
- **种子** 种子决定模型在生成图片时涉及的所有随机性，它初始化了 Diffusion 算法起点的初始值。 理论上，在应用完全相同参数（如 Step、CFG、Seed、prompts）的情况下，生产的图片应当完全相同。

**后续**：[stable diffusion 小白最全详细使用教程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/629493288)

### 街头少女

描述主题如下：一个女孩在街头大笑，湿透的，辫子，写实风格的，电影级别的，HDR的。

- Lora：无
- Embeddings:ng_deepnegative_v1_75t [1a3e]

#### Prompt

> a young woman, street, laughing, ponytails, (hdr:1.3), (muted colors:1.2), dramatic, complex background, cinematic, filmic, (rutkowski, artstation:0.8), soaking wet,

#### Negative Prompt

> (nsfw:2),Multiple people,easynegative,(worst quality:2),(low quality:2),lowres,(monochrome:1.4),(grayscale:1.4),big head,severed legs,short legs,missing legs,acnes,skin blemishes,age spot,backlight,(ugly:1.4),(duplicate:1.4),(morbid:1.2),(mutilated:1.2),mutated hands,(poorly drawn hands:1.4),blurry, (bad anatomy:1.4),(bad proportions:1.4),(disfigured:1.4),(unclear eyes:1.4),bad hands, bad tooth,missing fingers,extra digit,bad body,NG_DeepNegative_V1_75T,glans,EasyNegative:0.5,gross proportions.short arm,(missing arms:1.4),missing thighs,missing calf,mutation,duplicate,morbid,mutilated,poorly drawn cloth,strange finger,bad finger,(mutated hands and fingers:1.4),(text:1.4), bad-artist, bad_prompt_version2, bad-hands-5, bad-image-v2-39000,

#### 基础配置

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/297ad0e3c52c44e18ea5d23826d0c41c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

——————————————————————————————————————
[AI 绘画工具 Stable Diffusion 本地安装使用 - 掘金 (juejin.cn)](https://juejin.cn/post/7246960365736345660)

## 以AUTOMATIC1111/stable-diffusion-webui项目搭建

### 1、下载项目

`stable-diffusion-webui` 没有发布可执行程序（比如：`.exe`），我们需要通过 `git` 的方式将整个工程源码拉下来运行：

```shell
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
```

> 注：这个开源项目目前的更新频率很快，会不定期的修复一些 bug 或加入一些新功能，所以建议可以时常 `git pull` 拉取最新代码。

### 2、Python 环境

`stable-diffusion-webui` 主要是使用 Python 开发的，所以运行这个工程，需要安装一下 Python 环境并配置好环境变量，因为 Python 环境的安装很简单，这里就不多说了，环境配置完成之后，可以通过以下命令查看 Python 的版本号，验证环境是否正常：

```shell
python --version
```

> 注意：官方推荐安装 `Python 3.10.6` 版本

另外，建议使用 `Anaconda` 管理多个 Python 环境，详见

- 官方的 conda 环境安装说明：[Install and Run on NVidia GPUs · AUTOMATIC1111/stable-diffusion-webui Wiki (github.com)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#alternative-installation-on-windows-using-conda)
- anaconda 常用命令：[anaconda常用命令_anaconda命令_ligous的博客-CSDN博客](https://blog.csdn.net/ligous/article/details/124209700)

### 3、CUDA 环境

默认 `stable-diffusion-webui` 运行使用的是 GPU 算力，也就是说需要用到 Nvidia 显卡（配置越高，绘图越快）。这里我们需要安装 CUDA 驱动，先确定一下电脑能安装的 CUDA 版本，桌面右下角->右键 NVIDIA 设置图标->NVIDIA 控制面板：

![img](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/81d586d7aeac4a638b430f89a39eb10e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

可以看到我的电脑的显示的是 `NVIDIA CUDA 11.6.134 driver`，所以我的电脑要安装的 CUDA 版本不能超过 11.6。

> 注意：高版本显卡是可以安装低版本的 CUDA 驱动的，比如我也可以安装经典的 10.2 版本，但是安装 11.6 版本可以获得更高的 GPU 运行效率，所以一般来说推荐安装显卡支持的最高 CUDA 版本。

在下面的网址中找到对应的 CUDA 版本进行安装：

- CUDA 官方归档：[developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive)

![img](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a4765e3b177c4e999a3f1becab8a1f46~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

直接选择 "精简" 安装就可以了，安装完成之后，可以使用如下命令查看 CUDA 版本，来验证 CUDA 是否安装成功：

```shell
nvcc --version
```

![img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5866442a218f4ac8a54fe2b293e6629e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

> 注：如果你没有 Nvidia 显卡，也可以通过给 `stable-diffusion-webui` 指定运行参数 `--use-cpu sd`，让其使用 CPU 算力运行，但是非常不建议你这么做，CPU 算力跟 GPU 算力相比简直天差地别，可能 GPU 只需要 10 秒就能绘制完成，而 CPU 却要 10 分钟，这不是开玩笑的。另外，如果你的显卡内存不多，建议 4G 的显卡加上 `--medvram` 启动参数，2G 的显卡加上 `--lowvram` 启动参数。怎么配置启动参数我们后面说。

### 4、启动项目

在安装配置好运行环境之后，直接运行工程下的 `webui-user.bat` 文件即可（如果是类 Unix 系统，则运行 `webui-user.sh`）。

首次启动会自动下载一些 Python 依赖库（具体哪些库请看工程下的 `requirements.txt`） ，以及项目需要用到的配置和模型文件（比如：`v1-5-pruned-emaonly.safetensors`，将近 4 个 G~），初始化一次之后，下次启动就快了。

```shell
Launching Web UI with arguments:
...
Running on local URL:  http://127.0.0.1:7860
To create a public link, set `share=True` in `launch()`.
```

看到这个提示就说明成功运行起来了，打开网址就可以看到程序的运行界面了：

![img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/73bbbc2e939a4cd08e36e8144c42c02c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

> 温馨提示：该项目是英文页面，可以使用浏览器的翻译功能转成中文来使用~

## 二、使用

`stable-diffusion-webui` 的功能很多，主要有如下 2 个：

- 文生图（`text2img`）：根据提示词（Prompt）的描述生成相应的图片。
- 图生图（`img2img`）：将一张图片根据提示词（Prompt）描述的特点生成另一张新的图片。

> 注：本文只讲解文生图（`text2img`）功能，图生图（`img2img`）后续有机会再出文章，喜欢的请多多点赞关注支持一下 😃。

### 1、文生图（`text2img`）

在开始使用文生图之前，有必要了解以下几个参数的含义：

| 参数            | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| Prompt          | 提示词（正向）                                               |
| Negative prompt | 消极的提示词（反向）                                         |
| Width & Height  | 要生成的图片尺寸。尺寸越大，越耗性能，耗时越久。             |
| CFG scale       | AI 对描述参数（Prompt）的倾向程度。值越小生成的图片越偏离你的描述，但越符合逻辑；值越大则生成的图片越符合你的描述，但可能不符合逻辑。 |
| Sampling method | 采样方法。有很多种，但只是采样算法上有差别，没有好坏之分，选用适合的即可。 |
| Sampling steps  | 采样步长。太小的话采样的随机性会很高，太大的话采样的效率会很低，拒绝概率高(可以理解为没有采样到,采样的结果被舍弃了)。 |
| Seed            | 随机数种子。生成每张图片时的随机种子，这个种子是用来作为确定扩散初始状态的基础。不懂的话，用随机的即可。 |

> 以上对参数的解析源自以下文章：
>
> - [NovelAI模型各参数解析以及对应关系 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/574063064)
> - [AI杀疯了｜文字生成图片详解 (baidu.com)](https://baijiahao.baidu.com/s?id=1758865024644276830&wfr=spider&for=pc)

接下来我们来生成一张赛博朋克风格的猫咪图片，配置以下参数后，点击 "Generate" 即可：

```less
Prompt：a cute cat, cyberpunk art, by Adam Marczyński, cyber steampunk 8 k 3 d, kerem beyit, very cute robot zen, beeple |

Negative prompt：(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, flowers, human, man, woman

CFG scale：6.5

Sampling method：Euler a

Sampling steps：26

Seed：1791574510
```

> 注：提示词（Prompt）越多，AI 绘图结果会更加精准，另外，目前中文提示词的效果不好，还得使用英文提示词。

![赛博朋克猫咪](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0aaa3893e81d4d78b56d41ccb7db208c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

### 2、模型文件

眼尖的你可能发现了，上面截图里左上角 `Stable Diffusion checkpoint` 的值怎么跟之前截图里的不一样？这是因为我换了一个模型文件，还记得前面提到那个将近 4 个 G 大小的模型文件（`v1-5-pruned-emaonly.safetensors`）吗？那是 `stable-diffusion-webui` 的默认模型文件，用这个模型文件生成出来的图片比较丑，因此我换了另一个模型文件。模型文件下载的网站几个，比较出名的就是 `civitai`，这上面共享的都是别人训练好的模型。

> 模型文件下载地址：
>
> - `civitai`：[Civitai | Stable Diffusion models, embeddings, LoRAs and more](https://civitai.com/)
> - 默认的 `v1-5-pruned-emaonly`：[runwayml/stable-diffusion-v1-5 at main (huggingface.co)](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)

![img](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0239a1eca2ad444da2d1da06d42d5210~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

根据你要生成的图片风格（比如：动漫、风景），挑选合适的模型查看，前面那个文生图的例子，使用的就是这个 `Deliberate` 模型，直接点击 "Download Latest" 即可下载该模型文件。

![img](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a18aa06e91474da19af8cd217d0b6eae~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

> 注：模型文件有 2 种格式，分别是 `.ckpt`（Model PickleTensor） 和 `.safetensors`（Model SafeTensor），据说 `.safetensors` 更安全，这两种格式 `stable-diffusion-webui` 都支持，随意下载一种即可。

将下载好的模型文件放到 `stable-diffusion-webui\models\Stable-diffusion` 目录下：

![img](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4ab9f11797164f329b8844da82e204c0~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

放置好模型文件之后，需要重启一下 `stable-diffusion-webui`（执行 `webui-user.bat`）才能识别到。

![img](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/84397776eb28476f928d6c9bfcfc1e41~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

这些模型文件一般会附带一组效果图，点击任意一张，就可以看到生成该效果图的一些参数配置：

![img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/173697a92bc74fdd8db0cc923b3ece30~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

把这些参数配置到 `stable-diffusion-webui` 中，点击 "Generate" 就可以生成类似效果的图片了。

> 注：因为 AI 绘图带有随机性质，所以生成出来的图片跟效果图不一定完全一样。

文生图功能有很多东西可以发掘，你可以用它来生成世界上独一无二的图片，而要用好文生图功能，提示词（Prompt）是必须掌握的重中之重，它是有语法规则的，在此推荐两篇对 Prompt 详细说明的文章：

- 全网 Stable Diffusion Prompt 运用技巧：[【AI绘画】全网 Stable Diffusion Prompt运用技巧（自用） - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv19903784)
- Prompt 工具網站：[4 個 AI 繪圖「 Prompt 工具網站」推薦！讓你輕鬆輸入精準指令掌控 AI｜Accucrazy 肖準行銷 - Accucrazy 肖準行銷](https://www.accucrazy.com/prompt-tools-ai/)

## 三、工程配置

前面说到，`stable-diffusion-webui` 是可以配置启动参数的，这是官方的 wiki：

- 配置参数文档：[Command Line Arguments and Settings · AUTOMATIC1111/stable-diffusion-webui Wiki (github.com)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings)

### 1、常用参数

这里列几个常用的参数说明一下：

| 参数                            | 说明                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| --listen                        | 默认启动绑定的 ip 是 `127.0.0.1`，只能是你自己电脑可以访问 webui，如果你想让同个局域网的人都可以访问的话，可以配置该参数（会自动绑定 `0.0.0.0` ip）。 |
| --port xxx                      | 默认端口是 `7860`，如果想换个端口，可以配置该参数，例如：`--port 8888`。 |
| --gradio-auth username:password | 如果你希望给 webui 设置登录密码，可以配置该参数，例如：`--gradio-auth GitLqr:123456`。 |
| --use-cpu                       | 默认使用 GPU 算力（需要 Nvidia 显卡），如果没显卡，可以配置该参数，改用 CPU 算力。 |
| --medvram                       | 为低显存（比如：4G）启用模型优化，会牺牲一点速度。           |
| --lowvram                       | 为极低显存（比如：2G）启用模型优化，会牺牲很多速度。         |
| --autolaunch                    | 启动时自动打开浏览器访问 webui。                             |

要配置这些参数很简单，打开 `webui-user.bat`，把你需要配置的参数添加到 `COMMANDLINE_ARGS` 后面即可：

```shell
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=--listen --port 8888 --gradio-auth GitLqr:123456 --autolaunch

call webui.bat
```

![img](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5abe6c44e5ee4ac995d700dd3b18284b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

### 2、API 接口服务

除了上述几个常用的参数外，还有一个特别的参数 `--api`，可以在启动 `stable-diffusion-webui` 的同时，启动一个接口服务，在 `COMMANDLINE_ARGS` 后面追加上 `--api`：

```shell
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=--listen --port 8888 --gradio-auth GitLqr:123456 --autolaunch --api

call webui.bat
```

重启后在 url 后面加上 `/docs` 即可看到 api 请求说明文档：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0e2eda7f5ab4714b749ca90260c8799~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

这样我们就可以通过编写程序的方式，使用文生图、图生图等功能了，关于接口传参格式等要求，参见官方 wiki：

- 官方 api 说明文档：[API · AUTOMATIC1111/stable-diffusion-webui Wiki (github.com)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API#api-guide-by-kilvoctu)

## Linux上如何使用Stable Diffusion WebUI

### 前提条件

- 已安装CUDA
- 已安装git
- 已安装Anaconda
  - 直接安装Anaconda。
  - 虽然Linux自带的Python，但是缺胳膊少腿，所以不要指望Linux自带的Python。

### 捣鼓好Stable Diffusion WebUI需要的环境

创建并激活进入虚拟环境：

```bash
conda create -n webui python=3.10.6
conda activate webui
```

成功进入虚拟环境之后就可以开搞了。

### 下载Stable Diffusion WebUI

从github上下载，终端中输入：

```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
```

进入文件夹：

```bash
cd stable-diffusion-webui
```

为了减少你的麻烦，请做好以下几个**铺垫步骤**：

#### pip换源

```bash
pip config set global.index-url <http://mirrors.aliyun.com/pypi/simple/>
pip config set global.trusted-host mirrors.aliyun.com
```

> **笔者提示：** 安装过程中可能会遇到奇怪的问题，**一般都是网络造成的**，很大一部分是pip源造成的。
>
> 我搭的时候弄得阿里云源，疯狂报错。搭的时候用的清华源，一下就成功了。
>
> 我又配另一个服务器，阿里云全部成功。我俩复盘了一下，就是当时网络的问题。所以阿里云源不好使，多换几个别的。

#### 修改lunch.py

找到下面这段代码，给每个github地址前边都加上：[GitHub Proxy 代理加速 (ghproxy.com)](https://ghproxy.com/)

```py
def prepare_environment():
    global skip_install

    torch_command = os.environ.get('TORCH_COMMAND', "pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117")
    requirements_file = os.environ.get('REQS_FILE', "requirements_versions.txt")
    commandline_args = os.environ.get('COMMANDLINE_ARGS', "")

    xformers_package = os.environ.get('XFORMERS_PACKAGE', 'xformers==0.0.16rc425')
    gfpgan_package = os.environ.get('GFPGAN_PACKAGE', "git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379")
    clip_package = os.environ.get('CLIP_PACKAGE', "git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1")
    openclip_package = os.environ.get('OPENCLIP_PACKAGE', "git+https://github.com/mlfoundations/open_clip.git@bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b")

    stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', "https://github.com/Stability-AI/stablediffusion.git")
    taming_transformers_repo = os.environ.get('TAMING_TRANSFORMERS_REPO', "https://github.com/CompVis/taming-transformers.git")
    k_diffusion_repo = os.environ.get('K_DIFFUSION_REPO', 'https://github.com/crowsonkb/k-diffusion.git')
    codeformer_repo = os.environ.get('CODEFORMER_REPO', 'https://github.com/sczhou/CodeFormer.git')
    blip_repo = os.environ.get('BLIP_REPO', 'https://github.com/salesforce/BLIP.git')
```

**笔者提示：** 刚才说安装过程中可能会遇到奇怪的问题，**一般都是网络造成的**，另一个原因就是从github下载东西的时候失败，所以这里直接加个代理省事。用梯子也不好使。

#### 下载默认模型

> **笔者提示：** 这一步不是必须的，webui.sh会自动运行下载的，但是我用服务器下的巨慢，所以手动下的。

下载：<https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors>，放到 `stable-diffusion-webui/models/Stable-diffusion/` 里

### 使用webui

终端输入启动webui：

```bash
bash webui.sh
```

**出现URL就是成功！** 点击链接用浏览器打开。

### 部分报错处理方法

一般都是网络问题，方法就是**找到Traceback里边的Command，重新给它换个别的国内源**，阿里云不行换清华、豆瓣等等。

1. RuntimeError

   > RuntimeError: Couldn't install torch.
   >
   > Command: "/home/Ann/stable-diffusion-webui/venv/bin/python3" -m  pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url [download.pytorch.org/whl/cu117](https://download.pytorch.org/whl/cu117)
   >
   > Error code: 2

   下载源有问题，看一下你换源了么？已经换源的话不好使，那就再试一下别的源。

   把`command`后边那块复制下来，改一改：

   > pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --trusted-host mirrors.aliyun.com  --extra-index-url [download.pytorch.org/whl/cu117](https://download.pytorch.org/whl/cu117) -i `别的源的地址`

2. Preparing metadata (setup.py) ... error

   > subprocess.CalledProcessError: Command '['/home/Ann/stable-diffusion-webui/venv/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpmlg_i0y8', '--quiet', 'cython']' returned non-zero exit status 2.
   >
   > distutils.errors.DistutilsError: Command '['/home/Ann/stable-diffusion-webui/venv/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpmlg_i0y8', '--quiet', 'cython']' returned non-zero exit status 2.

   还是看`Command`。报错转化出来是这个命令：

   > "/home/Ann/stable-diffusion-webui/venv/bin/python3" -m pip --disable-pip-version-check wheel --no-deps -w /tmp/tmpmlg_i0y8 --quiet cython

   表示在使用 pip 安装 cython 时，生成了一个 Wheel 文件。

   - 其中 **/home/liuyx169/stable-diffusion-webui/venv/bin/python3** 表示使用指定的 Python 解释器来执行 pip 命令。
   - **-m pip** 表示使用 pip 模块来执行命令。
   - **--disable-pip-version-check** 表示禁用 pip 版本检查
   - **wheel** 表示使用 Wheel 格式打包安装包
   - **--no-deps** 表示不安装依赖包
   - **-w /tmp/tmpmlg_i0y8** 表示将生成的 Wheel 文件放置在指定的目录下
   - **--quiet** 表示以安静模式运行，不输出详细信息
   - **cython** 表示要安装的 Python 包的名称。

   归根结底还是在安装cythom这个包的时候没装上，还是网的问题。

   如果你确定换源了，那解决方法还是再换个源手动装一下：

   > pip install cython  -i **别的源的地址** --disable-pip-version-check wheel --no-deps

3. pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.

   还是源的问题。找到Traceback里边的Command再换个源。

4. The TLS connection was non-properly terminated.

   > fatal: unable to access '[github.com/TencentARC](https://github.com/TencentARC/GFPGAN.git/)': gnutls_handshake() failed: The TLS connection was non-properly terminated. error: subprocess-exited-with-error

   出现这个问题，回去看一下你的launch.py改对了么？确定给launch.py所有的github地址前边都加上[ghproxy.com/](https://ghproxy.com/) 即可。

## 在 Mac OS 上安装 Stable Diffusion

### 一、安装 Home Brew

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/032bfd063bc84870a4a57df3384f3fc2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

在开始我们需要安装下 [Home Brew](https://brew.sh/), 可以直接复制下面代码到终端并执行

```sh
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### 二、安装所需依赖

下面我们需要使用 `brew` 安装一些所需要的依赖包: `make` `protobuf` `rust` `python@3.10` `git` `wget`, 可以直接复制下面代码到终端并执行

```sh
brew install cmake protobuf rust python@3.10 git wget
```

### 三、拉取 Stable Diffusion Web UI 存储库

这里我们需要拉取下 `Stable Diffusion` 的一个 [WEB UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) 仓库代码

```sh
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

### 四、下载模型

在这里我们需要提前下载好一个基本的 [模型](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original), 点击 [这里](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original) 进入下载页

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/44d2f05cf9574d069574cd10cdf4c422~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

下载好模型后, 需要将模型文件放到 `stable-diffusion-webui/models/Stable-diffusion` 目录下

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1087279493064d6981c9ca44d0c36009~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

五、启动项目

进入项目, 执行 `webui.sh` 脚本

```sh
cd stable-diffusion-webui
./webui.sh
```

等待: 这一步会比较久, 需要耐心等待……

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2ada8561cca6458e90d3a057eaefc56e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

如果执行上面命令, 抛出错误了则需要修改项目根目录下的 `webui-user.sh` 文件: 该文件默认 `第十三行` 是被注释掉的, 我们需要修改这一行内容

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9c68b2b663054c608cff10e45467c9ea~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

修改内容如下:

```diff
# 第13行
+ export COMMANDLINE_ARGS="--medvram --opt-split-attention --skip-torch-cuda-test --no-half --use-cpu all"
```

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/16fca336c3a14205a7d413e487b7fcff~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

最后重新运行 `webui.sh` 脚本:

```sh
./webui.sh
```

等待片刻, 这里如果成功运行的话, 最后会给出一个 `WEB UI` 界面的 `访问地址`

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ef9102da517542058cfa8626d59f8aa9~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

下面我们就可以通过上面的地址, 在浏览器访问 `Stable Diffusion` `WEB UI` 界面

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/918cc4140844474c9ca1eb64e43baa7b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 六、测试

下面我们尝试在界面上输入 `咒语` 生成图片, 如下截图在输入框中输入关键词 `home`, 然后点击 `Generate` 开始绘画

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c26c27e69e147e1b6abb349453891d7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这里我们可以观察控制台, 就能够看到, 如下进度条, 这就说明系统正在生成图片

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3afac0f12d1841f683a490af55c8f70f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这里需要等待一会(机器配置好坏决定等待时长), 最终会在右边生成一张图(当然图片的质量肯定是一般般的, 因为我们的咒语还是太简单了)

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4348c311ee7e42f1bb4e97063fcee455~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这里我们还可以看下, 终端进度条, 也以显示 `100%`

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06db1e708ff2477f99ca7f92ddad99f4~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

> 最后补充下: 如果出现如下报错, 请参考上一章节, 通过修改项目根目录下的 `webui-user.sh` 文件, 可修改该问题

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ae48ccde905848db943969a5b5753dbf~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 七、汉化

由于 `stable diffusion webui` 项目都英文的, 但是呢里面又涉及到很多设置与参数, 为了方便设置参数, 这里还是很有必要针对 `stable diffusion webui` 进行一个汉化

#### 7.1 安装汉化包

汉化包我们选择 [stable-diffusion-webui-chinese](https://github.com/VinsonLaro/stable-diffusion-webui-chinese), 在项目文档中介绍了两种安装方式, 这里我们选择第一种方式进行安装:

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/beca9c4340e544db8f3a02bfe657c734~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这里我们进入下载安装的一个界面(`Extensions` -> `Install from URL`), 这里可安装图示进行操作, 下面链接就是仓库地址 `https://github.com/VinsonLaro/stable-diffusion-webui-chinese`, 这里点击安装时会有个安装进度条(没截到 😭)

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c18ed9d6616d49a28eb64941c9c067be~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

安装完成后, 我们还需要, 重新加载下 `UI`, 这里直接点击页面底部的 `Reload UI` 即可

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/383f7ddc9cb248259f1d4c97996f8015~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

#### 7.2 配置语言

上面我们只是完成汉化包的安装, 下面还需要配置下语言, 配置路径: `Settings` -> `User interface` -> `Localization`, 这里我选择的是 `chinese-english-0512`, 这样的话页面就会有中英文的一个对照, 方便后面参数配置

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4459267623dc4dcf86099054df710b1b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

选择完后, `保存配置` 并 `重新加载 UI`

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4133c811a2934a1694699826db8ae81d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

最后可以看下最终汉化后的效果

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8bcf8b46fc2f47989d6c68539f4e785a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 八、模型下载 & 演示

下面我们尝试下载安装模型, 进行一个简单的尝试

#### 8.1 模型下载

模型下载源这里推荐 [C 站](https://civitai.com), 在这上面我们可以下载各种风格的模型

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2537e46071c446daa580a19524b0b5fa~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

这里我选择 [toonyou](https://civitai.com/models/30240/toonyou) 模型, 并进行了下载

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c0716506b574dd192dcd731f02a4439~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

同上文, 这里我们需要将下载后的模型复制到 `stable-diffusion-webui/models/Stable-diffusion` 目录下

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94ebed1ee4fa4f69ba336a4e5e38a7e2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

最后的最后, 我们需要重新加载下 `UI`

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de48be10ecce4aaa9856708debcaa648~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

加载完成后, 就可以在模型选择一栏, 看到我们下载好的模型了

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a497053c76914d55a2dbfd584b621697~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

#### 8.2 开始魔法

如下演示图, `选择模型` -> `输入魔法` -> `点击生成`, 等待片刻... 即将完成一副巨作

> 咒语: `Girls, Hanfu, aestheticism, cherry, large cherry, petals fall, big scene, elegant Hanfu, dream, unreal, inception space, sci-fi --ar 3:4  --s 250     --q 2  --v 5 --q 1 --s 100`

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c2ab559a0d24cf9a691f099249c9dfc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 九、参考

- [轻松安装Stable Diffusion WebUI | MacOS M1&2, Intel CPU可用 | 完整指南和教程](https://www.youtube.com/watch%3Fv%3D4vtLrafPd5c)
- [MacOS:轻松安装Stable Diffusion WebUI | M1, M2, Intel | 完整指南和教程](https://updayday.notion.site/MacOS-Stable-Diffusion-WebUI-M1-M2-Intel-61a0fd82ea0e451d9ead16beafc3a28b)
- [免费搭建一套可自由更换模型的stable-diffusion](https://mp.weixin.qq.com/s/gxfWc2tVS2ruoPZhcc1Qsw)

## 低成本Stable Diffusion API解决方案

- **stablediffusion api**：<https://stablediffusionapi.com/>
- **replicate**：<https://replicate.com/stability-ai/stable-diffusion>

## 远程云端部署Stable Diffusion

### 简单又便宜！所有人都能用上完整版 Stable Diffusion

|                       | **价格** | **简单** | **版本** | **便携** | **整体评价**                         |
| --------------------- | -------- | -------- | -------- | -------- | ------------------------------------ |
| **Google colab**      | ⭐⭐⭐⭐⭐    | ⭐⭐       | ⭐⭐⭐⭐     | ⭐⭐⭐⭐⭐    | 价格相对较低，操作简单，但稳定性较差 |
| **大厂云服务**        | ⭐⭐       | ⭐⭐       | ⭐⭐       | ⭐⭐⭐⭐⭐    | 价格较高，操作流程复杂，可能存在bug  |
| **AI工具整合包**      | ⭐⭐⭐      | ⭐⭐⭐⭐     | ⭐        | ⭐⭐⭐⭐⭐    | 价格适中，操作简单，但版本更新不及时 |
| **MAC 电脑本地安装**  | ⭐⭐       | ⭐        | ⭐        | ⭐⭐⭐      | 成本高，操作复杂，效果不佳           |
| **PC 台式机本地安装** | ⭐⭐⭐      | ⭐⭐⭐      | ⭐⭐⭐⭐     | ⭐        | 成本高，操作复杂，便携性差           |

苹果设备、电脑性能受限或者预算有限，可以使用完整版 Stable Diffusion 么？完全可以！作者 @逗砂 分享了自己尝试且放弃过的多个方案，并最终找到了最满意的工具 —— **揽睿星舟！**

*0*. **网址** ：[www.lanrui-ai.com/](https://www.lanrui-ai.com)

*1*. **价格**：一块 3090的每小时算力价格只要1.9元，这是目前看到的国内最低价格

*2*. **简单**：官方针对 Stable Diffusion 做了快捷版应用，直接点击安装就可以使用，更新也比较及时

*3*. **版本**：目前看到的唯一一个能够用非本地安装的方式看到最新版本的controlnet的工具，虽然目前只在基于工作空间的方式可以使用 [**⋙ 使用教程**](https://mp.weixin.qq.com/s/p1rqHPcjHXswowBdO5OHvQ)

————————————————————————————————————————————

教程：【AI绘画、国产ChatGPT一键部署，免费服务器A10显卡，10分钟搭建保姆级教程】<https://www.bilibili.com/video/BV18c411M7PM?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

一键部署，使用阿里云，远程云端部署Stable Diffusion、通义千问，本地电脑无需高性能的显卡，不用部署复杂的开发环境，也能玩各种有趣好玩的AI算法。

- 免费试用中心：<https://click.aliyun.com/m/1000373727/>
- 函数计算FC：<https://click.aliyun.com/m/1000374159/>
- 文件存储NAS：<https://click.aliyun.com/m/1000374158/>

————————————————————————————————————————

【【AI绘画】阿里云在线试用 免费服务器v100显卡 5分钟搭建WebUI 保姆级教程】<https://www.bilibili.com/video/BV1po4y1877P?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- 阿里云试用宝典：<https://developer.aliyun.com/free/>
- 机器学习PAI控制台：<https://pai.console.aliyun.com/>
- 一键包/镜像资源：<https://pan.quark.cn/s/12af730acb20>

【保姆级教程：在colab云端上面部署stable diffusion并汉化，免费的15G显存】<https://www.bilibili.com/video/BV15m4y1r7Y3?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【AutoDL GPU云端部署，开启Stablediffusion无限跑图】<https://www.bilibili.com/video/BV1eL411B7jn?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【五分钟学会Stable Diffusion一键安装包Easy Diffusion】<https://www.bilibili.com/video/BV1B24y1j7jg?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【腾讯云GPU服务器部署Ai绘画Stable Diffusion全过程，操作简单，直接复制粘贴代码即可】<https://www.bilibili.com/video/BV1NY4y1S7eA?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

## colab部署StableDiffusion

- 服务器在我们本地，不用联网了，空间大。
- 搭在服务器上还有另一个好处，就是我弄好以后全实验室都可以用，启动起来就不用停下了。
- Colab要科学上网。
- 谷歌硬盘空间太小，放不下我想要的所有checkpoint
- Colab长时间不用会自己断开
- ……

**绘图消耗的计算成本相对于自己装机或者购买显卡来说超级低，适合新入门尝鲜。**

- 首先，**访问一键部署脚本**。跳转谷歌 🌍[Google Colab](https://colab.research.google.com/drive/1lekLF7iib6M1R-NCylS0VMTF4wve-XuV)，并运行脚本中的第1步。
- 然后，在第2步中选择 SD 模型处填入 **ChilloutMix** ，点击运行。
- 接着，**设置 LoRA** (默认内置选项，或填写他人的 LoRA 模型下载地址)，点击运行。
- 继续，依次点击运行即可后续几步，直到显示**绘图环境安装成功。**
- **开始绘图**，按照作者教程填写 prompt 信息，选择 LoRA 模型，就可以生成图片啦。
- **参数优化**，如果觉得默认设置生成的图片分辨率低，可以按照图示调整参数。

[无显卡也能AI作画 | Colab + Stable Diffusion WebUI - 掘金 (juejin.cn)](https://juejin.cn/post/7217750296171233339)

## 阿里云Serverless部署StableDiffusion

[免费搭建个人stable-diffusion绘画(非本地、干货教程) - 掘金 (juejin.cn)](https://juejin.cn/post/7237004563647397946)

[阿里云 AIGC 白嫖 FC 搭建 stable diffusion - 掘金 (juejin.cn)](https://juejin.cn/post/7221142199391961147)

[阿里云 PAI 免费试用搭建 stable-diffusion-WebUI - 掘金 (juejin.cn)](https://juejin.cn/post/7221884988492398651)

[白嫖党 YYDS: 阿里云快速搭建 Stable Diffusion - 掘金 (juejin.cn)](https://juejin.cn/post/7246401806677442617)

————————————————————————————————————————

### 上手操作

之前我们部署应用，都是通过服务器或者云服务器居多，需要自己去：各种装软件，各种配环境（这一步往往就劝退了很多人），各种操作搞一通。

而这次我们彻底换一个方式，不用服务器，而是用容器，而且是基于Serverless的容器集群，然而**过程却非常简单**，**快速上手**。

老规矩，这里还是以阿里云为例。

这里**直接访问快速入口**：

[click.aliyun.com/m/100037316…](https://click.aliyun.com/m/1000373164/)

即可打开阿里云的资源领用中心：

![页面地址：https://click.aliyun.com/m/1000373164/](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/27c37f2509fa453b9c5832e8efa1d17c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

注意，这个地址大家可以收藏好。

因为我不止一次地收到过类似私信，说：

- 阿里云上是怎么免费领取资源来着？
- 新用户是怎么白瞟阿里云的资源来着？

而这个地址：

[click.aliyun.com/m/100037316…](https://click.aliyun.com/m/1000373164/)

**它就是总入口！**

打开之后可以看到，里面有很多分类和产品，用户之前如果没有用过这个产品的话，都可以免费领用。

![页面地址：https://click.aliyun.com/m/1000373164/](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/26641d0900034b6790a74c55158342f7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

所以这个地址建议大家可以收藏好，免得后续临时想用时却找不到。或者说以后但凡想白瞟阿里云资源时（doge），就可以打开这个地址进去看看。

这次AI绘画应用的部署我们要用的是容器集群，**直接访问快速入口**：

[click.aliyun.com/m/100037408…](https://click.aliyun.com/m/1000374087/)

进去之后，我们直接点击「立即试用」按钮。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/396f291473fc4ab0adf45912ddd29c98~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

首先可以在弹出的面板上选择好地域，然后在服务协议右侧，单击「完成服务角色的授权」进入授权。

![转存失败，建议直接上传图片文件]()

授权完成以后，再回到该面板，重新勾选服务协议之后：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8384a2ffde44f8a80b1dfb4110754a3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

方可点击「立即试用」按钮来正式创建资源了。

![转存失败，建议直接上传图片文件]()

完成之后，进入集群的控制台页面，可以看到系统正在帮我们自动创建一个标准版容器集群，等待几分钟后，当集群状态为「运行中」时，即可正常使用。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a3dd82e935114ff98a93884abd7e57e1~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

集群就绪以后，接下来我们就可以在里面部署各种各样好玩的应用了！

### 部署Stable Diffusion应用

接上一步，集群就绪以后，接下来我们就在这个容器集群里，来部署上线Stable Diffusion这个AI绘画应用。

它将会以容器的方式来运行，非常方便。

我们点进刚创建完成的集群，会进入到集群的工作页面。

此时我们进入左侧导航栏里的「工作负载」 > 「无状态」，然后选择右上角「使用镜像创建」的方式来部署此次AI绘画应用。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/91379da9e28d45e2b8c483ae0f9f5d5c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

接下来按如下步骤填写几个关键信息，即可快速上线AI应用。

- 应用基本信息

这一步主要就是填写应用名称等信息，大家根据需要自行填写即可。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d94ca6527af644bf97965cf06f8811b0~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

- 容器配置

这一步虽然比较关键，但是设置非常简单，我们只需要设置好如下几个选项即可，其他保持不动。

| 配置项       | 配置内容                                                     |
| ------------ | ------------------------------------------------------------ |
| 镜像名称     | `yunqi-registry.cn-shanghai.cr.aliyuncs.com/lab/stable-diffusion` |
| 镜像标签     | `v1.2.0`                                                     |
| 所需资源     | 8Core 16GB                                                   |
| 启动执行命令 | `["python3", "launch.py"]`                                   |
| 启动执行参数 | `["--listen", "--skip-torch-cuda-test", "--no-half"]`        |

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/908347c3a68643d8968fa210a1adb25b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/18881b21b25d4337bc4531e8559cd125~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

> 需要说明一点的是：正因为平台官方对该镜像做了加速，所以等下拉取会很快，不然像这种AI应用的镜像一般都比较大，动不动就十几GB，没有加速的话实在太慢了，所以这也是为什么这次选用该容器集群来进行应用部署的重要原因。

- 高级配置

在该Tab页部分，我们重点需要设置的就是「对外服务的Service」，我们希望这个应用能被大家所访问到。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b082996f09a4ae9ace0754d57ce26cb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

点击上图中的「创建」按钮之后，会弹出「创建服务」的对话框。

其他配置都不需要动，我们只需要设置一下端口映射关系即可：我们通过7860这个端口提供给大家访问。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e6d807a059ba4e359f9c222d1dcbd99b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

以上这些配置都完成以后，我们点击创建，系统就会自动提交并开始部署应用，**过程就是这么简单**！

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f343c4bee7ae476c9050cc71f3b22799~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

点击上方的「查看应用详情」后，我们也可以到控制台里去追踪应用的具体部署情况。等Pod的状态变为Running时，应用就已经成功上线了！

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ac5e30472a443108a65fc56c8456038~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

所以整个过程就是这么简单，我们通过一个非常**低成本且简单的方法**将Stable Diffusion这个AI绘画应用给部署上线了，并且公网可访问。

### 效果展示

以上操作完成以后，Stable Diffusion就已经顺利部署上线了。

此时我们回到集群页面，点击左侧导航栏里的「网络」 > 「服务」，可以看到对外提供的Stable Diffusion公网服务。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/42f38bf33a024b9c9a6289ffdf40b9f3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

其对应有一个「外部端点」，即：一个可以访问Stable Diffusion AI绘画的公网IP。

我们直接点击，就可以打开浏览器，访问到Stable Diffusion的Web UI页面。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de5020056a2a4a148d72018c1f97bc34~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

此时我们在该页面中输入提示词和参数，就可以开始AI绘画的创作了。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2e09f69b95ba431ba1396c34649930bc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

所以整个过程非常简单易上手。

### 上手使用

好啦，聊了这么多，落实到应用上，还是得自己上手实践一波。

大家可以按照上述过程操作一遍，这也可以说是目前非常低成本部署AI绘画应用的方式了，而且过程非常简单。

有兴趣的小伙伴可以尝试一波，具体快捷入口为：

[click.aliyun.com/m/100037408…](https://click.aliyun.com/m/1000374087/)

另外像civitai.com或者liandange.com等模型网站上也有很多AI绘画相关的模型，都可以直接在：[click.aliyun.com/m/100037408…](https://click.aliyun.com/m/1000374087/) 上进行部署使用。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9feee05cd1e74876bca2adb782af1f92~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

大家有兴趣也可以试一试，相信会打开一个新世界的大门

## 在亚马逊 SageMaker 进行 Stable Diffusion 模型服务部署

[如何在亚马逊 SageMaker 进行 Stable Diffusion 模型在线服务部署 - 掘金 (juejin.cn)](https://juejin.cn/post/7221497108008255548)

[AI 绘画基于 Kaggle 10 分钟搭建 Stable Diffusion（保姆级教程） - 掘金 (juejin.cn)](https://juejin.cn/post/7247306840199135287)

## 【ChatGLM-6B+StableDiffusion+网络搜索】本地部署绘图

视频教程：【【ChatGLM-6B+StableDiffusion+网络搜索】本地部署可绘图，网上寻找信息的AI】<https://www.bilibili.com/video/BV1gX4y1B7PV?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

本项目基于 ChatGLM-6B (<https://github.com/THUDM/ChatGLM-6B>) 后期调教，

网络爬虫及 Stable Diffusion (<https://github.com/AUTOMATIC1111/stable-diffusion-webui>)

项目实现了 ChatGLM-6B 的网络搜索及图片生成功能

项目源码：<https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering>

秋叶里改下端口设置下允许API就可以了， 秋叶安装包默认的7860端口改成这个默认7861

视频教程：【【AI绘图】ChatGLM+StableDiffusion整合包】<https://www.bilibili.com/video/BV1Wa4y1V77o?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

网盘链接：<https://pan.baidu.com/s/19kbrJyZXKa093i3N6UYfqQ?pwd=pxok>

lemon大佬的github仓库：<https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering>
秋叶大佬的SD整合包：<https://www.bilibili.com/video/BV1iM4y1y7oA>
lemon大佬的演示视频：<https://www.bilibili.com/video/BV1gX4y1B7PV>
ChatGLM-6B官方仓库：<https://github.com/THUDM/ChatGLM-6B>

视频音源：樱桃MOMO叉屁屁<https://space.bilibili.com/75044618>

## 把Stable Diffusion变成商用软件

视频：【开源！如何把stable diffusion变成商用软件？教你正确的调用stable diffusion api！】<https://www.bilibili.com/video/BV1Y14y127BY?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- sdwebui-api-manager: <https://github.com/nftblackmagic/sdwebui-api-manager>
- sd-webui-hook-v2: <https://github.com/nftblackmagic/sd-webui-hook-v2>
- stable diffusion webui: <https://github.com/AUTOMATIC1111/stable-diffusion-webui>

## 图片素材爬虫采集工具

收费：

- Eagle
- Bilfish

开源免费的爬虫：

## 图片反推文字工具tag反推工具

LLaMA-Adapter V2：[Gradio (opengvlab.com)](http://llama-adapter.opengvlab.com/)

|                         | 工具                                                         | 说明                                                         | 地址                                             |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------ |
|                         | 提示词工具                                                   | poe机器人，一个是SD，一个是MJ。 (如果出来的提示词出来时汉字，属于poe间歇性抽风综合征，需要我刷新下指令就可以了） | <https://poe.com/JJgeSD> <https://poe.com/JJgeMJ>    |
| 跑图相关                | 语义分割工具                                                 | oneformer（免费在线使用/免登录/正常上网）                    | <https://huggingface.co/spaces/shi-labs/OneFormer> |
| 对照表                  | [ADE20K_语义分割释义.pdf](https://d36mqghu8a.feishu.cn/file/Y3vnbbkR8oq5b0xI7GUcvbBZnj4) |                                                              |                                                  |
| 语义分割工具            | segment-anything                                             | [https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything) |                                                  |
| 百度翻译                | 遇到单词和英文语句问题可使用                                 | <https://fanyi.baidu.com/?aldtype=85#zh/en/>                   |                                                  |
| controlnet1.1介绍       | 有版本更新细节，和各个模形效果演示                           | <https://github.com/lllyasviel/ControlNet-v1-1-nightly>        |                                                  |
| controlnet模型库        | 会定期更新新模型(正常上网)                                   | <https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main>  |                                                  |
| controlnet+tile图片放大 | 应该是目前讲的比较详细的教程了                               | [用controlnet  tile 放大图片步骤](https://d36mqghu8a.feishu.cn/docx/CURZdOGl9oXMDzxZsY0cOIuwnDc) |                                                  |
| 底模型，lora模型库      | 主要是底模型，lora，vae                                      | <https://civitai.com/> 国产C站（主打一个正常访问）： <https://www.liblibai.com>  <https://i-desai.com/> |                                                  |
| 建筑相关模型整理        | 由其他建筑大佬整理                                           | 文档放微信群公告里面了                                       |                                                  |
| stable diffusion安装包  | B站秋叶大佬封装的模型包                                      | <https://pan.baidu.com/s/1IlgadoGHHhRaUYPt2PKBxA?pwd=h40u>     |                                                  |
| sd模型类型识别工具      | 检查模型文件类型                                             | <https://spell.novelai.dev/>                                   |                                                  |
| 分辨率锁定高*宽比例     | 解决SD一大痛点，有了这个插件，调整分辨率的时候终于可以锁定宽高比 | <https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git> |                                                  |
| 提示词插件              | 可以安装到webui上的提示词插件，支持输入汉语                  | <https://github.com/Physton/sd-webui-prompt-all-in-one>        |                                                  |
| 放大算法                | 放大算法集合                                                 | <https://icedrive.net/s/43GNBihZyi>                            |                                                  |
| 提示词插件              | 基于chatgpt 的浏览器插件                                     | 没有链接去google应用商店搜索openai translator                |                                                  |
| Embeddings库            | 可下载Embeddings                                             | <https://cyberes.github.io/stable-diffusion-textual-inversion-models/> |                                                  |
| 设计风格图片库          |                                                              | Pinterest.ca                                                 |                                                  |
| upscale放大模型         | upscale放大模型系统介绍                                      | <https://upscale.wiki/wiki/Model_Database>                     |                                                  |
| tag反推插件             | 目前支持在线使用，期待被整合进去。亲测对图中元素的识别还存在偏差。这个反推与sd的反推算法差别在于可以输出成句子也就是自然语言，因此有了元素之间的联系和方位等介词信息。 | <http://llama-adapter.opengvlab.com/>                          |                                                  |
| ps的sd插件              |                                                              | 备忘，回头整理，怕忘了                                       |                                                  |
|                         | sd的ps插件                                                   |                                                              | 备忘，回头整理，怕忘了。感觉这俩相爱相杀         |
| 训练相关                | 图片裁剪工具                                                 | 能一次性，把所有照片传到网页上，自定义像素裁剪图片。 不足之处：不能对图片缩放后裁剪。比如想把头放大，就裁剪头部，那就没办法 | <https://www.birme.net/?target_height=384>         |
| tag修改高效工具         | 训练准备环节，用这个工具可以同时编辑多个tag。而且还带tag翻译功能，不用把翻译网页打开。 | <https://github.com/starik222/BooruDatasetTagManager>          |                                                  |
| 训练集标签编辑器：      |                                                              | <https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor> |                                                  |
| 批量调整图片尺寸：      | 这个图片裁剪工具可以把几十张图放在一屏上调整，统一保存，不用挨个打开。不过有2个缺陷：1、不能对图片做缩放。2、输出的图片尺寸必须统一； | <https://www.birme.net/?target_width=512&target_height=512>    |                                                  |
| 青龙lora脚本            | 青龙大佬经常更新脚本，可以关注下他的b站“青龙圣者”            | [https://pan.quark.cn/s/2a0ad8446b85#/list/share/911cab837aca4890ae5cf0f8f7dfa62b-%E9%9D%92%E9%BE%99%E7%9A%84AI%E5%B7%A5%E5%85%B7](https://pan.quark.cn/s/2a0ad8446b85#/list/share/911cab837aca4890ae5cf0f8f7dfa62b-青龙的AI工具) |                                                  |
| 未完待续，长期更新...   |                                                              |                                                              |                                                  |
|                         |                                                              |                                                              |                                                  |

## ControlNet 目前最全面的资源合集

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/368370213be142838bbc7264da857472~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

最近 ControlNet 势头很猛，补齐了 stable diffusion 条件控制这块短板，实现了人体姿势、图像边缘、深度图、语义色块图、法线图等多种方式对生成的图像进行精确控制，往无缝融入生产工作流又迈进了一大步。

**程序代码**：

> - **官方github**：[lllyasviel/ControlNet: Let us control diffusion models! (github.com)](https://github.com/lllyasviel/ControlNet)
> - **网页试玩demo**：[ControlNet - a Hugging Face Space by hysts](https://huggingface.co/spaces/hysts/ControlNet)
> - **ControlNet stable diffusion webui automatic111插件**：[Mikubill/sd-webui-controlnet: WebUI extension for ControlNet (github.com)](https://github.com/Mikubill/sd-webui-controlnet)
> - **ControlNet video 代码（runway gen1视频编辑平替）**：[camenduru/fffilonis-controlnet-video (github.com)](https://github.com/camenduru/fffilonis-controlnet-video)
> - **ControlNet video 网页试玩**：[ControlNet-Video - a Hugging Face Space by fffiloni](https://huggingface.co/spaces/fffiloni/ControlNet-Video)
> - **新功能上线说明（无需文字引导，纯图片猜测生成）**：[ControlNet 今日上线压轴新功能：猜测模式/非提示模式 (qq.com)](https://mp.weixin.qq.com/s/10W6bIhPQJ4aQafv_MaW9A)

**案例教程**：

> - **ControlNet SD webui 111插件安装**：[【AI绘画爱好者的福音插件】ControlNet安装与使用归纳教程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1jM411c7ev/?vd_source=5f0c99b3deddffe219938763769b15ac)](<https://www.bilibili.com/video/BV1jM411c7ev>)
> - **如果无法自动安装请看这个**：[stable diffusion webui无法安装扩展插件的解决方法_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1RD4y1A7Cb/?vd_source=5f0c99b3deddffe219938763769b15ac)
> - **初学者使用指南**：[ControlNet 工作流程初学者指南 (qq.com)](https://mp.weixin.qq.com/s/wAC_Mr_YarV3seoM_0dLQA)
> - **如何与应用场景结合**：[精确控制 AI 图像生成的破冰方案，ControlNet 和 T2I-Adapter (qq.com)](https://mp.weixin.qq.com/s/ylVbqeeZc7XUHmrIrNmw9Q)
> - **生成清晰的艺术字体案例**：[ww.reddit.com](https://ww.reddit.com/r/StableDiffusion/comments/119j8qr/clear_text_using_controlnet/)

## Stable Diffusion模型

- [【AI绘画】全网Stable Diffusion WebUI Model模型资源汇总（自用） - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv20039815)
- [出图效率倍增！47个高质量 Stable Diffusion 常用模型推荐 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv23887580)

### Stable Diffusion模型网站

**模型下载网站C站**：

- 官网：[Civitai | Stable Diffusion models, embeddings, LoRAs and more](http://civitai.com/)
- github开源地址：[civitai/civitai: A repository of models, textual inversions, and more (github.com)](https://github.com/civitai/civitai)

**LiblibAI模型网站(国内首家原创AI模型分享网站)**：<https://www.liblibai.com/>

- 真人模型搜索关键词：

  - AWPortrait V1.1（Checkpoint）

  - 墨幽人造人V1010（Checkpoint）
  - Instant photo 拍立得（Lora）

- 小王子Discord城堡社群链接：<https://discord.gg/9sJRDU6nbu>

- 视频教程：【【Stable Diffusion】七月模型推荐 超写实潮流时尚大片 不怕坏手】<https://www.bilibili.com/video/BV15m4y1Y7Rs?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- 官方B站：[LiblibAI_哩布哩布AI的个人空间_哔哩哔哩_bilibili](https://space.bilibili.com/482619845)

**xtimesai**：<https://www.xtimesai.com>

吐司在线生图的模型分享平台：

吐司 tusi.art 是一家支持在线生图的模型分享平台，简单说就是国内版 C 站+在线跑图，电脑显卡配置不好的朋友们可以都来尝试尝试这个免费在线跑图！真的很香，各种插件也都有，高清修复、ControlNet、ADetailer 修脸器等等

生成图片需要消耗算力，每天登录都可以充满 100 算力。但很多人都意犹未尽，别急！可以来领取使用我的专属福利 注册链接：<https://tusi.art>  注册完账号后，在编辑资料里的邀请码栏填上“ 秋叶 ”，即可立即获得 100 算力【前提是必须新用户或者7天内注册的用户】

另外大家也可以邀请自己的朋友注册，每邀请 1 人还可以得到额外 200 算力 @吐司TusiArt

### 其他Model|模型资源

使用注意：

- 与ckpt文件同名的vae.pt文件用于稳固该模型的表现，直接放在相同文件夹即可。训练时将该文件改名或移走。并不是所有模型都需要使用vae文件。
- 公开资源：
  - <https://rentry.co/sdmodels>（目前觉得比较全）
  - <https://cyberes.github.io/stable-diffusion-models/>（SD模型）
  - <https://publicprompts.art/>（App Icon Generator，比较有趣想资源）
  - <https://huggingface.co/> （在网站中检索）
  - <http://aimodel.subrecovery.top>
  - <https://docs.qq.com/doc/DY0lFeWZuVXRCdUJU>
  - <http://www.123114514.xyz/models/ckpt>（挺多私炉的）

- 【Stable Diffusion怎么做小说推文的出图讲解第一期】<https://www.bilibili.com/video/BV1Vs4y1w7kH?vd_source=36c9491a7fa2ab8a22ca060af01b7472>
- 【Stable Diffusion怎么做小说推文的出图讲解第二期：抄作业大战】<https://www.bilibili.com/video/BV1Eu41147wv?vd_source=36c9491a7fa2ab8a22ca060af01b7472>
- 【Stable Diffusion小说推文实战讲解第三期：如何利用GPT制作分镜，并批量高效率出图。】<https://www.bilibili.com/video/BV1W14y1D7QG?vd_source=36c9491a7fa2ab8a22ca060af01b7472>
- 【指定形象生成多人场景，Stable Diffusion小说推文实战讲解第四期。】<https://www.bilibili.com/video/BV1qV4y1m7sS?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【Stable Diffusion+Midjourney强强联手出梦幻酷图】<https://www.bilibili.com/video/BV1aX4y1q7Rh?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

将 2D 转为 3D 模型：

设计类AI大模型：<https://civitai.com/user/laizhende/models>

【AI绘画｜赛博修仙-御水之术】<https://www.bilibili.com/video/BV1Kh4y1o7Hs?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- 模型：基于majicmixSombre的魔改
- LORA：Detail Tweaker，hanfu 汉服，Zhongfenghua-style
- 基本步骤：mj跑底图-sd配合tile增加细节-ps修bug-sd配合tile放大到4k

搜索 chocolae

使用教程：【Stable Diffusion 何似在人间 仙侠模型发布 （适合小说插画、背景）】<https://www.bilibili.com/video/BV1Ph4y1X7ub?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

4月AI绘画模型推荐榜：<https://mp.weixin.qq.com/s/ODdA6WsnbdTZkb-7OEZULw>

## 模型用处

[AI绘图StableDiffusion最强大模型盘点 - 诸神乱战 (qq.com)](https://mp.weixin.qq.com/s/bZ-_GyH8fUYTqfURPhA3pA)

[AI绘图StableDiffusion最棒LoRA模型盘点 - 小样也能出奇迹 (qq.com)](https://mp.weixin.qq.com/s/Z7onNo09-7--9eGrbPe0wA)

基础款AI生图模型checkpoint：

- 墨幽人造人：脸部模型固定
- AWPainting 1.1：日漫风格
- 国风3 GuoFeng3：汉服，国画，lora
- majicMIX系列：人造机器人，颜控福音

上次**图生图**的文章中也是使用的这些模型，这次直接使用**文生图**。

| 模型                                   | 介绍                                           |
| -------------------------------------- | ---------------------------------------------- |
| 2dn_1                                  | 动漫模型                                       |
| 3Guofeng3_v32Light                     | 中国、国风模型，感觉上偏3D国漫                 |
| anything-v4.5-pruned                   | 说是里面东西很多很杂                           |
| CamelliaMix_2.5D                       | 2.5D模型                                       |
| camelliamix_v20                        | 动漫模型                                       |
| chilloutmix_NiPrunedFp32Fix            | 真人模型，这个主要针对亚洲人训练的，热度比较高 |
| Dalcefo_v4_Painting                    | 动漫模型                                       |
| dalcefoPainting_3rd                    | 动漫模型，色彩比较淡                           |
| dalcefoRealistic_v2                    | 真人模型                                       |
| dreamshaper_4BakedVae                  | 动漫模型，有点3D的感觉                         |
| grapefruitHentaiModel_grapefruitv41    | 动漫模型，这个热度高                           |
| meinamix_meinaV8                       | 动漫复合模型                                   |
| openjourney-v4                         | 动漫模型，有些3D的意思                         |
| povSkinTexture_povSkinTextureDreamlike | 真人模型，很少用                               |
| realisticVisionV13_v13                 | 真人模型，很少用                               |
| realisticVisionV20_v20                 | 真人模型，很少用                               |

SDXL 0.9 demo：<https://github.com/lifeisboringsoprogramming/sd-webui-xldemo-txt2img>

SDXL Model huggingface :

- <https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9>
- <https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-0.9>

## 模型训练器

【【AI绘画】模型训练器发布！简单又不失专业的LoRA模型训练一键包】<https://www.bilibili.com/video/BV1AL411q7Ub?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- AutoDL 云端使用教程：<https://www.bilibili.com/read/cv24050162>

具体的训练操作步骤：【【AI绘画】最佳人物模型训练！保姆式LoRA模型训练教程 一键包发布】<https://www.bilibili.com/video/BV1fs4y1x7p2?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

## 模型训练|LoRA炼丹秘籍

LoRA训练文章四部曲链接：

- 【AI绘画进阶篇】喂饭级LoRA模型训练包安装教程 <https://www.bilibili.com/read/cv23746330>
- 【AI绘画进阶篇】（手把手教你炼丹）喂饭级LoRA模型训练教程(上) <https://www.bilibili.com/read/cv23640309>
- 【AI绘画进阶篇】（手把手教你炼丹）喂饭级LoRA模型训练教程(下) <https://www.bilibili.com/read/cv23684137>
- 【AI绘画进阶篇】使用XYZ脚本生成对比图进行LoRA模型测试教程 <https://www.bilibili.com/read/cv23572456>

教程：【可能是全网最快的LoRA模型训练教程（一），快来训练你的渡鸦小姐姐LoRA模型吧！】<https://www.bilibili.com/video/BV1Ms4y1k7eH?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

[云服务上进行Lora训练(俗称炼丹)👗👗👗 - 掘金 (juejin.cn)](https://juejin.cn/post/7225474060423561274)

[Stable Diffusion Lora训练实践（云端训练篇） - 掘金 (juejin.cn)](https://juejin.cn/post/7233261440501563451)

【全网还原度最高的真人LORA训练方法！】<https://www.bilibili.com/video/BV18X4y1t7jn?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【AI模特~lora训练~穿指定衣服~】<https://www.bilibili.com/video/BV1VT411t7Na?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【如何训练一个非常像的真人Lora模型（深度探讨）】<https://www.bilibili.com/video/BV1Ba4y1M7LD?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【Stable Diffusion 建筑设计工作流（第二季）—秋叶lora脚本训练UI介绍/Tag批量修改更新】<https://www.bilibili.com/video/BV1jk4y1x7X4?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- Bytorch官网学习：<https://pytorch.org/tutorials/>
- Tag批量修改插件原网址：<https://github.com/starik222/BooruDatasetTagManager>
- 插件和课件百度网盘链接：<https://pan.baidu.com/s/1nVcKpS6OL0VOvyq8zEs8gg?pwd=wrfn>    提取码：wrfn

[炼丹！训练 stable diffusion 来生成LoRA定制模型 - 掘金 (juejin.cn)](https://juejin.cn/post/7215496238627209272)

### LoRA训练 Part1 图片准备与批量裁切

1.收集整理你想训练的人物模型的人脸画像五官清晰的各种角度的图片20-50张，然后把这些图片批量裁切，成分辨率512乘以512的图片

2.打开Stable Diffusion 找到【训练】-【图像预处理】，粘贴图片所在的文件夹位置，再指定输出位置，勾选【自动面部焦点裁切】，然后点击【预处理】，便开始裁切，等待裁切完成。

### LORA训练 Part2 图片提示词批量反推

1.来到【WD 1.X 标签器(Tagger)】-【批量处理文件夹】，输入目录和输出目录都填入图片所在位置路径，然后点击“反推提示词“，便可以看到图片文件夹里多了txt文本文档，打开txt文本文档之后就可以看到自动反推出的提示词

2.接着对这些提示词进行批量打标(tag)操作：先安装【数据集标签编辑器】插件，【扩展】里搜索搜索【Dataset Tag Editor】来安装这个插件。

3.安装完成后会在顶部tab有了【Dataset Tag Editor】选项，填入【数据集目录】，然后点击【加载】，把图片加载进来

4.然后来到右边的tab【批量编辑描述】-【移除】tab页面。。。。。

## LoRA模型

[‍‌⁤⁤⁣‌‬⁡⁢⁡‌‬‌‬⁡⁤‍‌⁡‌⁢﻿‬⁤⁤⁣⁣‍‍⁤‬‍⁣⁣‬‬‍AI绘画：Stable Diffusion 终极炼丹宝典：从入门到精通 - 飞书云文档 (feishu.cn)](https://y3if3fk7ce.feishu.cn/docx/KqEMdhJigoFY8fxc9TPcwMninKf)

[AI绘画：StableDiffusion炼丹Lora攻略-实战萌宠图片生成 - 掘金 (juejin.cn)](https://juejin.cn/post/7253434752837566501)

## 二、Lora作用

LORA可以让我们轻松画出特定的人物，物品，特殊的笔触和特殊的画风或风格，属于一种特殊训练的子集。

### 1.AI模特

炼出一个自己的模特，让这个模特穿上自己的商品

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ab903616d8fd468c91c093771725952a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 2.炼衣服Lora

添加一个衣服的Lora，就可以让人物穿上特定的衣服

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2b2f8deb6eae465b9938e574565f1dbc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 3.改变画风/画面背景

通过添加Lora改变照片的画风，这个画风可以自己去训练

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/45c57d049e404da783fd0b3c61cd5fda~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### Lora模型究竟是什么？

**专业的解释**：

LoRA的全称是[LoRA: Low-Rank Adaptation of Large Language Models](https://link.zhihu.com/%3Ftarget%3Dhttps%3A//arxiv.org/abs/2106.09685)，可以理解为stable diffusion（SD)模型的一种插件，和hyper-network，controlNet一样，都是在不修改SD模型的前提下，利用少量数据训练出一种画风/IP/人物，实现定制化需求，所需的训练资源比训练SD模要小很多，非常适合社区使用者和个人开发者。LoRA最初应用于NLP领域，用于微调GPT-3等模型（也就是ChatGPT的前生）。由于GPT参数量超过千亿，训练成本太高，因此LoRA采用了一个办法，仅训练低秩矩阵（low rank matrics），使用时将LoRA模型的参数注入（inject）SD模型，从而改变SD模型的生成风格，或者为SD模型添加新的人物/IP。

**通俗的解释**：

Lora可以**复刻人物和物品的特征，固定人物动作，改变照片画风**

而且Lora只需要少量的数据就可以训练出来，比训练大模型要简单很多

所以大家可以通过训练自己的Lora，做出定制的图片

但不得不说的是，目前的Lora还不能做到100%相同，尤其是细节方面

但是相信随着之后的技术发展，万物皆可Lora的时代是不远的

## 三、如何炼制自己的Lora模型？

炼制Lora的方式有很多种

有用脚本训练的，也有在网站界面上训练的，最近还有很多朋友做出来了训练Lora的整合包

创建Lora模型的方式有许多，包括通过脚本进行训练，通过网页界面操作，甚至有一些专业人士最近提供了Lora训练的一键式整合包。尽管这些方法在表面上看起来有所不同，但其训练逻辑其实都是相同的。

因此，我们可以选择使用整合包。整合包的优点在于，它将炼丹所需的所有工具和步骤集成在一款软件中，为我们提供了一种更为便捷且有效的训练方式。

> 整合包就是把炼丹所需要的所有工具都整合到一个软件里

炼丹分为以下几步：

1.下载整合包

2.准备工作

3.开始训练

4.测试Lora

5.优化Lora

## 四、炼丹前的准备（**下载整合包**）

在炼Lora之前，需要大家先确认一下自己的电脑配置：

1.电脑配置需要N卡，并且6G显存以上

2.A卡和Mac系统，或者电脑配置不太行的小伙伴建议用云平台

我这里用的是B站up主朱尼酱的整合包：

我用夸克网盘分享了「StableDiffusion炼丹资料」

网盘链接：[pan.quark.cn/s/3c8cc96f3…](https://pan.quark.cn/s/3c8cc96f3221)

下载好了之后把它**解压到D盘或者E盘，不要放在C盘！！**

> 秋叶的整合包我也试过炼Lora，两个对比下来，我觉得朱尼酱的整合包会更适合小白

打开解压之后的文件夹，在“cfurnace_ui”文件夹里面找到“赛博丹炉”的应用程序

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b7454e8930e4d15b291641117ed5ccf~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

> 可以创建一个桌面快捷方式，这样就不用每次都要打开文件

看到这个页面就安装好了，点击“开启炼丹炉”就可以开始炼Lora啦！

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94b362e380c043b5bed92508c136788f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

## 五、选择合适的大模型

跟画图一样，炼Lora之前也要先选一个大模型，确定Lora的画风

**这里训练的萌宠，我选择的是“cheeseDaddys_35”大模型**：

真人模型=》选用“chilloutmix”的大模型

二次元=》选用“anything”的大模型

如果你的Stable Diffusion里面没有模型，那就要先去下载模型噢！

网盘里面已经给大家放了这两个大模型

我用夸克网盘分享了「2.大模型checkpoint」

链接：[pan.quark.cn/s/9767ac274…](https://pan.quark.cn/s/9767ac274f83)

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ae8e62f5d6e48bf990644d68de851a5~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

再往下就可以选择一个我们要训练的Lora的类型

选择之后就会帮我们选择默认的参数

训练真人Lora就选“人物”

训练二次元就选“二次元”

如果想炼绘画的风格可以选画风

除此之外还可以自定义去炼平面设计图或者建筑之类的

**我这里选择的是产品**：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24217c23b53643c1a2a91947fa2b76d1~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

## 六、高质量素材的制作

以上准备工作及参数设置好了后，就可以开始上传自己的素材开始训练了。

这些素材就是我们要喂给AI学习的素材

素材的质量非常重要！！会直接影响最后出来的Lora的质量

我们的素材需要满足几个点：

**1.上传20~30张照片**：

**2.素材要高清！！！**：

**3.多角度照片**：

这里我就以炼萌宠Lora为例子，上传萌宠的照片

点击“删除全部”把默认的素材删掉

然后点击“上传素材”，上传自己的照片

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed98bdfdbd5c4683bc53a44021971f00~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

**一般情况下，下面的参数默认就可以了**：

需要调整参数的话，最好是需要了解参数的含义，如果乱调的话，可能会训练失败。

> 不要选择太高的分辨率，容易爆显存
>
> 另外，如果训练真人Lora，可以勾选最右边的“脸部加强训练”
>
> 勾选了之后就会再多裁剪出来一组只有脸的照片，这样AI能学到更多的脸部细节

## 七、耐心等待的训练过程

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d42f49fa0bb043ae8064da5edaf9d5c8~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

看到这个页面就是模型正在训练中

到这一步只要**耐心等待**就可以了，没什么需要操作的

我们可以看一下下面的参数是什么意思

“Steps”就是训练步数

每训练50步右下角就会出现一张图片

那样就可以实时看到Lora的样子

这个白头发和红裙子是后台加上去的关键词

可以测试Lora的泛化性

> 泛化性就是看这个Lora能不能自由的去更换照片里的东西，比如发型、发色、服装之类的

Loss可以用来参考模型的好坏

**一个好的模型Loss值在0.07~0.09之间**：

> 注意：具体好不好还是要在Stable Diffusion实际测试才知道

等训练完了之后，点击“模型”

就可以看到生成出来模型

按照默认参数训练会出来20个模型，但不是说最后一个模型就是最好的

有可能炼到第十六第是十七个模型就已经够了，再往后的模型就已经训练过度了

所以这些模型还要实际在SD测试一下，才知道哪个是最好的

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/748087c2a2714c9aaf9bcf363dfcf8f9~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

## 八、如何测试Lora的好坏

模型生成出来之后就可以到SD里面生成图片

在SD里面可以生成这么一张大图，可以直接看到所有模型在不同权重下出来的效果

比较一下哪个模型更好，就只保留那个模型就可以了

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7da599f2ac104ec69ef3c9f29277e0e3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

接下来我们就看看怎么生成这张大图

首先把新生成的10个模型复制到SD的models文件夹，放到Lora文件夹里面

> 注意：最好新建一个文件夹，比如cuteDog

然后把没有序号编码的那个Lora重命名

> 没有序号编码的Lora就是最后生成出来的一个模型，这里只是为了方便进行测试，统一一下所有模型的名称

保存好模型之后就可以打开SD进行测试了

首先先选一个大模型

你用哪一个大模型来训练lora就选哪个大模型

然后输入正面关键词和负面关键词

正面关键词可以输入一些质量词，比如最高质量、高清画质、大师杰作等等

负面关键词直接复制我们以前用过的就可以

接下来就是选用我们刚刚炼好的Lora

随便选一个都可以

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c0df5842decb4ad486bcc631e2f895fb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

重点来了：把000017换成NUM，1换成STRENGTH

<lora:cute dog_20230708214731-000017:1>

例如：

<lora:cute dog_20230708214731-NUM:STRENGTH>

迭代步数，采样方法这些参数大家可以按照自己的习惯去修改

然后滑到最下面找到“脚本”

在脚本里面选择 “**X/Y/Z图表**”

X轴、Y轴类型都选择 “**提示词搜索/替换**”

X轴的值输入：NUM,000001,000002,000003,000004,000005,000006,000007,000008,000009,000010

> 这里的序号对应的就是我们10个Lora的编号

Y轴值输入：STRENGTH,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1

> 这里的序号代表的是Lora的权重

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5737eaa0dcca458aa39b69d90455797c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

全部参数设置好了之后就可以点击“生成”

生成出来就是这么一张大图，可以看到这几个Lora模型在不同强度下的表现

## 九、如何优化Lora

实际上，炼丹是一件比较玄学的事

有的人可能一次性就能炼出自己满意的Lora

但有的人可能要炼好几次才出来一个好的Lora

这时候我们可以通过调整训练的参数再重新炼一个

**前提是 确保我们的喂给AI的素材是高质量的！**

不然不管怎么修改参数，出来的Lora都是不合格的

这里我们就把炼Lora会遇到的问题分成两种情况

1.Lora出来的照片不像本人：**AI没学好**

2.Lora过拟合，甚至出来的照片崩了：**AI学过头了**

过拟合就是不管输入什么关键词，出来的照片都是你喂给AI的照片

没办法自由控制人物的服装、发型、发色等

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3945b20f944c435eb5b49e670c258e90~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

点击“参数调优”我们就可以自行设置参数

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aea4248b822a4696ad8bd4df47cdf7bc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

如果生成的照片不像本人，那就可以适当增加Repeat（学习步数）值

如果照片过拟合了，那就减少Repeat值

其他参数都可以不用调，因为默认的参数就差不多是最优值了

## 十、资源下载汇总

**Lora炼丹网盘资源汇总：** **[pan.quark.cn/s/3c8cc96f3…](https://pan.quark.cn/s/3c8cc96f3221)**

StableDiffusion资源整合安装包：[pan.quark.cn/s/2750beda9…](https://pan.quark.cn/s/2750beda9269)

StableDiffusion关键词分类查询：[StableDiffusion的关键词分类查询](https://y3if3fk7ce.feishu.cn/sheets/Wd2ZsLzTDh12LbtmlEgcp18Onjd)

ControlNet资料汇总：[pan.quark.cn/s/47bc8c798…](https://pan.quark.cn/s/47bc8c79892a)

AI资料网盘汇总（不定期更新）：[AI专区网盘资源汇总](https://y3if3fk7ce.feishu.cn/sheets/BIeAsn8IvhX3HUtcf84cFViinu3%3Ftable%3DtblTLSqLLvUznxAZ%26view%3DvewP2B92zv)

AIGC从入门到精通教程汇总：[AIGC从入门到精通教程汇总](https://y3if3fk7ce.feishu.cn/docx/QBqwdyde7omVf4x69paconlgnAc)

原文链接阅读更舒服：[AI绘画：StableDiffusion炼丹Lora攻略-实战萌宠图片生成](https://y3if3fk7ce.feishu.cn/docx/YoabdC9ynoS7cSxRMLocPuldnAc)

## 如何从0开始训练一个高质量Lora模型

【Stable diffusion：lora模型篇，生成模型基础知识，看完就会，横扫C站，喂饭级，可还原任何作品。】<https://www.bilibili.com/video/BV1Tm4y117HK?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【Stable diffusion：万物皆可lora，生成自己的lora模型，喂饭级。】<https://www.bilibili.com/video/BV1Pu411t74w?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【【Ai教学】如何从0开始训练一个高质量Lora模型】<https://www.bilibili.com/video/BV1hs4y1M79K?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【【Ai教学】如何训练一个画风LoRA】<https://www.bilibili.com/video/BV1Kz4y1n7rF?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

【【完美炼丹术，差异炼丹法】最新LoRA训练进阶教程10】<https://www.bilibili.com/video/BV11m4y147WQ?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

BIRME - 调整多个图像的大小（在线和免费） (onlinephotosoft.com)

打标软件：BooruDatasetTagManager

日志查看：TensorBoard

### 训练的参数调整设置

## Stable Diffusion扩展|插件

插件安装步骤：

1.Stable Diffusion运行界面：【扩展】tab：

- 【从网址安装】：输入github地址安装，下载后把安装包里的模型解压后，放在这个目录：sd-webui-aki > sd-webui-aki-v4.1 > models > adetailer
- 【可下载】安装：直接点击安装

2.重启Stable Diffusion，【文生图】tab中就可以看到插件了

Stable Diffusion插件模型huggingface网站：[webui (webui) (huggingface.co)](https://huggingface.co/webui)

开源地址：[huggingface/transformers: 🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX. (github.com)](https://github.com/huggingface/transformers)

比C站助手好用的LORA触发词/大模型管理插件，插件地址：<https://github.com/a2569875/lora-prompt-tool>

after 插件：崩脸修复神器，面部细节，表情管理

1、中文汉化包
搜索：zh(需要先取消Localization的筛选)
github：<https://github.com/hanamizuki-ai/stable-diffusion-webui-localization-zh_Hans>
————————————————————————————————————
2、提示词自动补全
搜索：tag autocompletion
github：<https://github.com/DominikDoom/a1111-sd-webui-tagcomplete>
————————————————————————————————————
3、提示词直接翻译
搜索：prompt-all-in-one
github：<https://github.com/Physton/sd-webui-prompt-all-in-one>
————————————————————————————————————
4、提示词反推
搜索：tagger
github：<https://github.com/toriato/stable-diffusion-webui-wd14-tagger>
————————————————————————————————————
5、图库浏览器
搜索：image broswer
github：<https://github.com/yfszzx/stable-diffusion-webui-images-browser>
————————————————————————————————————
6、C站助手
搜索：civitai helper
github：<https://github.com/butaixianran/Stable-Diffusion-Webui-Civitai-Helper>
————————————————————————————————————
7、图片超清无损放大
搜索：StableSR
github：<https://github.com/pkuliyi2015/sd-webui-stablesr>
————————————————————————————————————
8、图片分割（一）
搜索：segment anything
github：<https://github.com/continue-revolution/sd-webui-segment-anything>
————————————————————————————————————
9、图片分割（二）
搜索：inpaint anything
github：<https://github.com/Uminosachi/sd-webui-inpaint-anything>
————————————————————————————————————
10、图片精确控制
搜索：cut off
github：<https://github.com/hnmr293/sd-webui-cutoff>

————————————————————————————————————

漫画助手：【漫画助手V4.5发布，AI绘画国产漫画/推文插件，免费下载】<https://www.bilibili.com/video/BV1Aa4y1w7or?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

作者：[咸蛋酱巴拉巴的个人空间_哔哩哔哩_bilibili](https://space.bilibili.com/119916498)

————————————————————————————————————

一键调用Lora触发词助手太好用啦，插件：LoRA-Prompt-Tool

————————————————————————————————————

最强放大算法 插件|扩展：StableSR

插件国内打包地址：<https://www.123pan.com/s/BzxiVv-EPQUv.html>
github需魔法：<https://github.com/pkuliyi2015/sd-webui-stablesr>

————————————————————————————————————

提示词生成插件：maple-from-fall-and-flower

插件开源地址：<https://github.com/maple-flowers/maple-from-fall-and-flower>

————————————————————————————————————

人物脸部替换插件：Roop

开源地址：<https://github.com/s0md3v/sd-webui-roop>

————————————————————————————————————

人物面部重绘插件：sd-face-editor

地址：<https://github.com/ototadana/sd-face-editor>

————————————————————————————————————

高清写实人物画质采样器：DPM-adaptive

![采样器对比](.\img\采样器对比.jpg)

————————————————————————————————————

高效搭建AI图片管理库插件：mCollection

项目地址：<https://github.com/hunmer/mCollection>

需要开启SD的api功能，启动参数后面加入 --api 或者在启动器里开启api服务

插件获取：插件->导入->默认列表里有

————————————————————————————————————

人物商业换装插件：Segment Anything GroundingDINO

【【AI绘画】Stable Diffusion强到离谱的插件让商业换装如此简单，Segment Anything GroundingDINO喂饭级安装教程】<https://www.bilibili.com/video/BV1Vh411F7Zn?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

————————————————————————————————————

无闪烁动画制作|丝丝顺滑、简单易学|Temporal插件安装学习|Ebsynth程序使用：

【StableDiffusion无闪烁动画制作|丝丝顺滑、简单易学|Temporal插件安装学习|Ebsynth程序使用|AI动画制作】<https://www.bilibili.com/video/BV1Po4y1P7zb?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

Temporal插件：<https://github.com/CiaraStrawberry/TemporalKit>
Ebsynth下载：<https://ebsynth.com/>

————————————————————————————————————

提升画面丰富细节插件，让图片更生动饱满：Loopback scaler

GitHub地址：<https://github.com/Elldreth/loopback_scaler>

————————————————————————————————————

Stable Diffusion里插件装一个PS：Photopea

开源地址：<https://github.com/yankooliveira/sd-webui-photopea-embed.git>

使用教程：【告别爱国版限制  PS+SD神级插件横空出世】<https://www.bilibili.com/video/BV1du4y1d7Wt?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

————————————————————————————————————

————————————————————————————————————

————————————————————————————————————

————————————————————————————————————

————————————————————————————————————

————————————————————————————————————

————————————————————————————————————

## 主题插件

萝卜主题 Lobe Theme：<https://github.com/canisminor1990/sd-webui-lobe-theme>

## 基于Stable Diffusion WebUI 本地启动

## Stable Diffusion的后端服务器实例部署

【Stable diffusion的后端服务器该如何选择？这个服务器最省钱！一键部署webui api服务实例！】<https://www.bilibili.com/video/BV1uP411e7eo?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- runpod：<https://runpod.io?ref=dceuo3m2>
- github开源：<https://github.com/nftblackmagic/sdwebui-api-manager.git>
- aws：<https://docs.aws.amazon.com/dlami/latest/devguide/gpu.html>
- lambda：<https://lambdalabs.com/service/gpu-cloud/pricing>

## StableDiffusion腾讯云快速部署

教程：【StableDiffusion腾讯云快速部署，全网最详细保姆级教程（AI绘画、技术小白必看）】<https://www.bilibili.com/video/BV1gu4y1o7Bg?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

文中所涉及的软件以及地址：

- 腾讯云服务器购买入口：<http://985.so/mfnph>
- 叶秋一键安装包链接（含contrlnet1.1）: <http://985.so/mfz5h>
- hNVIDIA 官网驱动下载： <http://985.so/mfz54>
- FTP Rush：<http://985.so/mfz5g>
- 插件地址：
  - 中英文对照界面插件：<https://gitcode.net/overbill1683/stable-diffusion-webui-localization-zh_Hans>
  - 最牛提示词插件：<https://gitcode.net/ranting8323/sd-webui-prompt-all-in-one>

服务器环境搭建篇

### 一、前言

- 关键词：便捷、省钱、简单
- 大家好，我是AI训练师，一个并不懂技术的AI爱好者。
- 如今AI做图火了，各大云服务商开始降价，吸引AI玩家租用GPU服务器出图炼丹，网络上也有各类免费薅羊毛的视频供大家学习。但是经过一圈配置下来就会发现，使用过程会遇到各种坑：英文环境报错看不懂，图片不知道存哪里了，下载图片得一张张下，忘记关机还被扣费等等。玩到最后懵逼的你依然懵逼，我是来薅羊毛的，不是来学习一门计算机编程的（此处应该有掌声！）。
- 要知道，我只是个计算机小白好不好，平时用的是Windows11系统的电脑，点开秋叶整合包的启动器，直接弹出StableDiffusion的出图界面，才是我的习惯。
- 如何以最快、最省钱、最简单的方式使用StableDiffusion出图呢，我研究出了一整套小白也能看懂的腾讯云端Windows部署方案，让大家在云端部署后也能像在本地电脑一样使用方便。（这个方案还可以多人一起共享哟，费用有人AA了，是不是还有点小激动啊^-^）

### 二、操作步骤

#### 2.1 购买服务器

   跟大家想的一样，GN8型的服务器有P40的显卡，每天到时间就被抢光了，基本抢不到，手速好的可以试试。我们就买GN7型号的，自Tesla-T4显卡，也是个不错的选择。点击“立即购买”按钮 活动地址：<http://985.so/mfnph>

![img](https://i0.hdslb.com/bfs/article/cb899c8c0cd1d4debc5675c28f04aaa795adf8ad.png@1256w_732h_!web-article-pic.webp)

- 地域：选择离你最近的地点，不选默认也行，预装镜像：选择Windows sever 2019中文版，点击立即购买付款后

![img](https://i0.hdslb.com/bfs/article/49a767358b60c71294e0cb3abec8fc7f915c642d.png@1256w_1628h_!web-article-pic.webp)

- 付款购买完成之后（大概5分钟后），我们点击右上角的“控制台”进入腾讯云总览首页，在“我的资源”当中点击“云服务器”即可进入服务器界面

![img](https://i0.hdslb.com/bfs/article/34157366dd77d5047778ec6dfdde21e0bd92a0b8.png@1256w_626h_!web-article-pic.webp)

- 这里插一嘴，默认购买的服务器硬盘是100G的，服务器系统直接占用了25G，也就是还剩下75G硬盘，通过我多年的经验，这个硬盘是不够的，建议将系统盘增加至200G，花费17.5元左右。

![img](https://i0.hdslb.com/bfs/article/f7041dcae9f52a351c3aac7af46740c3f558fe2a.png@1256w_812h_!web-article-pic.webp)

- 调整目标硬盘大小点击下一步付款就行。

![img](https://i0.hdslb.com/bfs/article/7eddaac9520baf786ce4a73787fae0844ddcdcbf.png@1256w_950h_!web-article-pic.webp)

#### 2.2 登录服务器

想要登录服务器获取服务器IP地址、用户名和密码，初始密码在顶部的站内信（小信封），点开即可看到，复制好密码后，点击右侧的登录按钮进入登录界面

![img](https://i0.hdslb.com/bfs/article/e9a62534ae48c3068a266ffaaa33343768981658.png@1256w_476h_!web-article-pic.webp)

- 填入密码就能登录，不过这个方式不方便，我一般是点击RDP文件下载，存到桌面，这个是今后登录服务器的快捷方式，如果还想用其他的登录方式可以查看这里<https://cloud.tencent.com/document/product/213/35697，>

![img](https://i0.hdslb.com/bfs/article/9b16168b77c097a95eb1fd5fa4ba6f485d4ddd38.png@1256w_1548h_!web-article-pic.webp)

- 这样就能直接进入到服务器的桌面了

![img](https://i0.hdslb.com/bfs/article/0aaf812b1be4e651f78c2c13b05c5e4e965202f3.png@1256w_614h_!web-article-pic.webp)

#### 2.3 安装显卡驱动

- 注意了，初始状态下，服务器是没有特斯拉显卡驱动的，我们需要打开服务器自带浏览器，访问 NVIDIA 驱动下载 <http://985.so/mfz54> 官网 找到Tesla-T4的驱动，下载对应的驱动进行安装

![img](https://i0.hdslb.com/bfs/article/f704b2e922d77401e582459a957fe363fb03a614.png@1256w_752h_!web-article-pic.webp)

- 默认安装完成之后，点击这个地址 C:\Program Files\NVIDIA Corporation\NVSMI，确认已经存在以下文件，进行下一步

![img](https://i0.hdslb.com/bfs/article/d37df95653b27bfc1984ca23b0074f51802cfd7a.png@1256w_452h_!web-article-pic.webp)

- 右键“此电脑”选择属性，

![img](https://i0.hdslb.com/bfs/article/a4ab14af223616859628b94cbab34cff863a894d.png@1256w_1140h_!web-article-pic.webp)

- 点击系统高级系统设置

![img](https://i0.hdslb.com/bfs/article/d21c5edd82feb73cc052088bafff813509041fd8.png@1256w_900h_!web-article-pic.webp)

- 点开环境变量

![img](https://i0.hdslb.com/bfs/article/ac0a4cccc02ce652ce21a7dc033e442d9a6432af.png@1256w_1764h_!web-article-pic.webp)

- 将地址C:\Program Files\NVIDIA Corporation\NVSMI新建至path的环境变量当中，点击确定

![img](https://i0.hdslb.com/bfs/article/002a71dbe4a89cf4957a34de04a8e04e6e0ae394.png@1256w_640h_!web-article-pic.webp)

- 开始菜单当中打开命令提示符，

![img](https://i0.hdslb.com/bfs/article/3953e3933abf5364c90004cfb6565ea95e7b0c25.png@1256w_810h_!web-article-pic.webp)

- 输入nvidia-smi 看到以下界面表示驱动程序安装成功，

![img](https://i0.hdslb.com/bfs/article/5c56016f9c8b724ff2a97111be8e33dde51ee518.png@1256w_810h_!web-article-pic.webp)

- 2.4 安装StableDiffusion主程序（敲黑板，关键点来了）

#### 2.4.1上传主程序到服务器

- 我们知道StableDiffusion的秋叶一键安装包体积大概快10G左右，介于各位大佬主程序的存储习惯，这里提供了3种下载方案给大家参考，个人最推荐的是第三种，各位可以根据需求选择：
- 方案一：百度网盘，须开通超级会员，下载速度实测 12M/s（不开会员你懂的），30元/月；
- 叶秋一键安装包链接: <https://pan.baidu.com/s/1kJX3bj_lV8Ks25m4hMkpwQ?pwd=jsnr>
- 方案二：夸克网盘，无需开通会员，下载速度实测 300K~500K/s，免费；
- 叶秋一键安装包链接：<https://pan.quark.cn/s/320cc763339b>
- 方案三：搭建FTP文件服务器，上传/下载速率实测 5M/s，免费；（服务器都租了，传文件还花钱，岂不是冤大头^-^），把本地文件拖动到服务器，或者从服务器上下载图片，拖动过去即可，跟在自己电脑上一样简单。
- 云端FTP服务器的搭建，建议参考官方的FTP搭建方式（<https://cloud.tencent.com/document/product/213/10414?from=20421&from_column=20421）> ，这里我就不赘述了，如果大家在搭建过程遇到很多问题，我再出一个手把手FTP服务器搭建教程。
- 本地FTP软件我推荐使用的是FTP Rush（<https://www.wftpserver.com/zh/download.htm#ftprush），适用于各个平台。>

![img](https://i0.hdslb.com/bfs/article/84108efef5a641247740592e7635364acf223101.png@1256w_786h_!web-article-pic.webp)

- 另外说一下腾讯云本身也提供文件传输方式COSBrowser，个人不推荐，使用过后好像是按照存储量收费的，别问我怎么知道的，嗯哼~

#### 2.4.2 安装软件

- 先双击安装“启动器运行依赖”，之后解压sd-webui-aki-v4.1，解压好之后在文件夹内，双击“A启动器”

![img](https://i0.hdslb.com/bfs/article/108883d14ad6dcdc506c5558a5ad90675f3bb206.png@!web-article-pic.webp)

- 打开一键启动后

![img](https://i0.hdslb.com/bfs/article/7e3b4ae16206aaa017a3c9f084478926400014fe.png@1256w_814h_!web-article-pic.webp)

- 当你看到这个界面的时候就可以开始你的出AI之旅了，到此为止服务器配置基本完成。

![img](https://i0.hdslb.com/bfs/article/30a2713ead152200e15ce86aaf2567c99c27f6c6.png@1256w_704h_!web-article-pic.webp)

### 三、使用技巧及常见问题

#### 3.1 插件的安装

- 汉化：在启动器界面勾选启用“云端页面汉化”，操作界面将会变成是中文的

![img](https://i0.hdslb.com/bfs/article/dae97b3bb55870cd53ad2cf32bc8b5b001ab82c5.png@1256w_728h_!web-article-pic.webp)

- 推荐其他的必选插件
- 中英文对照界面插件  <https://gitcode.net/overbill1683/stable-diffusion-webui-localization-zh_Hans>
- 最牛提示词插件 <https://gitcode.net/ranting8323/sd-webui-prompt-all-in-one>

![img](https://i0.hdslb.com/bfs/article/2c18ff6fe566ad5127b5f73fcb3cea2b9a107013.png@1256w_502h_!web-article-pic.webp)

- 3.2大模型、lora的下载和安装
- 秋叶启动器上包含有模型管理，大家可以根据需要自行下载安装，如果这里没有的话，那就去C站<https://civitai.com/和抱脸上搜索https://huggingface.co/models，万能的互联网会告诉你一切。下载后的模型放在什么位置，点击启动器顶部的“打开文件夹”即可找到对应的文件路径，文件放进去即可。>

![img](https://i0.hdslb.com/bfs/article/bdd5223b128880cfcf1a0391e0c066f874503656.png@1256w_730h_!web-article-pic.webp)

- 3.3如何实现多人使用服务器
- 一键启动之前，一定要在启动之前将这两个按钮打开，如果已经启动了，将黑色界面的控制台关掉重新配置打开。

![img](https://i0.hdslb.com/bfs/article/6a35b0d183f524df92ba668671f108a9ed351459.png@1256w_736h_!web-article-pic.webp)

- 启动之后就能得到这样的地址，将地址分享给你的朋友，用浏览器打开即可在多台电脑上实现云端出图

![img](https://i0.hdslb.com/bfs/article/5a216910102e2d58d926ad78a4e7b1b8d7f09e06.png@1256w_786h_!web-article-pic.webp)

- 四、总结
- 上面就是以一个小白的视角搭建云端StableDiffusion的整体流程，注意啊，只是云端搭建流程，软件使用技巧体系过于庞大就不在这里详细说了。有说得不够详细的地方欢迎评论区留言讨论，如果有兴趣想了解其他的知识，我会根据具网友的反馈出额外的教程。
- 全程操作下来，总共花费79元（可用15天），时长大概有4个小时左右，毕竟我可是传了将近100多G 的文件上去呢。
- 最后，在线征集想一块租用服务器的小伙伴，合租是当前玩AI绘画最经济、实惠、高效的办法

## 『关于 ControlNet 的一切』原理 & 代码 & 教程，20+最精华内容汇总

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b30396eaed434e9984d286f6e016a13c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

最近 ControlNet 势头很猛，补齐了Stable Diffusion 条件控制这块短板，实现了人体姿势、图像边缘、深度图、语义色块图、法线图等多种方式对生成的图像进行精确控制，往无缝融入生产工作流又迈进了一大步。这里汇总了目前看到的关于ControlNet的一切：

### 🔔 原理说明

> **项目与使用简介**：[mp.weixin.qq.com/s/UfWNIknn7…](https://mp.weixin.qq.com/s/UfWNIknn7h-JaiNNmLPybQ)
>
> **从玩具变成生产利器**：[mp.weixin.qq.com/s/n0YznjSnc…](https://mp.weixin.qq.com/s/n0YznjSncYPkI93RpYxcRg)

### 🔔 程序及代码

> **官方Github**：[github.com/lllyasviel/…](https://github.com/lllyasviel/ControlNet)
>
> **网页试玩demo**：[huggingface.co/spaces/hyst…](https://huggingface.co/spaces/hysts/ControlNet)
>
> **ControlNet stable diffusion webui automatic111插件**：[github.com/Mikubill/sd…](https://github.com/Mikubill/sd-webui-controlnet)
>
> **ControlNet video 代码（runway gen1视频编辑平替）**：[github.com/camenduru/f…](https://github.com/camenduru/fffilonis-controlnet-video)
>
> **ControlNet video 网页试玩**：[huggingface.co/spaces/fffi…](https://huggingface.co/spaces/fffiloni/ControlNet-Video)
>
> **新功能上线说明（无需文字引导，纯图片猜测生成）**：[mp.weixin.qq.com/s/10W6bIhPQ…](https://mp.weixin.qq.com/s/10W6bIhPQJ4aQafv_MaW9A)
>
> **ControlLoRA，一个能够控制Stable Diffusion空间信息的轻量神经网络，不需额外安装controlnet，使用Lora文件即可实现条件控制**：[github.com/HighCWu/Con…](https://github.com/HighCWu/ControlLoRA)
>
> **T2I-Adapter，一个类似ControlNet的算法，同样可以对SD生成的图片进行条件控制**：[github.com/TencentARC/…](https://github.com/TencentARC/T2I-Adapter)

### 🔔 教程及案例

> **初学者使用指南 (英文版)**：[www.reddit.com/r/StableDif…](https://www.reddit.com/r/StableDiffusion/comments/1167j0a/a_guide_for_beginners_on_a_controlnet_workflow/)
>
> **初学者使用指南 (中文版)**：[mp.weixin.qq.com/s/wAC_Mr_Ya…](https://mp.weixin.qq.com/s/wAC_Mr_YarV3seoM_0dLQA)
>
> **ControlNet SD webui 111插件安装**：[www.bilibili.com/video/BV1jM…](https://www.bilibili.com/video/BV1jM411c7ev/)
>
> **如果无法自动安装插件请看这里**：[www.bilibili.com/video/BV1RD…](https://www.bilibili.com/video/BV1RD4y1A7Cb/)
>
> **如何和具体应用场景结合**： [mp.weixin.qq.com/s/ylVbqeeZc…](https://mp.weixin.qq.com/s/ylVbqeeZc7XUHmrIrNmw9Q)
>
> **生成清晰的艺术字体**：[www.reddit.com/r/StableDif…](https://www.reddit.com/r/StableDiffusion/comments/119j8qr/clear_text_using_controlnet/) 👉 [**Simon的白日梦**](https://mp.weixin.qq.com/s/Rf3_MBK6wTg6lUr0In9xlA)

## 把Stable Diffuion接入QQ微信等工具

## Stable Diffusion WebUI的插件编写

[✅最近开源了一个AI绘画的插件 - 掘金 (juejin.cn)](https://juejin.cn/post/7249607108043800634)

## 文案改写及AI绘画提示词

文案改写及AI绘画提示词网站：<https://888ai.net>

Stable Diffuion提示词工具：<https://poe.com/JJgeSD>

Midjourney提示词工具：<https://poe.com/JJgeMJ>

如：

- 给我一段室内客厅设计图的提示词
- 给我一段自然风光提示词，包含山川，河流，高山，峡谷

## 衍生平台

yadayoAI艺术平台：<https://yodayo.com/>

【无需安装！在线使用2000多个Lora和100多个AI模型进行免费绘画】<https://www.bilibili.com/video/BV1qV411M7Zt?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

海艺AI：[海艺 (seaart.ai)](https://www.seaart.ai/home)

## 免费在线的Stable Diffuion

免费Stable Diffuion：[MinisterAI - Free online AI Art Generator | Stable Diffusion (mst.xyz)](https://mst.xyz/home)

指令参数：1girl, (high detailed skin:1.0), 8k uhd, dslr, face, soft lighting, high quality, <lora:shiftymine_v2:1.0> 不需要元素：(low quality, worst quality:1.4), (bad anatomy), (inaccurate limb:1.2), bad composition, inaccurate eyes, extra digit, fewer digits, (extra arms:1.2) logo, text, poorly drawn nipples

[Stable Diffusion在线网站集合 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/622751562)

## 各个领域的中英文对照表

室内/建筑关键词中英文对照表：[⁡﻿‌⁤⁡⁢‍⁤‍⁡⁣⁢⁤⁢⁣‍﻿﻿⁣⁣‬‌﻿‬⁢⁣‌‍‬‌⁡⁡⁣⁡⁢室内/建筑关键词中英文对照表 - 飞书云文档 (feishu.cn)](https://d36mqghu8a.feishu.cn/sheets/NnnwsdcCKh3dpgt88kCcQsc8nIe?sheet=oVqwGF)

## 短视频变现渠道

短视频赛道优势：美女是刚需，不管是线上还是线下，

有美女的地方就会有流量，有流量的地方才有钱

变现方式：

壁纸cps：2.5-4毛下载/次

音乐推广：100-5000/条

教学收徒：199-1999/学员

广告变现：500-2000/条

男粉变现：单价8-15一个(大把人收，变现方式多种)

设备要求：电脑，最低4G或8G，N卡，＋ 手机远程操作教程
