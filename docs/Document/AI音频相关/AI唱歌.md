# AI唱歌

## 介绍

## 软件

- so-vits-svc github地址：<https://github.com/svc-develop-team/so-vits-svc>
- sadtalker github地址：<https://github.com/Winfredy/SadTalker>

视频留言里【【AI唱歌】再次进化！6分钟学会用AI唱歌，杀疯了！】<https://www.bilibili.com/video/BV1wv4y1J7pR?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

一键启动包下载地址（提取码：qi2p）： <https://pan.baidu.com/s/1Jm-p_DZ2IVcNkkOYVULerg?pwd=qi2p>

## AudioCraft整合包

官方的说明：We recommend 16GB of memory, but smaller GPUs will be able to generate short sequences, or longer sequences with the small model.最好是16G往上的，低的显存只能生成短的音频，并且只能用small这个模型

唯一需要安装的是基础环境python3.10的版本，可通过这个连接下载：
<https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe>

整合包下载地址：链接：<https://pan.baidu.com/s/1M0c-6_6yI2IMBjo0LN7HNg?pwd=gfrj>   提取码：gfrj

代码地址：<https://github.com/facebookresearch/audiocraft>

Colab地址：<https://github.com/camenduru/MusicGen-colab>

在线试玩：<https://huggingface.co/spaces/facebook/MusicGen>

## 如何训练一个AI歌手

视频教程：【手把手教学！如何自己训练一个AI歌手 - sovits本地&云端训练教程】<https://www.bilibili.com/video/BV1ea4y1G7gx?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

- sovits：<https://github.com/svc-develop-team/so-vits-svc>
- 一键包：<https://www.bilibili.com/video/BV1Cc411H74D/>
- UVR5：<https://www.bilibili.com/video/BV1ga411S7gP/>
- RX Audio Editor
- 123盘：<https://www.123pan.com/s/RiyA-LjS03>
- 夸克网盘：<https://pan.quark.cn/s/f9791f6790d3>
- 百度网盘：<https://pan.baidu.com/s/1xUXd9vVHR11sjJ6wCVuwHQ?pwd=hjhj> 提取码: hjhj
- Audio Slicer：
- Github链接：<https://github.com/flutydeer/audio-slicer/blob/main/README.zh-CN.md>
- 网盘链接：<https://henji.lanzout.com/iuSOk0uv354j>

————————————————————

AI声源：

- 孙燕姿

相关歌曲：

- 梁静茹 - 宁夏
- RADWIMPS&十明 - すずめ feat.十明
- 林俊杰 - 可惜没如果
- 米津玄师 - Lemon

【AI歌手+AI变声二合一，还能一键制作音乐视频！最新RVC模型训练教程，在线一键训练，效果提升明显，快来试试吧！】<https://www.bilibili.com/video/BV1r8411f7MR?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

程序连接：<https://huggingface.co/spaces/kevinwang676/Voice-Changer>

详细训练教程：【【RVC】在线一键训练AI歌手，无需配置环境，只需半小时！还能生成音乐视频！使用Autodl镜像快速训练，快来试试吧！】<https://www.bilibili.com/video/BV1mX4y1C7w4?vd_source=36c9491a7fa2ab8a22ca060af01b7472；>

在线训练链接：<https://www.autodl.com/home；>



[**⋙ 完整教程@数字生命卡兹克**](https://mp.weixin.qq.com/s/bBqGwsDgStTGTQs_ha03xg)

**借助 So-VITS-SVC，用自己的声音完整唱了一首「富士山下」**。作者用大量的图文，详细写了整个AI声音教程，并准确了完整安装包。

> *1*. **准备声音数据集**。声音模型对数据集的要求比较苛刻，想训练自己的声音需要录制1小时以上的无杂音的纯人声，WAV 格式，再使用 Audio Slicer (音频切分工具) 将其剪裁成10秒左右的分段文件
>
> *2*. **租云算力，上传数据集**。训练模型挺烧显卡的，直接找到便宜稳定的云算力平台，充值三五十元就可以搞定！轻松便捷
>
> *3*. **在云上训练模型**。跟着截图在云平台的控制台操作，进行 10,000 步的模型训练，耗时较久，做好准备
>
> *4*. **本地进行推理模型重绘歌曲**。声音重绘的原理是，用模型的音色替换人声。这一步推荐了大量实用工具，比如分离工具「UVR5」、音乐获取「QQ音乐」、歌曲合成「AU/剪映」等
>
> 注意！项目完成时云算力还在烧钱！如果不继续使用，直接先点关机，然后点击释放实例

## 音乐生成与创作AI

【音乐生成与创作AI，Meta开源Audiocraft 安装与使用教程】<https://www.bilibili.com/video/BV1bh4y1X77a?vd_source=36c9491a7fa2ab8a22ca060af01b7472>

Meta开源音乐生成大模型audiocraft，可根据文本提示和音乐样本创作新的乐曲，生成效果非常逼真，媲美艺术家作品：<https://github.com/facebookresearch/audiocraft>

安装说明文档在百度网盘：链接：<https://pan.baidu.com/s/17O8W112laAeSxz3pT0qa5w>   提取码：ro7s

## Meta 音乐生成模型 MusicGen，通过文字/音频来生成或修改音乐

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/87883384905c4756ab3a5347a4ce994e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

Meta近日在HuggingFace开源了一款新的音乐生成模型MusicGen，可以将文本和已有旋律转化为完整乐曲，也支持对现有音乐进行修改。

研发团队表示：我们使用了20000小时的授权音乐来训练该模型，并采用Meta的EnCodec编码器将音频数据分解为更小的单元进行并行处理，进而让MusicGen的运算效率和生成速度都比同类型AI模型更为出色 [MusicGen - a Hugging Face Space by facebook](https://huggingface.co/spaces/facebook/MusicGen)

## 教你打造属于自己的AI孙燕姿』AI歌手模型使用及训练保姆级课程

最近AI歌手很火啊！歸藏分享了他使用 So-VITS-SVC 项目包来推理和训练的详细全过程，并分享了所有的资料包和使用教程。

> 最终「AI孙燕姿」唱了一首「爱得太迟」，还挺不错！

### 🔔 第一部分：使用模型

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/73099c611cdf4fbda71ed85ab8d7abdb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

如果只想使用别人训练好的模型尝鲜，那么只看这部分就可以了。

> *1*. **原始声音处理**。准备一段高品质、清晰的演唱音频，并去掉背景音乐提取人声
>
> *2*. 推理过程。启动 webui.bat 并使用推理功能，选择模型与配置文件，加载模型后勾选「聚类f0」「F0均值滤波」两个选项，并通过音频转换生成音乐
>
> *3*. 音轨合并。下载当前生成的干声音频，并于第1步剥离的伴奏音频进行合成，就可以生成带有一首非常不错的歌曲啦！当然加上图片就可以生成视频~ [**⋙ 阅读全文**](https://mp.weixin.qq.com/s/bXD1u6ysYkTEamt-PYI1RA)

### 🔔 第二部分：训练模型

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/72b0f63174504722811f1056d005d431~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

> *1*. **数据准备**。准备质量比较高、人声比较清晰声音素材，并对素材进行格式转换、半轴分离、文件分割等处理
>
> *2*. **模型训练**。识别数据集、数据预处理、设置参数、开始训练，并获得模型保存的结果
>
> *3*. 音轨合并。回到上方第3步的同样操作 [**⋙ 阅读全文**](https://mp.weixin.qq.com/s/IeeW1PbMUbxMlLl529JTYQ)

## RVC 模型

使用 RVC 模型和入梦工具，带大家实现以下几个功能：

- 音乐干声分离：背景音（BGM）与人声（干声）的分离
- 训练个人音色模型：作为模仿其他干声素材的音色数据
- 男女换声（伪音）：基于异性干声素材，进行实时转化声音为异性声音
- AI 唱歌：仅作基础的模拟演唱，仍需进行调音等等操作，才可以达到完美
- 音色融合：不同音色的特征融合出一个全新的音色

在进行教学前，我们先假设这样一个场景：现有素材，男声音色A，女声音色B，女声音色C的朗读素材C，男唱歌状态下的音色D，女声音色C的唱歌素材E，我们根据以上介绍的功能进行整合，可以做到以下案例：

- 案例一：将女声C的朗读素材进行干声分离，再用男声音色A朗读女声音色C的朗读素材C。
- 案例二：可以用女声B的音色去朗读女声C的朗读素材。
- 案例三：甚至能够进行小延迟（0.1s）的实时音色转换，比如将使用男声音色A的声音去讲，可以实时转化为女声音色B的声音，实现无技巧完成男女伪声转换。
- 案例四：利用音色D的声音去演唱音色C的唱歌素材，实现类似AI孙燕姿的功能。
- 案例五：拿女音色B和C的素材进行融合出一个新的音色F
- 案例六：音色A从来没有说过外语（英语、日语等等），但需要现在马上说一段外语音频

效果可参考出处：[【rvc教程】AI变声/AI音色训练_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Ek4y1W7Xv/?vd_source=5f0c99b3deddffe219938763769b15ac)  极为逼真，值得尝试。当然，我也只是作为分享。 **在此感谢三位UP主：花儿不哭/唯有如梦/干易/掉脑袋切切_bling 的视频** 

下载资源： 文件目录如下：

![文件目录](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d299df65000a4896ad6f30b743a88c0a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

### 注意事项

- 性能要求：建议20系N卡以上，显存在 8g 以上，性能越高越好
- 模型文件目录要求：全英文、无中文、待处理音频、单音色素材独立一个文件夹
- 启动模型时，命令行界面不能关闭，否则，模型停止运行，下文中提到的所有命令行都使用时不能关闭
- 注意音色版权问题，不做违法勾当，技术无罪，请勿滥用
- 音色、音频素材质量好坏不仅仅体现在音源质量，音色训练干声素材更在意有无噪声（气泡音、混响者等不佳），是否贴合模仿场景（唱歌音色对应唱歌音频转换等等），是否音频变调范围较少等等

### 音色推理流程

什么是音色推理呢？其实就是实现案例一二的过程，也就是推理音色A到音色B，再应用到声音素材上的过程。我们将使用 RVC 模型的一建训练包，步骤如下：

1. 启动 RVC web 界面：双击打开 RVC-beta_5\RVC-beta\go-web.bat
2. 等待启动，启动成功命令行效果如下： 命令行： ![go-web.bat](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60a20686f4f646c2800563254517b888~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) web界面： ![web界面](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e76b1e086ba147d588b13aa334b090a5~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
3. 界面参数说明：
   - 推理音色：推理结果成品的实际音色
   - 待处理音频：推理结果成品的实际音频内容，支持绝大部分音频格式
   - index 路径：推理音色相符合的特征文件 index 结尾
   - 变调(整数, 半音数量, 升八度12降八度-12)：男女音调差距较大，男转女推荐+12key, 女转男推荐-12key, 如果音域爆炸导致音色失真也可以自己调整到合适音域.
   - 刷新音色列表和索引路径：加载新的推理音色和 index 文件，训练出新音色就需要重新加载
   - 卸载音色：去除加载进的音色，以节省显存
   - 音高提取算法：输入歌声可用pm提速,harvest低音好但巨慢无比
4. 选定对应参数数据：按照界面参数，选择推理音色、待处理音频、index 路径、变调等等最基本的参数（也就是说其他参数保持默认的参数也能使用，有能力、有需求的再自行微调），点击转换即可进行音色推理了。 转换结果效果如下： ![音色推理结果](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06f9c241074f4fa1b1722ce8017ceebf~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 点击播放按钮即可在线播放转换后的音频，右键点击即可下载结果音频或者改变播放速度。最好是先听听效果，再下载，毕竟不一定效果合适，可能需要调整参数。 这就是音色推理的全流程，也是整个模型训练性能要求最低的一个部分之一，如果，你连默认的音色都无法正常推理成功的话，音色训练部分建议在性能更强的电脑上进行。

### 素材干声分离

素材干声分离也就是分离人声和背景音，这一部分不一定需要本模型一键训练包来完成，只是为了获得更好的干声素材而做的预处理操作，有其他现成更简单的工具也可以使用。话扯远了，接下来就说说怎么进行素材的干声分离，步骤如下：

1. 启动 RVC 模型的一建训练包，和推理模型的启动方法一致，切换到干声分离界面，如下： ![素材干声分离界面](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88114ddfe8a34fd6a03ba3bf60fd9f56~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
2. 界面参数说明：
   - 待处理音频路径：待处理音频的文件夹路径，注意不是文件路径，这也是为什么每个待处理音频都要独立放置到一个文件夹的原因，因为太多文件，训练时间过长。
   - 按需选择分离模型：HP2 人声（只有背景音和人声类型）、HP5人声（带有背景音和人声叠加等等效果类型）
   - 指定人声输出目录：默认 RVC-beta\opt
   - 指定乐器文件夹：背景音文件夹，默认 RVC-beta\opt
3. 填写好对应参数信息之后，点击转换即可完成素材干声分离。最终效果如下： ![素材干声分离结果](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c6ed6073586c4a959caa3c5a4c3875b6~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 输出信息为 success 即为干声分离成功，如果报错，就需要检查音频和电脑的硬件问题了。

### 音色训练

音色训练其实就是利用经过预处理或者本身音源素质良好的干声素材进行训练，提取对应的音色特征，进而模拟其音色特征，再生成对应的音色包，这个过程中当然可以尝试通过微调参数实现更好的音色特征提取，但篇幅有限，本文只介绍最简单，最直接的音色训练教程。步骤如下：

1. 准备好 3 分钟以上、50 分钟以内的优质干声素材，建议在3到7分钟之间，效果就很不错了，做好训练时长等待的准备
2. 启动训练模型，切换到训练模块，如下： ![训练界面](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/512d4e92a53c4c25bbe67f6ef2765912~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
3. 界面参数说明：
   - 实验名：即将训练出来的音色包名称
   - 目标采样率：干声素材采集样本占比，按性能需求更改，默认 40k 就有不错的效果了
   - 模型是否带音高指导：如果是唱歌类型的干声素材，必须选择 true ，反之，选或不选都可以
   - 版本：建议使用 V1，V2 仍存在部分 Bug
   - 提取音高和处理数据所使用的 CPU 进程数，默认为 16 ，可根据性能瓶颈自行更改，最少为 2
   - 训练文件夹路径：所要训练的干声素材文件夹路径，注意是文件夹路径，同一个文件夹里面只能包含一个人的音色干声素材
   - 显卡信息：启动后会自动读取本机显卡信息，多张显卡可输入卡号，指定训练用显卡
   - 音高提取算法：输入歌声可用pm提速,高质量语音但CPU差可用dio提速,harvest质量更好但慢
   - 保存频率：每训练 n 轮，保存一次音色特征数据，建议以 20 为保存频率，可根据性能瓶颈自行更改
   - 总训练轮数：不得小于保存频率数，总训练轮数按性能瓶颈来，建议 200 轮即可，干声素材优秀可选择 50 轮即可，普通人听不出来的，最高可达 1000 轮，轮数越高，性能要求越大，时间越长，过高也会过拟合，不建议太高。
   - 每张显卡的 back_size：按默认即可，会在读取显卡信息后自动选择，如果自行指定训练显卡，可根据性能瓶颈自行选择
   - 是否仅保存最新的ckpt文件以节省硬盘空间：选择是的话，只有最后一轮的训练特征数据，反之，按保存频率保存音色文件
   - 是否缓存所有训练集至显存.：10min以下小数据可缓存以加速训练, 大数据缓存会炸显存也加不了多少速度
   - 是否在每次保存时间点将最终小模型保存至weights文件夹：选择是即可
4. 填好以上界面参数数据，点击一键训练即可，慢慢等待结果出现，建议只运行该模型 ckpt 处显示 success，结尾有个 2333333 即为成功 ![训练结果命令行](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a9f050e4dfa348d18cfe3ce347e37d71~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 训练结果（音色）文件夹：weights 文件夹 ![音色文件夹](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/869b8b5f25d147aba8d63ff4800d4b1b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 训练音色特征结果：logs 文件夹 ![音色特征数据](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8b0e4a47e918477fa955934d0fefcf79~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 如果，没有迁移训练和微调参数需求的话，可仅保存 index 和 npy 文件，连同前文的 pth 文件就可以构成一个完整的音色包文件。可分享音色包文件示例如下： ![音色包文件](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f78bdb1b52504c35ba46a39d3bdd5c87~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

利用这个音色包文件就可以进行前文的音色推理了，也就能够实现案例一、二、四、七，包含唱歌类型的模拟，以及说一段自己不会的外语音频也是可以实现的，同时，实现唱歌素材的模拟不就可以得到 AI 孙燕姿的干声素材，再利用之前干声分离出的背景音进行调整，就可以基本实现AI孙燕姿啦，只要我们拥有（训练所得、分享获得）孙燕姿的唱歌音色包，以及对应优质的唱歌干声素材，当然，还需要进一步的调音、编曲等待操作，让它更像更完美。

### 音色融合

音色融合就是基于前文提到的音色训练出来的音色包进行融合音色，当然，同一性别的音色融合效果会好一点，通过音色融合，我们就可以创造出一个全新的音色包，当然，也可以利用此操作减少音色爆音的几率，比如，A音色音色好但容易爆音，B音色不太好，但胜在稳定，就可以用高权重的A模型融合低权重的B模型，融合出来的音色就能拥有两个的优点，但权重比例得自行调整，达到一个比较好的平衡，基于融合后的音色就可以做出不一样的音源素材。步骤如下：

1. 启动模型，切换到 ckpt 部分 ![ckpt界面](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/781419969ffb4f20bfc80c998970c916~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

2. 界面参数说明：

   - A、B模型路径：A、B模型文件路径就是需要进行融合的两个音色模型的 pth 文件路径
   - A 模型权重：融合哪个音源特征更多的数值化表达，也就是融合结果音色更像哪个音色
   - 保存的模型名称：此次融合结果音色的名称

   其他参数自行调整，简单地调整以上数据就能实现音色融合

3. 点击融合，输出结果为 success 即可。音色包会在 weight 出现，并且，不会有对应的 index 和 npy 文件生成，但可用高权重的音色模型训练出来的结果文件。 ![音色融合](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0841c99a5f547d591ece4f7e6799c1e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 这我们就能实现案例五的效果了，你可以使用融合后的音色继续“炼丹”，直到满意为止。

### 入梦工具实现男女伪音实时无技巧转化

男女伪音，也就是男女声音实时互换的操作，实现类似于变声器的效果，部分游戏、陪玩也有在使用。步骤如下：

1. 启动模型和入梦工具：双击 RVC-beta_5\RVC-beta\go-realtime-gui.bat 和 RVC\RVC入梦小工具\RVC入梦小工具.exe GUI 界面如下： ![模型GUI界面](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b67d81770db84e24a851d3734861f295~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

   模型运行命令行界面如下： ![模型命令行](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6aa6dee92d2844a4b57ff92e9ae10a3f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) 入梦工具界面如下： ![入梦工具](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/675532e7182c4434a0b54a118f8d35e7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

2. 安装入梦工具驱动：点击入梦工具虚拟 MME，一直下一步即可安装驱动 ![驱动安装](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d1798570c9424cbd948d8b375fb15c02~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

3. 点击系统音频，配置扬声器和麦克风

   - 录制设备配置成入梦工具为默认使用设备 ![配置录制设备](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1caf834185c040769bb906eac5067301~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

   - 播放设备不用修改，使用电脑默认设置就行，需要修改入梦扬声器的属性配置中的采样频率和位深度与电脑默认设置的设备对应属性一致，再更改入梦麦克风的侦听属性为侦听此设备即可。不过建议为耳机类型的扬声器，公放类型会被录制设备读取，产生回音，出现杂音。 ![修改属性一](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/65cb709a869d43d0bda44ec1a7460b17~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) ![默认设备属性](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2bcae4cd268240d28d3f61833bb4ce3a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

     ![修改属性二](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c2349086ed524ac6b15cf15b7b78e796~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) ![修改属性三](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3e29425d861c451585adb9aa141dddc4~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

4. 配置模型音频输入输出设备：输入设备设置为电脑默认麦克风即可，输出设备设置为入梦扬声器，实际播放声音为电脑默认音频输出设备，如下： ![音频输入输出设备设置](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/91e544ce9bdc425698327fcf29884b75~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

5. 模型 GUI 界面加载模型参数说明： ![加载模型](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f4d9a3c62b724b0fa1bd3592933d2839~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

   - 载入 Hubert 模型：不会默认读取模型，需要自行载入，双击按钮打开文件夹，选中 RVC-beta_5\RVC-beta\hubert_base.pt 即可。
   - 选择 pth 文件：双击按钮打开文件夹，自行选中音色包内的 pth 文件即可
   - 选择 index 文件：双击按钮打开文件夹，自行选中对应音色包内的 index  文件即可
   - 选择 npy 文件：双击按钮打开文件夹，自行选中对应音色包内的 npy 文件即可

6. 模型 GUI 界面常规设置及其性能设置参数说明： ![常规设置及其性能设置](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d48096eaf1e43e38e094153770dee62~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

   - 响应阈值：麦克风读取响应速度，自行调整不爆音即可，数据越低，实时延迟越小
   - 音调设置：男女音调差距较大，男转女推荐+12key, 女转男推荐-12key, 如果音域爆炸导致音色失真也可以自己调整到合适音域。
   - index rate：0.3 到 0.5即可，特征提取相关参数
   - 采样长度：推理时间，采样长度自行调整，不含过多电子音即可，数值越低，延迟越低，建议为 1 即可
   - 淡入淡入长度：保持默认即可，除非有一些奇怪的尾音
   - 额外推理长度：推理长度高一点，声音可能会好一些，但延迟高，自行调整
   - 输入输出降噪：如果录音环境存在一定噪声可勾选

7. 选择完其他设置，点击开始转化即可实现实时转换音色的效果，注意推理时间正常变化才是正常运行。

8. 如果需要切换音色的话，就必须停止音频转换再重新修改加载模型部分的参数。

9. 如果是游戏使用、录制时使用，就必须把对应软件的麦克风设置为入梦麦克风，注意检查一下

本章节解决了案例三的男女伪音转换效果，这也将引起我们的警觉。

### 总结一下

AI 语音技术的进步已经带来了许多令人兴奋的结果，而 RVC 则是其中的一个重要发展方向。RVC 可以让使用者将一个人的声音样本複制并转移到另一个人身上，并可实现即时语音转换。以下是 RVC 可能带来的一些结果：

1. 更自然的语音转换：RVC 技术可以让语音转换更加自然、逼真。这种技术可以学习一个人的语音特徵，包括音调、节奏和语速等，并将这些特徵应用到其他人的语音中，使其听起来更加自然。
2. 音频和影片后期制作：RVC 技术还可以用于音频和影片后期制作。例如，在电影和电视剧中，演员的声音可能需要进行修剪或处理，RVC 技术可以帮助制作人员快速、高效地完成这些任务。
3. 音乐创作：RVC 技术可以用于音乐创作，例如合成电子音乐或增强现有音乐。使用这种技术，音乐家可以从其他艺术家的声音中获得灵感，并将其应用到自己的创作中。

虽然这技术对于娱乐、语音合成等方面有著极大的应用价值。然而，这种技术也引发了许多道德等问题，例如滥用、欺骗、侵犯隐私等问题，需要你我共同关注，使用该技术时也要特别注意这些问题，请小心别踩线。
